---
title: Управление микрослужбами и многоконтейнерными приложениями для обеспечения высокого уровня масштабируемости и доступности
description: Реальные рабочие приложения должны развертываться с оркестраторами, которые управляют работоспособностью, рабочими нагрузками и жизненным циклом всех контейнеров.
ms.date: 02/15/2019
ms.openlocfilehash: e548e6b3816dec1e56c273c53c9fd052443eb09b
ms.sourcegitcommit: 7588136e355e10cbc2582f389c90c127363c02a5
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/14/2020
ms.locfileid: "76919543"
---
# <a name="orchestrating-microservices-and-multi-container-applications-for-high-scalability-and-availability"></a>Управление микрослужбами и многоконтейнерными приложениями для обеспечения высокого уровня масштабируемости и доступности

Использование оркестраторов для приложений, готовых к развертыванию в рабочей среде, крайне важно, если приложение основано на микрослужбах или разнесено по нескольким контейнерам. Как было сказано ранее, в рамках подхода на основе микрослужб каждая микрослужба имеет собственную модель и данные, поэтому она является автономной с точки зрения разработки и развертывания. Но если у вас есть более традиционное бизнес-приложение, состоящее из нескольких служб (например, SOA) и требующее распределенного развертывания, оно также будет включать в себя несколько контейнеров или служб. Такие системы сложны в масштабировании и управлении, поэтому для создания масштабируемого многоконтейнерного приложения, готового к развертыванию в рабочей среде, оркестратор абсолютно необходим.

На рис. 4-6 показано развертывание приложения, состоящего из нескольких микрослужб (контейнеров) в кластере.

![Схема, на которой показаны составные приложения Docker в кластере.](./media/orchestrate-high-scalability-availability/composed-docker-applications-cluster.png)

**Рис. 4-6**. Кластер контейнеров

Такой подход выглядит логичным. Однако как обеспечить балансировку нагрузки, маршрутизацию и оркестрацию для таких составных приложений?

Docker CLI позволяет управлять одним контейнером в одном узле, но этого недостаточно, если требуется управлять множеством контейнеров, развернутых в нескольких узлах для более сложных распределенных приложений. В большинстве случаев необходима платформа управления, которая будет автоматически запускать контейнеры, масштабировать контейнеры с несколькими экземплярами в каждом образе, а также при необходимости приостанавливать или завершать их работу. В идеале она также должна контролировать доступ к ресурсам, таким как сеть и хранилище данных.

Чтобы перейти от управления отдельными контейнерами или простыми составными приложениями к управлению крупными корпоративными приложениями с микрослужбами, следует прибегнуть к платформам оркестрации и кластеризации.

С точки зрения архитектуры и разработки, если вы создаете крупные корпоративные приложения на основе микрослужб, важно знать следующие платформы и продукты, которые поддерживают сложные сценарии:

- **Кластеры и оркестраторы**. Если вам нужно масштабировать приложения на множестве узлов Docker, как в случае с крупным приложением на основе микрослужб, крайне важно иметь возможность управлять всеми этими узлами как единым кластером, абстрагируясь от сложности базовой платформы. Именно такую возможность предоставляют кластеры контейнеров и оркестраторы. Примерами оркестраторов могут служить Azure Service Fabric и Kubernetes. Функции Kubernetes доступны в Azure через службу Azure Kubernetes.

- **Планировщики**. *Планировщик* дает администратору возможность запускать контейнеры в кластере посредством пользовательского интерфейса. Планировщик кластера имеет несколько функций: обеспечение эффективного использования ресурсов в кластере, применение заданных пользователем ограничений, эффективная балансировка нагрузки контейнеров между узлами, а также обеспечение устойчивости к ошибкам и высокой доступности.

Понятия кластера и планировщика тесно связаны друг с другом, поэтому продукты, предоставляемые разными поставщиками, часто включают в себя оба набора возможностей. В следующем разделе приведен список наиболее важных платформ и программного обеспечения, предоставляющих возможности управления кластерами и планирования. Эти оркестраторы, как правило, предлагаются в составе общедоступных облачных платформ, таких как Azure.

## <a name="software-platforms-for-container-clustering-orchestration-and-scheduling"></a>Программные платформы для кластеризации контейнеров, оркестрации и планирования

| Платформа | Комментарии |
|:---:|:---|
| **Kubernetes** <br/> ![Изображение логотипа Kubernetes.](./media/orchestrate-high-scalability-availability/kubernetes-container-orchestration-system-logo.png) | [*Kubernetes*](https://kubernetes.io/) — это решение с открытым кодом, которое предоставляет широкий ряд возможностей: от организации инфраструктуры кластера и планирования контейнеров до оркестрации. Оно позволяет автоматизировать развертывание, масштабирование и выполнение операций с контейнерами приложений в кластерах узлов. <br/> <br/> *Kubernetes* предоставляет ориентированную на контейнеры инфраструктуру, которая объединяет контейнеры приложений в логические блоки, чтобы упростить управление и обнаружение. <br/> <br/> Решение *Kubernetes* является зрелым в Linux и менее зрелым в Windows. |
| **Служба Azure Kubernetes (AKS)** <br/> ![Изображение логотипа службы Azure Kubernetes.](./media/orchestrate-high-scalability-availability/azure-kubernetes-service-logo.png) | [Служба Azure Kubernetes (AKS)](https://azure.microsoft.com/services/kubernetes-service/) является управляемой службой оркестрации контейнеров Kubernetes в Azure, которая упрощает управление, развертывание и эксплуатацию кластера Kubernetes. |
| **Azure Service Fabric** <br/> ![Изображение логотипа Azure Service Fabric.](./media/orchestrate-high-scalability-availability/azure-service-fabric-logo.png) | [Service Fabric](https://docs.microsoft.com/azure/service-fabric/service-fabric-overview) — это платформа микрослужб от корпорации Майкрософт, которая предназначена для создания приложений. Она позволяет [оркестрировать](https://docs.microsoft.com/azure/service-fabric/service-fabric-cluster-resource-manager-introduction) службы и создавать кластеры компьютеров. Службы в Service Fabric могут развертываться как контейнеры или как обычные процессы. Кроме того, в рамках одного приложения или кластера можно сочетать службы в процессах и службы в контейнерах. <br/> <br/> Кластеры *Service Fabric* могут быть развернуты в Azure, локально или в любом облаке. Тем не менее управляемый подход упрощает развертывание в Azure. <br/> <br/> *Service Fabric* предоставляет дополнительные перспективные [модели программирования Service Fabric](https://azure.microsoft.com/documentation/articles/service-fabric-choose-framework/), такие как [службы с отслеживанием состояния](https://azure.microsoft.com/documentation/articles/service-fabric-reliable-services-introduction/) и [Reliable Actors](https://azure.microsoft.com/documentation/articles/service-fabric-reliable-actors-introduction/). <br/> <br/> Решение *Service Fabric* является зрелым в Windows (годы развития в этой среде) и менее зрелым в Linux. <br/> <br/> С 2017 года в Service Fabric поддерживаются как контейнеры Linux, так и контейнеры Windows. |
| **Сетка Azure Service Fabric** <br/> ![Изображение логотипа Сетки Azure Service Fabric.](./media/orchestrate-high-scalability-availability/azure-service-fabric-mesh-logo.png) | [*Сетка Azure Service Fabric*](https://docs.microsoft.com/azure/service-fabric-mesh/service-fabric-mesh-overview) обеспечивает тот же уровень надежности, критически важной производительности и масштабируемости, что и Service Fabric, но также предлагает полностью управляемую бессерверную платформу. Нет необходимости управлять кластером, виртуальными машинами, хранилищем и конфигурацией сети. Вы можете сконцентрировать усилия на разработке приложений. <br/> <br/> *Сетка Service Fabric* поддерживает контейнеры Windows и Linux, позволяя осуществлять разработку на любом языке программирования и платформе.

## <a name="using-container-based-orchestrators-in-azure"></a>Использование оркестраторов на основе контейнеров в Azure

Ряд поставщиков облачных служб, включая Azure, Amazon EC2 Container Service и Google Container Engine, предлагают поддержку контейнеров Docker, а также кластеров Docker и оркестрации. Azure поддерживает кластер и оркестратор Docker посредством службы Azure Kubernetes (AKS), Azure Service Fabric и сетки Azure Service Fabric.

## <a name="using-azure-kubernetes-service"></a>Использование службы Azure Kubernetes

Кластер Kubernetes объединяет несколько узлов Docker в пул и предоставляет доступ к ним как к единому виртуальному узлу Docker, что позволяет развертывать несколько узлов в кластере и осуществлять масштабирование, добавляя любое число экземпляров контейнеров. Кластер отвечает за выполнение всех сложных задач управления, включая масштабирование, обеспечение работоспособности и т. д.

Служба AKS позволяет упростить создание и настройку кластера виртуальных машин в Azure, предварительно настроенных для выполнения упакованных в контейнеры приложений, а также управление им. Благодаря оптимизированной конфигурации популярных средств планирования и оркестрации с открытым кодом служба AKS дает возможность развертывать приложения на основе контейнеров в Microsoft Azure и управлять ими, используя имеющиеся навыки или прибегая к знаниям большого и продолжающего расширяться сообщества.

Служба Azure Kubernetes оптимизирует настройку популярных средств и технологий кластеризации Docker с открытым кодом для Azure. Вы получаете открытое решение, которое обеспечивает переносимость как контейнеров, так и конфигурации приложения. Вы выбираете размер, число узлов и средства оркестрации, а служба Azure Kubernetes делает все остальное.

![Схема, показывающая структуру кластера Kubernetes.](./media/orchestrate-high-scalability-availability/kubernetes-cluster-simplified-structure.png)

**Рис. 4-7**. Упрощенная структура и топология кластера Kubernetes

На рис. 4-7 показана структура кластера Kubernetes, где главный узел (виртуальная машина) управляет большинством операций по координации кластера, и вы можете развертывать контейнеры в остальных узлах, управляемых как единый пул с точки зрения приложения. Это позволяет расширять среду до тысяч и даже десятков тысяч контейнеров.

## <a name="development-environment-for-kubernetes"></a>Среда разработки для Kubernetes

Что касается среды разработки, [которую компания Docker анонсировала в июле 2018 г.](https://blog.docker.com/2018/07/kubernetes-is-now-available-in-docker-desktop-stable-channel/), Kubernetes также можно запускать на одном компьютере разработки (Windows 10 или macOS), просто установив [Docker Desktop](https://www.docker.com/community-edition). Позднее можно развернуть ее в облаке (AKS) для дальнейшего тестирования интеграции, как показано на рис. 4-8.

![Схема, показывающая Kubernetes на компьютере разработчика и развернутым в AKS.](./media/orchestrate-high-scalability-availability/kubernetes-development-environment.png)

**Рис. 4-8**. Выполнение Kubernetes на компьютере разработки и в облаке

## <a name="get-started-with-azure-kubernetes-service-aks"></a>Начало работы со службой Azure Kubernetes (AKS)

Чтобы начать использовать AKS, необходимо развернуть кластер AKS с помощью портала Azure или интерфейса командной строки. Дополнительные сведения о развертывании кластера Kubernetes в Azure см. в статье [Развертывание кластера службы Azure Kubernetes (AKS)](https://docs.microsoft.com/azure/aks/kubernetes-walkthrough-portal).

За программное обеспечение, устанавливаемое по умолчанию в составе службы AKS, плата не взимается. Все возможности по умолчанию реализуются с помощью ПО с открытым кодом. Служба AKS доступна для нескольких виртуальных машин в Azure. Плата взимается только за выбранные вычислительные операции, а также за другие используемые ресурсы базовой инфраструктуры, такие как хранилище и сеть. За саму службу AKS вы дополнительно не платите.

Дополнительные сведения о реализации развертывания в Kubernetes на основе `kubectl` и исходных `.yaml`-файлов см. в публикации [Setting eShopOnContainers up in AKS (Azure Kubernetes Service)](https://github.com/dotnet-architecture/eShopOnContainers/wiki/10.-Setting-the-solution-up-in-AKS-(Azure-Kubernetes-Service)) (Настройка eShopOnContainers в AKS (служба Azure Kubernetes)).

## <a name="deploy-with-helm-charts-into-kubernetes-clusters"></a>Развертывание с помощью чартов Helm в кластерах Kubernetes

При развертывании приложения в кластере Kubernetes можно использовать оригинальное средство CLI `kubectl.exe`, использующее файлы развертывания на основе собственного формата (`.yaml`-файлы), как уже упоминалось в предыдущем разделе. Однако для более сложных приложений Kubernetes, например при развертывании сложных приложений на основе микрослужб, мы рекомендуем использовать [Helm](https://helm.sh/).

Чарты Helm помогают осуществлять определение, управление версиями, установку, предоставление общего доступа, обновление или откат даже самых сложных приложений Kubernetes.

Более того, использование Helm рекомендуется, поскольку дополнительные среды Kubernetes в Azure, такие как [Azure Dev Spaces](https://docs.microsoft.com/azure/dev-spaces/azure-dev-spaces), также основаны на чартах Helm.

Поддержка Helm осуществляется фондом [Cloud Native Computing Foundation (CNCF)](https://www.cncf.io/) в сотрудничестве с корпорацией Майкрософт, Google, Bitnami и сообществом Helm.

Дополнительные сведения о реализации чартов Helm и Kubernetes см. в публикации [Using Helm Charts to deploy eShopOnContainers to AKS](https://github.com/dotnet-architecture/eShopOnContainers/wiki/10.1-Deploying-to-AKS-using-Helm-Charts) (Использование чартов Helm для развертывания eShopOnContainers в AKS).

## <a name="use-azure-dev-spaces-for-you-kubernetes-application-lifecycle"></a>Использование Azure Dev Spaces в жизненном цикле приложения Kubernetes

[Azure Dev Spaces](https://docs.microsoft.com/azure/dev-spaces/azure-dev-spaces) обеспечивает быструю итеративную среду разработки Kubernetes для команд разработчиков. Выполнив минимальную настройку компьютера разработки, можно итеративно запускать и отлаживать контейнеры непосредственно в службе Azure Kubernetes (AKS). Для разработки приложений Windows, Mac или Linux вы можете использовать привычные инструменты, такие как Visual Studio, Visual Studio Code или командная строка.

Как уже упоминалось, служба Azure Dev Spaces использует чарты Helm при развертывании контейнерных приложений.

Azure Dev Spaces помогает командам разработчиков работать более производительно в Kubernetes, так как позволяет быстро выполнять итерацию и отладку кода непосредственно в глобальном кластере Kubernetes в Azure просто с помощью Visual Studio 2017 или Visual Studio Code. Кластер Kubernetes в Azure — это общий управляемый кластер Kubernetes, поэтому ваша команда может работать совместно. Вы можете разрабатывать код в изолированном пространстве, а затем развернуть его в глобальном кластере и выполнить сквозное тестирование с другими компонентами без репликации или имитации зависимостей.

Как показано на рис. 4-9, наиболее характерная функция Azure Dev Spaces — возможность создания "пространств", которые могут выполняться, будучи интегрированными с остальной частью глобального развертывания в кластере.

![Схема, демонстрирующая использование нескольких областей в Azure Dev Spaces.](./media/orchestrate-high-scalability-availability/use-multiple-spaces-azure-dev.png)

**Рис. 4-9**. Использование нескольких пространств в Azure Dev Spaces

Azure Dev Spaces позволяет прозрачно комбинировать и сопоставлять рабочие микрослужбы с экземпляром контейнера разработки, упрощая тестирование новых версий. По сути, вы можете настроить общее пространство разработки в Azure. Каждый разработчик может сосредоточиться на своей части приложения и последовательно разрабатывать код до фиксации в пространстве разработки, которое уже содержит все остальные службы и облачные ресурсы, от которых зависят их сценарии. Зависимости всегда находятся в актуальном состоянии, и разработчики работают в среде, отражающей рабочую.

Azure Dev Spaces обеспечивает отдельное пространство, позволяющее работать изолированно, без риска помешать другим членам команды. Эта функция основана на префиксах URL-адресов. При использовании префикса пространства разработки в URL-адресе для запроса контейнера служба Azure Dev Spaces запускает специальную версию контейнера, развернутую для этого пространства, если она существует. В противном случае будет запускаться глобальная или объединенная версия.

Вы можете ознакомиться с [вики-страницей eShopOnContainers в Azure Dev Spaces](https://github.com/dotnet-architecture/eShopOnContainers/wiki/10.2-Using-Azure-Dev-Spaces-and-AKS), чтобы получить представление о практическом применении функции на конкретном примере.

Дополнительные сведения см. в статье [Коллективная разработка с помощью Azure Dev Spaces](https://docs.microsoft.com/azure/dev-spaces/team-development-netcore).

## <a name="additional-resources"></a>Дополнительные ресурсы

- **Начало работы со службой Azure Kubernetes (AKS)**  \
  <https://docs.microsoft.com/azure/aks/kubernetes-walkthrough-portal>

- **Azure Dev Spaces** \
  <https://docs.microsoft.com/azure/dev-spaces/azure-dev-spaces>

- **Kubernetes.** Официальный сайт. \
  <https://kubernetes.io/>

## <a name="using-azure-service-fabric"></a>Использование Azure Service Fabric

Платформа Azure Service Fabric создана в рамках перехода корпорации Майкрософт от предоставления "готовых" продуктов (зачастую монолитных) к предоставлению служб. При ее создании учитывался опыт разработки и эксплуатации масштабных служб, например базы данных SQL Azure, Azure Cosmos DB, служебной шины Azure или базы данных Кортаны. Она продолжала развиваться по мере внедрения во множестве служб. Важно отметить, что Service Fabric работает не только в среде Azure, но и в автономных развертываниях Windows Server.

Service Fabric помогает решить сложные проблемы при разработке и запуске службы, связанные с эффективным использованием ресурсов инфраструктуры, что позволяет командам решать бизнес-задачи, применяя подход на основе микрослужб.

Service Fabric предоставляет два масштабных решения, которые позволяют создавать приложения в рамках подхода на основе микрослужб.

- Платформа, которая предоставляет системные службы для развертывания, обновления, обнаружения и перезапуска служб, в которых произошел сбой, а также обнаружения служб, управления состоянием и мониторинга работоспособности. В сущности, эти системные службы позволяют задействовать множество характеристик микрослужб, описанных ранее.

- Программные интерфейсы (API) или платформы, позволяющие создавать приложения как микрослужбы: [Reliable Actors и Reliable Services](https://docs.microsoft.com/azure/service-fabric/service-fabric-choose-framework). Для создания микрослужбы можно использовать любой код. Однако программные интерфейсы не только упрощают задачу, но и обеспечивают более глубокую интеграцию с платформой. Так вы можете, например, получать информацию о работоспособности и данные диагностики, а также пользоваться преимуществами средств управления надежным состоянием.

Для Service Fabric не важен способ создания службы, поэтому вы можете использовать любую технологию. Но эта платформа предоставляет встроенные интерфейсы API, упрощающие создание микрослужб.

Как показано на рис. 4-10, вы можете создавать и запускать микрослужбы в Service Fabric как простые процессы или как контейнеры Docker. Микрослужбы на основе контейнеров можно также сочетать с микрослужбами на основе процессов в рамках одного кластера Service Fabric.

![Схема, показывающая сравнение кластеров Azure Service Fabric.](./media/orchestrate-high-scalability-availability/azure-service-fabric-cluster-types.png)

**Рис. 4-10**. Развертывание микрослужб в виде процессов или контейнеров в Azure Service Fabric

На первом изображении микрослужбы отображаются в виде процессов, где каждый узел выполняет один процесс для каждой микрослужбы. На втором изображении микрослужбы отображаются в виде контейнеров, где каждый узел выполняет Docker с несколькими контейнерами, по одному контейнеру на микрослужбу. В кластерах Service Fabric на основе узлов Linux и Windows могут выполняться соответственно контейнеры Docker Linux и контейнеры Windows.

Актуальные сведения о поддержке контейнеров в Azure Service Fabric см. в статье [Service Fabric и контейнеры](https://docs.microsoft.com/azure/service-fabric/service-fabric-containers-overview).

Service Fabric — это хороший пример платформы, которая позволяет определять логическую архитектуру (бизнес-микрослужбы или ограниченные контексты), отличную от физической реализации. Например, если вы реализуете в [Azure Service Fabric](https://docs.microsoft.com/azure/service-fabric/service-fabric-overview)[надежные службы с отслеживанием состояния](https://docs.microsoft.com/azure/service-fabric/service-fabric-reliable-services-introduction), которые представлены в следующем разделе [Микрослужбы с отслеживанием и без отслеживания состояния](#stateless-versus-stateful-microservices), бизнес-микрослужба будет состоять из нескольких физических служб.

Как показано на рис. 4-10, с точки зрения логической архитектуры микрослужб при создании надежной службы Service Fabric с отслеживанием состояния обычно требуется реализовать два уровня служб. Первый из них — это внутренняя надежная служба с отслеживанием состояния, которая обеспечивает работу нескольких разделов (каждый раздел является службой с отслеживанием состояния). Второй уровень — это внешняя служба или служба шлюза, которая отвечает за маршрутизацию и объединение данных в разных разделах или экземплярах служб с отслеживанием состояния. Служба шлюза также отвечает за взаимодействие с клиентом и выполнение повторных обращений к внутренней службе. Службой шлюза называется реализуемая вами пользовательская служба, но вы также можете использовать готовую [службу обратного прокси-сервера](https://docs.microsoft.com/azure/service-fabric/service-fabric-reverseproxy) Service Fabric.

![Схема, демонстрирующая несколько служб с отслеживанием состояния в контейнерах.](./media/orchestrate-high-scalability-availability/service-fabric-stateful-business-microservice.png)

**Рис. 4-11**. Бизнес-микрослужба с несколькими экземплярами службы с отслеживанием состояния и пользовательской внешней службой шлюза

В любом случае при использовании надежных служб Service Fabric с отслеживанием состояния у вас также есть логическая микрослужба или бизнес-микрослужба (ограниченный контекст), которая состоит из нескольких физических служб. Каждую из служб шлюза и служб раздела можно реализовать как службу веб-API ASP.NET, как показано на рис. 4-11. Service Fabric поддерживает несколько надежных служб с отслеживанием состояния в контейнерах.

В Service Fabric службы можно объединять в группы и развертывать как [приложение Service Fabric](https://docs.microsoft.com/azure/service-fabric/service-fabric-application-model), которое представляет собой модуль упаковки и развертывания для оркестратора или кластера. Таким образом, приложение Service Fabric можно сопоставить с автономной логической микрослужбой или ограниченным контекстом, чтобы развертывать службы в автономном режиме.

### <a name="service-fabric-and-containers"></a>Service Fabric и контейнеры

Вы также можете развертывать службы в образах контейнеров в кластере Service Fabric. Как показано на рис. 4-12, для каждой службы обычно имеется один контейнер.

![Схема, демонстрирующая один контейнер для каждой службы, передающий информацию в базу данных.](./media/orchestrate-high-scalability-availability/azure-service-fabric-business-microservice.png)

**Рис. 4-12**. Бизнес-микрослужба с несколькими службами (контейнерами) в Service Fabric

Приложение Service Fabric может выполнять несколько контейнеров, обращающихся к внешней базе данных, и весь набор будет логической границей бизнес-микрослужбы. Однако в Service Fabric также возможны так называемые "сцепленные" контейнеры (два контейнера, которые должны развертываться вместе в составе логической службы). Важным моментом является то, что бизнес-микрослужба — это логическая граница вокруг нескольких связанных элементов. Во многих случаях это может быть одна служба с единственной моделью данных, однако в других она может представлять собой несколько физических служб.

Имейте в виду, что вы можете сочетать службы в процессах и службы в контейнерах в рамках одного приложения Service Fabric, как показано на рис. 4-13.

![Схема, показывающая в одном приложении службы в процессах и в контейнерах.](./media/orchestrate-high-scalability-availability/business-microservice-mapped-to-service-fabric-application.png)

**Рис. 4-13**. Бизнес-микрослужба, сопоставленная с приложением Service Fabric с контейнерами и службами с отслеживанием состояния

Дополнительные сведения о поддержке контейнеров в Azure Service Fabric см. в статье [Service Fabric и контейнеры](https://docs.microsoft.com/azure/service-fabric/service-fabric-containers-overview).

## <a name="stateless-versus-stateful-microservices"></a>Микрослужбы с отслеживанием и без отслеживания состояния

Как уже упоминалось, у каждой микрослужбы (логического ограниченного контекста) должна быть своя модель предметной области (данные и логика). В случае микрослужб без отслеживания состояния базы данных будут внешними — с применением либо реляционных СУБД, таких как SQL Server, либо СУБД на основе NoSQL, например MongoDB или Azure Cosmos DB.

Однако сами службы могут поддерживать отслеживание состояния в Service Fabric, т. е. данные будут находиться в микрослужбе. Эти данные могут существовать не только на том же сервере, но и внутри процесса микрослужбы, в памяти, а также храниться на жестких дисках и реплицироваться в другие узлы. На рис. 4-14 показаны различные подходы.

![Схема, показывающая сравнение службы с отслеживанием состояния и без.](./media/orchestrate-high-scalability-availability/stateless-vs-stateful-microservices.png)

**Рис. 4-14**. Микрослужбы с отслеживанием и без отслеживания состояния

В службы без отслеживания состояния состояние (постоянное хранение, база данных) хранится за пределами микрослужбы. В службах с отслеживанием состояния состояние хранится внутри микрослужбы. Микрослужбы без отслеживания состояния — вполне допустимый подход, и он проще в реализации, чем микрослужбы с отслеживанием состояния, так как подобен традиционным и общеизвестным шаблонам. Но микрослужбы без отслеживания состояния вызывают задержку при взаимодействии процесса с источниками данных и вдобавок содержат больше "движущихся деталей", что осложняет повышение производительности за счет дополнительного кэша и очередей. Результат таков: вы можете получить более сложные архитектуры со слишком большим количеством уровней.

Напротив, [микрослужбы с отслеживанием состояния](https://docs.microsoft.com/azure/service-fabric/service-fabric-reliable-services-introduction#when-to-use-reliable-services-apis) могут показывать превосходство в сложных сценариях, поскольку при их использовании отсутствуют задержки во взаимодействии логики предметной области с данными. Интенсивная обработка данных, игровые серверы, базы данных как услуга и другие сценарии, требующие низкой задержки, — все они выигрывают от использования служб с отслеживанием состояния, обеспечивая локальное состояние для более быстрого доступа.

Службы без отслеживания состояния и с отслеживанием состояния дополняют друг друга. Например, как видно на диаграмме справа на рис. 4-14, службу с отслеживанием состояния можно разбить на несколько разделов. Для доступа к этим разделам может потребоваться служба без отслеживания состояния, выступающая в роли службы шлюза и способная обращаться к каждому разделу с помощью ключей разделов.

У служб с отслеживанием состояния есть недостатки. Они сложны для расширения. Функциональность, которая обычно реализовывалась бы в рамках внешней базы данных, должна обрабатывать такие операции, как репликация данных между микрослужбами с отслеживанием состояния и секционирование данных. Но это как раз одна из тех областей, где может помочь оркестратор, такой как [Azure Service Fabric](https://docs.microsoft.com/azure/service-fabric/service-fabric-reliable-services-platform-architecture) с [надежными службами с отслеживанием состояния](https://docs.microsoft.com/azure/service-fabric/service-fabric-reliable-services-introduction#when-to-use-reliable-services-apis). Он упрощает разработку и жизненный цикл микрослужб с отслеживанием состояния с помощью [API Reliable Services](https://docs.microsoft.com/azure/service-fabric/service-fabric-work-with-reliable-collections) и [Reliable Actors](https://docs.microsoft.com/azure/service-fabric/service-fabric-reliable-actors-introduction).

К другим платформам микрослужб, которые допускают использование служб с отслеживанием состояния и поддерживают шаблон субъекта, повышая отказоустойчивость и снижая задержки при взаимодействии между бизнес-логикой и данными, относятся Microsoft [Orleans](https://github.com/dotnet/orleans) от Microsoft Research и [Akka.NET](https://getakka.net/). В настоящее время идет работа над улучшением поддержки Docker в обеих этих платформах.

Учтите, что контейнеры Docker сами по себе не поддерживают отслеживание состояния. Чтобы реализовать службу с отслеживанием состояния, вам потребуется одна из высокоуровневых платформ, указанных выше.

## <a name="using-azure-service-fabric-mesh"></a>Использование сетки Azure Service Fabric

Сетка Azure Service Fabric — это полностью управляемая служба, которая позволяет разработчикам создавать и развертывать критически важные приложения без необходимости управлять инфраструктурой. Используйте сетку Service Fabric, чтобы создавать и запускать безопасные распределенные приложения для микрослужб, которые масштабируются по запросу.

Как показано на рис. 4-15, приложения, размещенные в сетке Service Fabric, выполняются и масштабируются так, что вам не приходится беспокоиться об инфраструктуре.

![Схема, показывающая развертывание из локального репозитория в Сетку Service Fabric.](media/orchestrate-high-scalability-availability/deploy-microservice-containers-apps-service-fabric-mesh.png)

**Рис. 4-15**. Развертывание приложения для микрослужб или контейнеров в сетке Service Fabric

На самом деле сетка Service Fabric состоит из кластеров из тысяч компьютеров. Все операции в кластере скрыты от разработчика. Нужно просто отправить контейнеры и указать необходимые ресурсы, требования к доступности и ограничения ресурсов. Сетка Service Fabric автоматически выделяет инфраструктуру, запрошенную развертыванием приложения, а также обрабатывает сбои инфраструктуры, гарантируя высокую доступность ваших приложений. Вы думаете только о работоспособности и скорости реагирования приложения, а не об инфраструктуре.

Дополнительные сведения см. в [документации по сетке Service Fabric](https://docs.microsoft.com/azure/service-fabric-mesh/).

## <a name="choosing-orchestrators-in-azure"></a>Выбор оркестраторов в Azure

В следующей таблице приведены рекомендации по выбору оркестратора в зависимости от рабочих нагрузок и фокуса операционной системы.

![Изображение таблицы сравнения Kubernetes и Service Fabric.](media/orchestrate-high-scalability-availability/orchestrator-selection-azure-guidance.png)

**Рис. 4-16**. Выбор оркестратора в руководстве по Azure

>[!div class="step-by-step"]
>[Назад](soa-applications.md)
>[Вперед](deploy-azure-kubernetes-service.md)
