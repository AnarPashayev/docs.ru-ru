---
title: Взаимодействие с внешними клиентами
description: Узнайте, как клиентские клиенты взаимодействуют с системами, собственными в облаке
author: robvet
ms.date: 09/08/2019
ms.openlocfilehash: a488337b48e30b99bfcc9894a780350f32af864f
ms.sourcegitcommit: 559fcfbe4871636494870a8b716bf7325df34ac5
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 10/30/2019
ms.locfileid: "73841795"
---
# <a name="front-end-client-communication"></a>Взаимодействие с внешними клиентами

[!INCLUDE [book-preview](../../../includes/book-preview.md)]

В собственной облачной системе клиентские клиенты (мобильные, веб-приложения и настольные) должны иметь канал связи для взаимодействия с независимыми микрослужбами.  

Что такое варианты?

Для простоты клиент клиентского интерфейса может *напрямую взаимодействовать* с внутренними микрослужбами, как показано на рисунке 4-2.

![Прямой обмен данными между клиентом и службой](./media/direct-client-to-service-communication.png)

**Рис. 4-2.** Прямой обмен данными между клиентом и службой

При таком подходе каждая микрослужба имеет общедоступную конечную точку, доступную клиентам клиентского доступа. В рабочей среде подсистема балансировки нагрузки помещается перед микрослужбами, поэтому трафик передается пропорционально.

Простота взаимодействия с клиентами, хотя и проста в реализации, может быть приемлемым только для простых приложений микрослужб. Этот шаблон тесно связывает клиентские интерфейсы с основными серверными службами, открывая дверцу для ряда проблем, в том числе:

- Уязвимости клиента для рефакторинга серверной службы.
- Более широкая контактная зона в качестве основных серверных служб предоставляется напрямую.
- Дублирование перекрестных проблем в каждой микрослужбе.
- Чрезмерно сложный клиентский код — клиенты должны отследить несколько конечных точек и отреагировать на сбои в устойчивом виде.

Вместо этого широко принятый шаблон проектирования в облаке — реализация [службы шлюза API](../microservices/architect-microservice-container-applications/direct-client-to-microservice-communication-versus-the-api-gateway-pattern.md) между внешними приложениями и серверными службами. Шаблон показан на рисунке 4-3.

![Шаблон шлюза API](./media/api-gateway-pattern.png)

**Рис. 4-3.** Шаблон шлюза API

На предыдущем рисунке обратите внимание на то, как служба шлюза API абстрагирует основные микрослужбы ядра серверной части. Реализованный как веб-API, он выступает в качестве *обратных прокси-серверов*и направляет входящий трафик во внутренние микрослужбы.

Шлюз изолирует клиент от внутреннего секционирования и рефакторинга службы. При изменении серверной службы она размещается в шлюзе без нарушения работы клиента. Это также первая строка обороны для перекрестных задач, таких как идентификация, кэширование, устойчивость, отслеживание и регулирование. Многие из этих проблем могут быть отключены от серверных основных служб до шлюза, что упрощает работу серверных служб.

Необходимо соблюдать осторожность, чтобы упростить и ускорить работу шлюза API. Как правило, Бизнес-логика хранится вне шлюза. Сложные риски шлюза становятся узким местом и в конечном итоге создают сам Монолит. Более крупные системы часто предоставляют несколько шлюзов API, сегментированных по типу клиента (Mobile, Web, Desktop) или серверной функциональности. Шаблон [Серверная часть для внешних интерфейсов](https://docs.microsoft.com/azure/architecture/patterns/backends-for-frontends) обеспечивает направление реализации нескольких шлюзов. Шаблон показан на рисунке 4-4.

![Шаблон шлюза API](./media/backend-for-frontend-pattern.png)

**Рис. 4-4.** Серверная часть для внешнего шаблона

Обратите внимание, что на предыдущем рисунке показано, как входящий трафик отправляется в конкретный шлюз API на основе типа клиента: веб-, мобильного или классического приложения. Этот подход имеет смысл, так как возможности каждого устройства значительно отличаются в пределах форм фактора, производительности и ограничений на отображение. Обычно мобильные приложения предоставляют меньше функциональных возможностей, чем браузер или классические приложения. Каждый шлюз можно оптимизировать в соответствии с возможностями и функциями соответствующего устройства.

Для начала можно создать собственную службу шлюза API. Быстрый поиск в GitHub предоставит множество примеров. Однако доступно несколько платформ и продуктов для коммерческих шлюзов.

## <a name="ocelot-gateway"></a>Шлюз Оцелот

Для простых облачных приложений .NET вы можете использовать [шлюз Оцелот](https://github.com/ThreeMammals/Ocelot). Оцелот — это шлюз API с открытым исходным кодом, созданный для микрослужб .NET, которым требуется единая точка входа в систему. Это упрощенный, быстрый и масштабируемый.

Как и любой другой шлюз API, его основная функциональность заключается в пересылке входящих HTTP-запросов к подчиненным службам. Кроме того, он поддерживает широкий спектр возможностей, которые можно настроить в конвейере по промежуточного слоя .NET Core. Его набор функций представлен в следующей таблице.

|Функции Оцелот  | |
| :-------- | :-------- |
| Маршрутизация | Проверка подлинности |
| Агрегирование запросов | Авторизация |
| Обнаружение служб (с помощью Consul и Еурека) | Регулирование |
| Балансировка нагрузки | Ведение журнала, трассировка |
| Кэширование | Преобразование заголовков/строки запроса |
| Сквозная корреляция | Настраиваемое по промежуточного слоя |
| Качество обслуживания | Политики повтора |

Каждый шлюз Оцелот определяет вышестоящий и нисходящий адреса и настраиваемые функции в файле конфигурации JSON. Клиент отправляет HTTP-запрос шлюзу Оцелот. После получения Оцелот передает объект HttpRequest через его конвейер, манипулирующий этим объектом, в состояние, заданное его конфигурацией. В конце конвейера Оцелот создает новый Хттпреспонсеобжект и передает его в подчиненную службу. Для ответа Оцелот выполняет обратный конвейер, отправляя ответ обратно клиенту.

Оцелот доступен в виде пакета NuGet. Он предназначен для NET Standard 2,0, что делает его совместимым с .NET Core 2.0 и .NET Framework 4.6.1 + Runtime. Оцелот интегрируется с любым компонентом, который говорит по протоколу HTTP и работает на платформах, поддерживаемых .NET Core: Linux, macOS и Windows. Оцелот является расширяемой и поддерживает многие современные платформы, включая контейнеры DOCKER, службы Kubernetes Azure или другие общедоступные облака.  Оцелот интегрируется с такими пакетами с открытым исходным кодом, как [Consul](https://www.consul.io), [Графкл](https://graphql.org)и [Еурека](https://github.com/Netflix/eureka)Netflix.

Рассмотрим Оцелот для простых облачных приложений, не требующих обширного набора функций для коммерческого шлюза API.

## <a name="azure-application-gateway"></a>Шлюз приложений Azure

Для простых требований к шлюзу вы можете использовать [шлюз приложений Azure](https://docs.microsoft.com/azure/application-gateway/overview). Доступно в виде [службы Azure PaaS](https://azure.microsoft.com/overview/what-is-paas/), она включает основные функции шлюза, такие как маршрутизация URL-адресов, завершение SSL и брандмауэр веб-приложения. Служба поддерживает возможности [балансировки нагрузки уровня 7](https://www.nginx.com/resources/glossary/layer-7-load-balancing/) . С помощью уровня 7 можно маршрутизировать запросы на основе фактического содержимого HTTP-сообщения, а не только низкого уровня сетевых пакетов TCP.

В этой книге мы пропаганды облачные системы в [Kubernetes](https://www.infoworld.com/article/3268073/what-is-kubernetes-your-next-application-platform.html). Контейнер Orchestrator, Kubernetes автоматизирует развертывание, масштабирование и эксплуатационные проблемы в контейнерных рабочих нагрузках. Шлюз приложений Azure можно настроить в качестве шлюза API для кластера [службы Kubernetes Azure](https://azure.microsoft.com/services/kubernetes-service/) .

Контроллер входящего трафика [шлюза приложений](https://azure.github.io/application-gateway-kubernetes-ingress/) позволяет шлюзу приложений Azure работать непосредственно со [службой Azure Kubernetes](https://azure.microsoft.com/services/kubernetes-service/). На рис. 4,5 показана архитектура.

![Контроллер входящего трафика шлюза приложений](./media/application-gateway-ingress-controller.png)

**Рис. 4-5.** Контроллер входящего трафика шлюза приложений

Kubernetes включает встроенную функцию, которая поддерживает балансировку нагрузки HTTP (уровень 7) [, называемую](https://kubernetes.io/docs/concepts/services-networking/ingress/)входящими. Входящий объект определяет набор правил, определяющих, как экземпляры микрослужб внутри AKS могут быть доступны внешнему миру. На предыдущем рисунке контроллер входящего трафика интерпретирует правила входящего трафика, настроенные для кластера, и автоматически настраивает шлюз приложений Azure. На основе этих правил шлюз приложений направляет трафик в микрослужбы, работающие в AKS. Входной контроллер прослушивает изменения в правилах входящих данных и вносит соответствующие изменения в шлюз приложений Azure.

## <a name="azure-api-management"></a>Управление API Azure

Для средних и крупномасштабных облачных систем вы можете использовать службу [управления API Azure](https://azure.microsoft.com/services/api-management/). Это облачная служба, которая не только решает ваши потребности в шлюзе API, но и предоставляет полнофункциональную среду разработки и администрирования. Управление API показано на рисунке 4-6.

![Управление API Azure](./media/azure-api-management.png)

**Рис. 4-6.** Управление API Azure

Для начала служба управления API предоставляет сервер шлюза, который обеспечивает управляемый доступ к внутренним службам на основе настраиваемых правил и политик. Эти службы могут находиться в облаке Azure, в локальном центре обработки данных или в других общедоступных облаках. Ключи API и токены JWT определяют, кто может делать. Весь трафик заносится в журнал для аналитических целей.

Для разработчиков служба управления API предлагает портал разработчика, который предоставляет доступ к службам, документации и примерам кода для их вызова. Разработчики могут использовать API Swagger и Open для проверки конечных точек службы и анализа их использования. Служба работает в основных платформах разработки: .NET, Java, Golang и других.

Портал издателя предоставляет панель мониторинга управления, в которой администраторы предоставляют интерфейсы API и управляют их поведением. Доступ к службе можно предоставить, отслеживать работоспособность службы и собирать данные телеметрии службы. Администраторы применяют *политики* к каждой конечной точке, чтобы влиять на их поведение. [Политики](https://docs.microsoft.com/azure/api-management/api-management-howto-policies) — это предварительно построенные инструкции, которые последовательно выполняются для каждого вызова службы.  Политики настраиваются для входящего вызова, исходящего вызова или вызова при возникновении ошибки. Политики могут применяться к различным областям служб, что позволяет реализовать детерминированное упорядочение при объединении политик. Продукт поставляется с большим количеством предварительно созданных [политик](https://docs.microsoft.com/azure/api-management/api-management-policies).

Ниже приведены примеры того, как политики могут повлиять на поведение облачных служб.  

- Ограничьте доступ к службе.
- Принудительная проверка подлинности.  
- При необходимости регулировать вызовы из одного источника.
- Включите кэширование.
- Блокировать вызовы с конкретных IP-адресов.
- Управление потоком службы.
- Преобразование запросов из SOAP в другие форматы данных, например из XML в JSON.

Служба управления API Azure может предоставлять серверные службы, размещенные в любом месте — в облаке или в центре обработки данных. Для устаревших служб, которые могут быть предоставлены в собственных системах в облаке, они поддерживают API-интерфейсы RESTFUL и SOAP. Даже другие службы Azure можно предоставлять через службу управления API. Вы можете разместить управляемый API поверх службы резервного копирования Azure, такой как [служебная шина Azure](https://azure.microsoft.com/services/service-bus/) или [Azure Logic Apps](https://azure.microsoft.com/services/logic-apps/). Служба управления API Azure не включает встроенную поддержку балансировки нагрузки и должна использоваться в сочетании со службой балансировки нагрузки.

Управление API Azure доступно на [четырех разных уровнях](https://azure.microsoft.com/pricing/details/api-management/):

- Разработчик
- Basic
- Стандартный
- Премиум

Уровень разработчика предназначен для непроизводственных рабочих нагрузок и оценки. Другие уровни предлагают более мощные возможности, функции и более высокие соглашения об уровне обслуживания (SLA). Уровень "Премиум" обеспечивает [виртуальную сеть Azure](https://docs.microsoft.com/azure/virtual-network/virtual-networks-overview) и [поддержку нескольких регионов](https://docs.microsoft.com/azure/api-management/api-management-howto-deploy-multi-region). Все уровни имеют фиксированную цену за час.

Недавно корпорация Майкрософт объявила о том, что для управления API Azure не использовался [сервер управления API](https://azure.microsoft.com/blog/announcing-azure-api-management-for-serverless-architectures/) . Эта служба, называемая *ценовой категорией потребления*, представляет собой вариант управления API, разработанный на основе бессерверной вычислительной модели. В отличие от ранее показанных ценовых категорий, уровень потребления предоставляет возможность мгновенной подготовки и оплаты за действие.

Он включает функции шлюза API для следующих вариантов использования:

- Микрослужбы, реализованные с использованием бессерверных технологий, таких как [функции Azure](https://docs.microsoft.com/azure/azure-functions/functions-overview) и [Azure Logic Apps](https://azure.microsoft.com/services/logic-apps/).
- Резервные ресурсы службы Azure, такие как очереди и разделы служебной шины, служба хранилища Azure и другие.
- Микрослужбы, в которых трафик имеет случайные пиковые пики, но остается в большей части времени.

Уровень потребления использует те же базовые компоненты управления API службы, но использует совершенно другую архитектуру, основанную на динамически выделяемых ресурсах. Он идеально соответствует модели бессерверных вычислений:

- Нет инфраструктуры для управления.
- Нет бездействующей емкости.
- Высокий уровень доступности.
- Автоматическое масштабирование.
- Стоимость зависит от фактического использования.
  
Новая категория потребления — отличный вариант для собственных облачных систем, которые предоставляют бессерверные ресурсы в качестве API-интерфейсов.

> На момент написания статьи уровень потребления находится в предварительной версии в облаке Azure.

## <a name="real-time-communication"></a>Обмен данными в режиме реального времени

Обмен данными в режиме реального времени или Push-уведомления — это еще один вариант для интерфейсных приложений, взаимодействующих с внутренними облачными системами по протоколу HTTP. Такие приложения, как финансовые тикеры, Интернет-учреждения, игры и обновления хода выполнения заданий, занимают мгновенные ответы в режиме реального времени от серверной части. При обычной связи по протоколу HTTP клиенту не удается получить сведения о доступности новых данных. Клиент должен постоянно *опрашивать* или отправлять запросы на сервер. При обмене данными в *режиме реального времени* сервер может в любое время отправлять новые данные клиенту.

Системы в режиме реального времени часто характеризуются потоками данных с высокой частотой и большим числом параллельных клиентских подключений. Ручная реализация подключения в режиме реального времени может быстро стать сложной и требовать нетривиальные инфраструктуры для обеспечения масштабируемости и надежного обмена сообщениями между подключенными клиентами. Вы можете управлять экземпляром кэша Redis для Azure и набором подсистем балансировки нагрузки, настроенных с прикрепленными сеансами для сходства клиентов.

[Служба Azure SignalR](https://azure.microsoft.com/services/signalr-service/) — это полностью управляемая служба Azure, которая упрощает обмен данными в облаке с собственными приложениями в режиме реального времени. Сведения о технической реализации, такие как подготовка ресурсов, масштабирование и постоянные подключения, являются абстрактными. Они обрабатываются с помощью соглашения об уровне обслуживания 99,9%. Вы сосредоточены на функциях приложения, а не на инфраструктуре.

После включения облачная служба HTTP может отправлять обновления содержимого непосредственно подключенным клиентам, включая браузер, мобильные и классические приложения. Клиенты обновляются без необходимости опрашивать сервер. Azure SignalR абстрагирует технологии транспорта, которые создают связь в режиме реального времени, включая WebSocket, серверные события и длительный опрос. Разработчики сосредоточены на отправке сообщений всем или конкретным подмножествам подключенных клиентов.

На рис. 4-7 показан набор HTTP-клиентов, подключающихся к облачному приложению с включенным сигнальным приложением Azure SignalR.

![Azure SignalR](./media/azure-signalr-service.png)

**Рис. 4-7.** Azure SignalR

Еще одним преимуществом службы Azure SignalR является реализация безсерверных облачных служб. Возможно, ваш код выполняется по запросу с помощью триггеров функций Azure. Этот сценарий может быть непростым, поскольку код не поддерживает длинные соединения с клиентами. Служба Azure SignalR может справиться с этой ситуацией, так как служба уже управляет подключениями.

Служба Azure SignalR тесно интегрируется с другими службами Azure, такими как база данных SQL Azure, служебная шина или кэш Redis, что открывает множество возможностей для собственных облачных приложений.

>[!div class="step-by-step"]
>[Назад](communication-patterns.md)
>[Вперед](service-to-service-communication.md)
