---
title: Взаимодействие с внешними клиентами
description: Узнайте, как клиенты-фронтовые клиенты общаются с облачными системами
author: robvet
ms.date: 09/08/2019
ms.openlocfilehash: af26873381509df7807db6ecb37a7d73669adb37
ms.sourcegitcommit: e3cbf26d67f7e9286c7108a2752804050762d02d
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/09/2020
ms.locfileid: "80989081"
---
# <a name="front-end-client-communication"></a>Взаимодействие с внешними клиентами

[!INCLUDE [book-preview](../../../includes/book-preview.md)]

В облачной системе фронт-клиенты (мобильные, веб- и настольные приложения) требуют канала связи для взаимодействия с независимыми микрослужбами бэк-энда.  

Какие есть варианты?

Чтобы все было просто, клиент-фронт-энд мог *напрямую общаться* с микрослужбами бэк-энда, показанными на рисунке 4-2.

![Прямой клиент к обслуживанию связи](./media/direct-client-to-service-communication.png)

**Рисунок 4-2.** Прямой клиент к обслуживанию связи

При таком подходе каждая микроуслуга имеет публичную конечную точку, доступкую для фронтовых клиентов. В производственной среде вы размещаете балансомер нагрузки перед микрослужбами, пропорционально перемещая трафик.

Хотя это просто в реализации, прямая связь с клиентами будет приемлема только для простых приложений микрослужбы. Эта модель плотно пары фронт-конец клиентов к основным бэк-энд услуг, открывая дверь для ряда проблем, в том числе:

- Предчувствие клиента к рефакторингу бэк-энда.
- Более широкая поверхность атаки, поскольку основные службы бэк-энда непосредственно подвергаются воздействию.
- Дублирование кросс-резки проблем в каждой микрослужбе.
- Чрезмерно сложный код клиента - клиенты должны отслеживать несколько конечных точек и обрабатывать сбои устойчивым способом.

Вместо этого широко принята модель облачного дизайна заключается в внедрении [службы шлюза API](../microservices/architect-microservice-container-applications/direct-client-to-microservice-communication-versus-the-api-gateway-pattern.md) между фронт-энд-приложениями и бэк-энд-сервисами. Рисунок показан на рисунке 4-3.

![Шаблон шлюза API](./media/api-gateway-pattern.png)

**Рисунок 4-3.** Шаблон шлюза API

На предыдущем рисунке обратите внимание, как служба API Gateway абстрагирует микрослужбы ядра бэк-энда. Реализованный как веб-API, он действует как *обратный прокси,* перенаправив входящий трафик во внутренние микрослужбы.

Шлюз изолирует клиента от раздела и рефакторинга внутренней службы. Если вы измените бэк-энд службы, вы разместить для него в шлюз, не нарушая клиента. Это также ваша первая линия обороны для перекрестных проблем, таких как идентичность, кэширование, устойчивость, измерение и регулирование. Многие из этих проблем, связанных с перекрестным сокращением, могут быть отключены от основных служб бэк-энда до шлюза, что упрощает обслуживание бэк-энда.

Необходимо позаботиться о том, чтобы API Gateway был простым и быстрым. Как правило, бизнес-логика не доявляется до шлюза. Сложный шлюз рискует стать узким местом и, в конечном итоге, самим монолитом. Большие системы часто разоблачают несколько aPI шлюзов, сегментированных по типу клиента (мобильный, веб, настольный компьютер) или бэк-энд функциональности. Шаблон [Backend для Frontends](https://docs.microsoft.com/azure/architecture/patterns/backends-for-frontends) обеспечивает направление для реализации нескольких шлюзов. Рисунок показан на рисунке 4-4.

![Шаблон шлюза API](./media/backend-for-frontend-pattern.png)

**Рисунок 4-4.** Бэкэнд для шаблона переднего энда

Обратите внимание на предыдущую цифру, как входящий трафик отправляется на определенный шлюз API - на основе типа клиента: веб, мобильный или настольный приложение. Такой подход имеет смысл, поскольку возможности каждого устройства значительно различаются по форм-фактору, производительности и ограничениям отображения. Обычно мобильные приложения предоставляют меньшую функциональность, чем браузер или настольные приложения. Каждый шлюз может быть оптимизирован в соответствии с возможностями и функциональностью соответствующего устройства.

Для начала можно создать собственный сервис API Gateway. Быстрый поиск GitHub даст много примеров. Тем не менее, есть несколько рамок и коммерческих продуктов шлюза доступны.

## <a name="ocelot-gateway"></a>Оселет Шлюз

Для простых облачных приложений .NET можно рассмотреть [ворота Ocelot.](https://github.com/ThreeMammals/Ocelot) Ocelot — это aPI-шлюз с открытым исходным кодом, созданный для микрослужб .NET, требующих единой точки входа в их систему. Легкий, быстрый, масштабируемый.

Как и любой API Gateway, его основная функциональность заключается в переадресовании входящих запросов HTTP в службы ниже по течению. Кроме того, он поддерживает широкий спектр возможностей, настраиваемых в промежуточном конвейере .NET Core. Его набор функций представлен в следующей таблице.

|Особенности Оселета  | |
| :-------- | :-------- |
| Маршрутизация | Аутентификация |
| Агрегация запроса | Авторизация |
| Сервис Новерис (с консулом и Эврикой) | Регулирование |
| Балансировка нагрузки | Регистрация, отслеживание |
| Caching | Заголовки/Преобразование строки в керах |
| Корреляция Пасс-через | Пользовательские Middleware |
| Качество обслуживания | Политика повторного отработки |

Каждый шлюз Ocelot определяет адреса вверх по течению и вниз по течению и настраиваемые функции в файле конфигурации JSON. Клиент отправляет запрос HTTP на шлюз Ocelot. После получения Ocelot передает объект HttpRequest через его конвейер, манипулируя им в состояние, указанное его конфигурацией. В конце конвейера Ocelot создает новый HTTPResponseObject и передает его службе ниже по течению. Для ответа Ocelot меняет конвейер, отправляя ответ обратно клиенту.

Ocelot доступен в виде пакета NuGet. Он нацелен на стандарт NET 2.0, что делает его совместимым как с .NET Core 2.0,и .NET Framework 4.6.1 .1 .1 "время выполнения. Ocelot интегрируется со всем, что говорит HTTP и работает на платформах, которые поддерживает .NET Core: Linux, macOS и Windows. Ocelot является расширяемым и поддерживает многие современные платформы, включая контейнеры Docker, услуги Azure Kubernetes или другие общедоступные облака.  Ocelot интегрируется с открытым исходным кодом пакеты, как [консул](https://www.consul.io), [Графл](https://graphql.org), и [Netflix в Эврика](https://github.com/Netflix/eureka).

Рассмотрим Ocelot для простых облачных приложений, которые не требуют богатого набора функций коммерческого шлюза API.

## <a name="azure-application-gateway"></a>Шлюз приложений Azure

Для простых требований к шлюзу можно рассмотреть [шлюз приложений Azure.](https://docs.microsoft.com/azure/application-gateway/overview) Доступный как служба Azure [PaaS,](https://azure.microsoft.com/overview/what-is-paas/)он включает в себя основные функции шлюза, такие как разгром URL, прекращение SSL и брандмауэр Web Application Firewall. Служба поддерживает [возможности балансировки нагрузки layer-7.](https://www.nginx.com/resources/glossary/layer-7-load-balancing/) С помощью уровня 7 можно направлять запросы на основе фактического содержимого сообщения HTTP, а не только низкоуровневых сетевых пакетов TCP.

На протяжении всей этой книги, мы евангелизации хостинг облачных систем родной в [Kubernetes](https://www.infoworld.com/article/3268073/what-is-kubernetes-your-next-application-platform.html). Контейнерный оркестратор Kubernetes автоматизирует развертывание, масштабирование и эксплуатационные проблемы контейнерных нагрузок. Шлюз приложений Azure можно настроить как шлюз API для кластера [служб Azure Kubernetes.](https://azure.microsoft.com/services/kubernetes-service/)

[Контроллер входа в приложение](https://azure.github.io/application-gateway-kubernetes-ingress/) позволяет Azure Application Gateway работать непосредственно с [сервисом Azure Kubernetes.](https://azure.microsoft.com/services/kubernetes-service/) На рисунке 4.5 показана архитектура.

![Контроллер входящего трафика Шлюза приложений](./media/application-gateway-ingress-controller.png)

**Рисунок 4-5.** Контроллер входящего трафика Шлюза приложений

Kubernetes включает в себя встроенную функцию, которая поддерживает балансирование нагрузки HTTP (Level 7), называемую [Ingress.](https://kubernetes.io/docs/concepts/services-networking/ingress/) Ingress определяет набор правил для того, как экземпляры микрослужб внутри AKS могут подвергаться воздействию внешнего мира. На предыдущем изображении контроллер входа интерпретирует правила входа, настроенные для кластера, и автоматически настраивает шлюз приложения Azure. Основываясь на этих правилах, портал приложений направляет трафик в микрослужбы, работающие внутри AKS. Контроллер входа прислушивается к изменениям правил входа и вносит соответствующие изменения в шлюз приложения Azure.

## <a name="azure-api-management"></a>Cлужба управления Azure API 

Для систем, нативных от умеренной и крупномасштабной, можно рассмотреть [Управление API Azure.](https://azure.microsoft.com/services/api-management/) Это облачный сервис, который не только решает ваши потребности API Gateway, но и обеспечивает полнофункциональный разработчик и административный опыт. Управление API показано на рисунке 4-6.

![Cлужба управления Azure API ](./media/azure-api-management.png)

**Рисунок 4-6.** Cлужба управления Azure API 

Для начала API Management предоставляет сервер шлюза, который позволяет осуществлять контролируемый доступ к бэк-энд-сервисам на основе настраиваемых правил и политик. Эти службы могут быть в облаке Azure, центре обработки данных на prem или в других общедоступных облаках. Ключи API и токены JWT определяют, кто может что делать. Весь трафик регистрируется для аналитических целей.

Для разработчиков API Management предлагает портал разработчика, предоставляющий доступ к услугам, документации и примерному коду для их отзыва. Разработчики могут использовать AWAGger/Open API для проверки конечных точек обслуживания и анализа их использования. Сервис работает на основных платформах разработки: .NET, Java, Golang и других.

Портал издателя предоставляет панель мониторинга управления, где администраторы разоблачают AI и управляют их поведением. Доступ к услугам может быть предоставлен, служба здравоохранения контролируется, и телеметрия службы собраны. Администраторы применяют *политики* к каждой конечной точке, чтобы повлиять на поведение. Политики — это заранее построенные операторы, которые выполняются последовательно для каждого вызова [службы.](https://docs.microsoft.com/azure/api-management/api-management-howto-policies)  Политики настраиваются для входящего вызова, исходящего вызова или вызываются при ошибке. Политики могут применяться в различных областях служб, с тем чтобы детерминированный порядок при объединении политик. Продукт поставляется с большим количеством заранее [построенных полисов.](https://docs.microsoft.com/azure/api-management/api-management-policies)

Вот примеры того, как политики могут повлиять на поведение ваших облачных служб:  

- Ограничьте доступ к службе.
- Обеспечить аутентификацию.  
- При необходимости звонят из одного источника.
- Включите кэширование.
- Блокировка звонков с определенных IP-адресов.
- Контролируйте поток службы.
- Преобразование запросов от SOAP до REST или между различными форматами данных, например, от XML до JSON.

Управление API Azure может разоблачать бэк-энд-сервисы, размещенные в любом месте — в облаке или в центре обработки данных. Для устаревших служб, которые вы можете предоставить в облачных системах, он поддерживает как REST, так и SOAP AIS. Даже другие службы Azure могут быть раскрыты с помощью Управления API. Можно разместить управляемый API поверх службы поддержки Azure, [например, Azure Service Bus](https://azure.microsoft.com/services/service-bus/) или [Azure Logic Apps.](https://azure.microsoft.com/services/logic-apps/) Управление API Azure не включает встроенную поддержку балансировки нагрузки и должно использоваться в сочетании с службой балансировки нагрузки.

Управление API Azure доступно на [четырех уровнях:](https://azure.microsoft.com/pricing/details/api-management/)

- Разработчик
- Basic
- Standard
- Premium

Уровень разработчика предназначен для непроизводственных рабочих нагрузок и оценки. Другие уровни предлагают постепенно больше мощности, возможностей и более высоких соглашений уровня обслуживания (SLAs). Уровень Premium предоставляет [виртуальную сеть Azure](https://docs.microsoft.com/azure/virtual-network/virtual-networks-overview) и [многорегионную поддержку.](https://docs.microsoft.com/azure/api-management/api-management-howto-deploy-multi-region) Все уровни имеют фиксированную цену за час.

Недавно корпорация Майкрософт объявила о [безсерверном уровне Управления](https://azure.microsoft.com/blog/announcing-azure-api-management-for-serverless-architectures/) API для Azure API Management. Называется как *уровень цен на потребление,* услуга является вариантом Управления API, разработанного вокруг модели без серверов вычислений. В отличие от ранее показанных «предварительно распределенных» уровней ценообразования, уровень потребления обеспечивает мгновенное обеспечение и ценообразование с оплатой за действие.

Он позволяет функции API Gateway для следующих случаев использования:

- Микросервисы внедряются с использованием технологий без серверов, таких как [Azure Functions](https://docs.microsoft.com/azure/azure-functions/functions-overview) и [Azure Logic Apps.](https://azure.microsoft.com/services/logic-apps/)
- Ресурсы поддержки службы Azure, такие как очереди и темы service Bus, хранилище Azure и другие.
- Микроуслуги, где трафик имеет случайные большие всплески, но остается низким большую часть времени.

Уровень потребления использует те же базовые компоненты API Management, но использует совершенно другую архитектуру, основанную на динамически выделенных ресурсах. Он идеально соответствует модели без серверов:

- Нет инфраструктуры для управления.
- Нет простоя.
- Высокая доступность.
- Автоматическое масштабирование.
- Стоимость основана на фактическом использовании.
  
Новый уровень потребления является отличным выбором для облачных систем, которые предоставляют бессерверные ресурсы в виде AA.

> На момент написания статьи уровень потребления находится в предварительном просмотре в облаке Azure.

## <a name="real-time-communication"></a>связь в режиме реального времени;

Связь в режиме реального времени или push — это еще один вариант для фронтовых приложений, которые общаются с облачными системами по http. Приложения, такие как финансовые тикеры, онлайн-образование, игры и обновления хода работы, требуют мгновенного ответа в режиме реального времени. При нормальной коммуникации HTTP клиент не может знать, когда доступны новые данные. Клиент должен постоянно *осваивать* или отправлять запросы на сервер. Благодаря общению в *режиме реального времени* сервер может в любое время передать новые данные клиенту.

Системы реального времени часто характеризуются высокочастотными потоками данных и большим количеством одновременных клиентских подключений. Ручное внедрение подключения в режиме реального времени может быстро стать сложным, что требует нетривиальной инфраструктуры для обеспечения масштабируемости и надежного обмена сообщениями для подключенных клиентов. Можно было бы управлять экземпляром Кэша Azure Redis и набором балансироворов нагрузки, настроенных с липкими сеансами для сродства клиента.

[Служба Azure SignalR](https://azure.microsoft.com/services/signalr-service/) — это полностью управляемая служба Azure, которая упрощает общение в режиме реального времени для ваших облачных приложений. Детали технической реализации, такие как подготовка емкости, масштабирование и постоянные соединения, абстрагируются. Они обрабатываются для вас с 99,9% сервисного соглашения. Вы фокусируетесь на функциях приложения, а не на инфраструктуре сантехники.

После включения облачный сервис HTTP может нажимать обновления содержимого непосредственно на подключенных клиентов, включая браузерные, мобильные и настольные приложения. Клиенты обновляются без необходимости опроса сервера. Azure SignalR абстрагирует транспортные технологии, создающие подключение в режиме реального времени, включая WebSockets, события сервера и длинные опросы. Разработчики сосредотачиваются на отправке сообщений всем или конкретным подмнозам подключенных клиентов.

На рисунке 4-7 показан набор клиентов HTTP, подключенных к облачному приложению с включенным Azure SignalR.

![Azure SignalR](./media/azure-signalr-service.png)

**Рисунок 4-7.** Azure SignalR

Еще одним преимуществом сервиса Azure SignalR является реализация облачных сервисов Serverless. Возможно, ваш код выполняется по требованию с помощью триггеров Azure Functions. Этот сценарий может быть сложным, потому что ваш код не поддерживает длительные связи с клиентами. Служба Azure SignalR может справиться с этой ситуацией, так как она автоматически управляет подключениями.

Служба Azure SignalR тесно интегрируется с другими службами Azure, такими как база данных Azure S'L, Service Bus или Redis Cache, открывая множество возможностей для ваших облачных приложений.

>[!div class="step-by-step"]
>[Назад](communication-patterns.md)
>[Вперед](service-to-service-communication.md)
