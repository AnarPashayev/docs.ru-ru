---
title: Определение ориентации на облако
description: Узнайте о основополагающих столпах, которые являются основой для облачных систем
author: robvet
ms.date: 08/20/2019
ms.openlocfilehash: 27191a67b2964ac2e1636a4d7dc55d5314b78439
ms.sourcegitcommit: 7588136e355e10cbc2582f389c90c127363c02a5
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/14/2020
ms.locfileid: "79401739"
---
# <a name="defining-cloud-native"></a>Определение родного облака

[!INCLUDE [book-preview](../../../includes/book-preview.md)]

Остановите то, что вы делаете, и напишите 10 своим коллегам. Попросите их определить термин "Облако родной". Хороший шанс, что вы получите восемь разных ответов. Интересно, что через шесть месяцев, как облачные технологии и практики развиваться, так будет их определение.

Универса облака — это изменение того, как мы думаем о построении критически важных бизнес-систем.

Облачные системы предназначены для быстрого изменения, больших масштабов и устойчивости.

Фонд облачных вычислений предоставляет [официальное определение:](https://github.com/cncf/foundation/blob/master/charter.md)

> *Облачные технологии позволяют организациям создавать и запускать масштабируемые приложения в современных динамических средах, таких как общедоступные, частные и гибридные облака. Контейнеры, сервисные сетки, микрослужбы, неизменная инфраструктура и декларативные AA иллюстрируют этот подход.*

> *Эти методы позволяют слабо соединенные системы, которые являются устойчивыми, управляемыми и наблюдаемыми. В сочетании с надежной автоматизацией они позволяют инженерам часто и предсказуемо изменять высокоэффективные изменения с минимальным трудом.*

Приложения становятся все более сложными, и пользователи требуют все больше и больше. Пользователи ожидают быстрой отзывчивости, инновационных функций и нулевого простоя. Проблемы с производительностью, повторяющиеся ошибки и неспособность быстро двигаться больше не являются приемлемыми. Они легко перейдут к вашему конкуренту.

Облако родной много о *скорости* и *ловкости.* Бизнес-системы эволюционируют от создания возможностей для бизнеса к оружию стратегических преобразований, ускорению скорости и росту бизнеса. Крайне важно, чтобы получить идеи на рынок немедленно.

Вот некоторые компании, которые внедрили эти методы. Подумайте о скорости, ловкости и масштабируемости, которых они достигли.

| Company | Среда |
| :-------- | :-------- |
| [Netflix](https://www.infoq.com/news/2013/06/netflix/) | Имеет 600 услуг в производстве. Развертывается сто раз в день. |
| [Uber](https://eng.uber.com/micro-deploy/) | Имеет 1000 услуг, хранящихся в производстве. Развертывает несколько тысяч сборок каждую неделю. |
| [WeChat](https://www.cs.columbia.edu/~ruigu/papers/socc18-final100.pdf) | Имеет 300 услуг в производстве. Делает почти 1000 изменений в день. |

Как видите, Netflix, Uber и WeChat разоблачают системы, состоящие из сотен независимых микросервисов. Этот архитектурный стиль позволяет им быстро реагировать на рыночные условия. Они могут мгновенно обновлять небольшие участки живого, сложного приложения и индивидуально масштабировать эти области по мере необходимости.

Скорость и ловкость родного облака обусловлены рядом факторов. В первую очередь это облачная инфраструктура. Пять дополнительных основных столбов, показанных на рисунке 1-3, также являются основой для облачных систем.

![Облако-родные основополагающие столбы](./media/cloud-native-foundational-pillars.png)

**Рисунок 1-3**. Облако-родные основополагающие столбы

Давайте потрудим некоторое время, чтобы лучше понять значение каждого столба.

## <a name="the-cloud"></a>Облако...

Облачные системы в полной мере используют преимущества модели облачных сервисов.

Эти системы, разработанные для процветания в динамичной, виртуализированной облачной среде, широко используют платформу в качестве вычислительной инфраструктуры и управляемых сервисов [Платформы (PaaS).](https://azure.microsoft.com/overview/what-is-paas/) Они рассматривают базовую инфраструктуру как *одноразовую* - подготовленную в течение нескольких минут и перегабашенные, масштабированные, перемещенные или уничтоженные по требованию - с помощью автоматизации.

Рассмотрим широко принят DevOps концепции [домашних животных против крупного рогатого скота](https://medium.com/@Joachim8675309/devops-concepts-pets-vs-cattle-2380b5aab313). В традиционном центре обработки данных, серверы рассматриваются как *домашние животные*: физическая машина, учитывая значимое имя, и заботятся. Масштабируется, добавляя больше ресурсов в ту же машину (масштабирование). Если сервер заболевает, вы ухаживаете за ним. Если сервер становится недоступным, все замечают.

Модель обслуживания *скота* отличается. Каждый экземпляр предоставляется в качестве виртуальной машины или контейнера. Они идентичны и назначены системы идентификатора, такие как служба-01, служба-02, и так далее. Масштабируется, создавая больше из них (масштабирование). Когда человек становится недоступен, никто не замечает.

Модель крупного рогатого скота охватывает *неизменяемую инфраструктуру.* Серверы не ремонтируются и не изменяются. Если один не удается или требует обновления, он уничтожен и новый подготовлен - все делается с помощью автоматизации.

Облачные системы охватывают модель обслуживания Cattle. Они продолжают работать по мере того, как инфраструктура масштабируется, не обращая внимания на машины, на которых они работают.

Облачная платформа Azure поддерживает этот тип высокоупругой инфраструктуры с возможностями автоматического масштабирования, самовосстановления и мониторинга.

## <a name="modern-design"></a>Современный дизайн

Как бы вы спроектировать облачное приложение? Как будет выглядеть ваша архитектура? К каким принципам, шаблонам и передовым практикам вы бы придерживались? Какие проблемы инфраструктуры и оперативной деятельности будут важны?

### <a name="the-twelve-factor-application"></a>Приложение "Двенадцать факторов"

Широко признанной методологией построения облачных приложений является [приложение «Двенадцать факторов».](https://12factor.net/) В нем описывается набор принципов и методов, которым разработчики следуют для построения приложений, оптимизированных для современных облачных сред. Особое внимание уделяется переносимости в различных средах и декларативной автоматизации.

В то время как применимо к любому веб-приложению, многие практикующие считают его прочной основой для создания облачных приложений. Системы, основанные на этих принципах, могут быстро развертывать и масштабировать ся,а также добавлять функции для быстрого реагирования на изменения рынка.

В следующей таблице освещается методология «Двенадцать факторов»:

|    |  Фактор | Объяснение  |
| :-------- | :-------- | :-------- |
| 1 | Кодовая база | Единая кодовая база для каждой микрослужбы, хранящаяся в собственном репозитории. Отслеживаемый с помощью управления версиями, он может развертываться в нескольких средах (КЗ, Постановка, Производство). |
| 2 | Зависимости | Каждая микрослужба изолирует и упаковывает свои собственные зависимости, внеся изменения, не влияя на всю систему. |
| 3 | Конфигурации  | Информация о конфигурации перемещается из микрослужбы и экстернализуется с помощью инструмента управления конфигурацией за пределами кода. Одно и то же развертывание может распространяться по средам с правильной прикладной конфигурацией.  |
| 4 | Резервные службы | Вспомогательные ресурсы (хранилища данных, кэши, брокеры сообщений) должны подвергаться воздействию по адресу. Это отменяет ресурс от приложения, позволяя ему быть взаимозаменяемым.  |
| 5 | Сборка, выпуск, запуск | Каждый релиз должен обеспечивать строгое разделение на этапах сборки, выпуска и выполнения. Каждый из них должен быть помечен уникальным идентификатором и поддерживать возможность отката. Современные системы CI/CD помогают реализовать этот принцип. |
| 6 | Процессы | Каждая микрослужба должна выполняться в своем собственном процессе, изолированном от других запущенных служб. Экстернализация требуемого состояния для резервной службы, такой как распределенный кэш или хранилище данных. |
| 7 | Связывание порта | Каждая микрослужба должна быть автономной с ее интерфейсами и функциональностью, выставленной на собственном порту. Это обеспечивает изоляцию от других микрослужб. |
| 8 | Параллелизм | Службы масштабируются через большое количество небольших идентичных процессов (копий), в отличие от масштабирования одного большого экземпляра на самой мощной доступной машине. |
| 9 | Разогнанность | Экземпляры обслуживания должны быть одноразовыми, предпочитая быстрые запуски для увеличения возможностей масштабируемости и изящные остановки, чтобы оставить систему в правильном состоянии. Докер контейнеры вместе с оркестратором по своей сути удовлетворить это требование. |
| 10 | Дев/Пд Паритет | Сохраняйте среды на протяжении всего жизненного цикла приложения как можно более похожими, избегая дорогостоящих ярлыков. В данном разбивке контейнеры могут в значительной степени способствовать продвижению той же среды исполнения. |
| 11 | Logging | Относитесь к журналам, генерируемым микрослужбами, как потоки событий. Обработайте их с помощью агрегатора событий и распространяйте данные на инструменты интеллектуального анализа данных/журналы, такие как Azure Monitor или Splunk и в конечном итоге долгосрочные архивы. |
| 12 | Админ процессы | Выполнение административных/управленческих задач как одноразовых процессов. Задачи могут включать очистку данных и вытягивание аналитики для отчета. Инструменты, выражающие эти задачи, должны вызываться из производственной среды, но отдельно от приложения. |

В книге, [За Двенадцать-фактор App](https://content.pivotal.io/blog/beyond-the-twelve-factor-app), автор Кевин Хоффман детали каждого из первоначальных 12 факторов (написано в 2011 году). Кроме того, книга содержит три дополнительных фактора, которые отражают современный дизайн облачных приложений.

|    |  Новый фактор | Объяснение  |
| :-------- | :-------- | :-------- |
| 13 | API Первый | Сделайте все услуги. Предположим, что ваш код будет использован фронтальным клиентом, шлюзом или другой службой. |
| 14 | Телеметрия | На рабочей станции, у вас есть глубокая видимость в ашего приложении и его поведение. В облаке нет. Убедитесь, что ваш дизайн включает в себя сбор мониторинга, доменов и данных о работоспособности/системе. |
| 15 | Аутентификация/ авторизация  | Реализация идентификации с самого начала. Рассмотрим функции [RBAC (управление доступом на основе ролей),](https://docs.microsoft.com/azure/role-based-access-control/overview) доступные в общедоступных облаках.  |

Мы будем ссылаться на многие из 12 "факторов в этой главе и на протяжении всей книги.

### <a name="critical-design-considerations"></a>Критические соображения дизайна

Помимо руководства, представленного из двенадцатифакторной методологии, есть несколько критических проектных решений, которые необходимо принять при построении распределенных систем.

*Связи*

Как клиентские приложения переднего конца будут общаться с основными службами поддержки? Вы позволите прямое общение? Или, не могли бы вы абстрагировать бэк-энд услуг с шлюзом фасад, который обеспечивает гибкость, контроль и безопасность?

Как основные службы бэк-энда будут общаться друг с другом? Будете ли вы позволять прямые http звонки, которые приводят к соединению и влияние производительности и ловкости? Или вы могли бы рассмотреть возможность разъединение обмена сообщениями с технологиями очереди и темы?

Коммуникация подробно описана в главе 4, *Облачные модели связи.*

*Устойчивость*

Архитектура микрослужб перемещает систему из процесса в сетевую связь. Что делать в распределенной среде, если служба B не отвечает на звонок из службы А? Что происходит, когда служба C становится временно недоступной, а другие службы, называя ее стек, и ухудшают производительность системы?

Устойчивость подробно описана в главе 6, *Облачно-родной устойчивости.*

*Распределенные данные*

По замыслу, каждая микрослужба инкапсулирует свои собственные данные, подвергая операции через свой общедоступный интерфейс. Если да, то как задавка данных или реализации транзакции в нескольких службах?

Распределенные данные подробно охватываются главой 5, *шаблонами данных Cloud-Native.*

*Идентификация*

Как ваша служба определит, кто к нему имеет доступ и какие у них разрешения?

Идентификация подробно описана В главе 8, *Идентичность*.

## <a name="microservices"></a>Микрослужбы

Облачные системы охватывают микрослужбы, популярный архитектурный стиль для построения современных приложений.

Построенные как распределенный набор небольших независимых услуг, взаимодействующих через общую ткань, микрослужбы имеют следующие характеристики:

- Каждый реализует определенные бизнес-возможности в более широком контексте домена.

- Каждый из них разработан автономно и может быть развернут независимо.

- Каждый из них является автономным инкапсуляцией своей собственной технологии хранения данных (S'L, NoS'L) и платформы программирования.

- Каждый из них работает в своем собственном процессе и общается с другими пользователями, используя стандартные коммуникационные протоколы, такие как HTTP/HTTPS, WebSockets или [AM-P.](https://en.wikipedia.org/wiki/Advanced_Message_Queuing_Protocol)

- Они сочиняют вместе, чтобы сформировать приложение.

Рисунок 1-4 контрастирует монолитный подход к применению с подходом микрослужб. Обратите внимание, что монолит состоит из многослойной архитектуры, которая выполняется в одном процессе. Как правило, он потребляет реляционные базы данных. Однако подход к микрослужбе сегрегирует функциональность на независимые службы, включающие логику и данные. Каждая микрослужба размещает свой собственный хранилище данных.

![Монолитное развертывание по сравнению с микрослужбами](./media/monolithic-vs-microservices.png)

**Рисунок 1-4.** Монолитное развертывание по сравнению с микрослужбами

Обратите внимание, как микрослужбы продвигают принцип «Одна кодбаза, одно приложение» из [приложения «Двенадцать факторов»,](https://12factor.net/)обсуждавшихся ранее в главе.

> *Фактор \#1 определяет "Единую кодовую базу для каждой микрослужбы, хранящуюся в собственном репозитории. Отслеживаемый с помощью управления версиями, он может развертываться в нескольких средах."*

### <a name="why-microservices"></a>Зачем нужны микрослужбы

Микроуслуги обеспечивают гибкость.

Ранее в главе мы сравнили приложение электронной коммерции, построенное как монолит, с приложением с микроуслугами. В примере мы увидели некоторые явные преимущества:

- Каждая микрослужба имеет автономный жизненный цикл и может развиваться независимо и часто развертываться. Вам не придется ждать ежеквартального выпуска для развертывания новых функций или обновления. Можно обновить небольшую площадь сложного приложения с меньшим риском нарушения всей системы.

- Каждая микрослужба может масштабироваться независимо. Вместо масштабирования всего приложения в единое целое, вы масштабируете только те службы, которые требуют больше вычислительной мощности или пропускной способности сети. Этот мелкозернистый подход к масштабированию обеспечивает больший контроль над вашей системой и помогает снизить общие затраты при масштабировании части вашей системы, а не всего.

Отличным справочником для понимания микрослужб [является .NET Microservices: Архитектура для контейнерных приложений .NET](https://docs.microsoft.com/dotnet/standard/microservices-architecture/). Книга глубоко погружается в дизайн микрослужб и архитектуру. Это компаньон для [полностек овой архитектуры микрослужбы](https://github.com/dotnet-architecture/eShopOnContainers) доступны в качестве бесплатной загрузки от Microsoft.

### <a name="developing-microservices"></a>Развитие микросервисов

Микросервисы могут быть созданы с любой современной платформой разработки.

Платформа Microsoft .NET Core является отличным выбором. Бесплатный и открытый исходный код, он имеет много встроенных функций для упрощения разработки микрослужб. .NET Core является кросс-платформенным. Приложения могут быть построены и запущены на Windows, macOS и большинстве ароматизаторов Linux.

.NET Core обладает высокой результативной работой и хорошо забил по сравнению с Node.js и другими конкурирующими платформами. Интересно, что [TechEmpower](https://www.techempower.com/) провел аттестинговый набор [тестов производительности](https://www.techempower.com/benchmarks/#section=data-r17&hw=ph&test=plaintext) на многих платформах и платформах веб-приложений. .NET Core набрал в топ-10 - значительно выше Node.js и других конкурирующих платформ.

Ядро .NET поддерживается корпорацией Майкрософт и сообществом .NET на GitHub.

## <a name="containers"></a>Контейнеры

В настоящее время, это естественно, чтобы услышать термин *контейнер,* упомянутый в любом разговоре о *тумане родной*. В книге, [Облако Родные шаблоны](https://www.manning.com/books/cloud-native-patterns), автор Корнелия Дэвис отмечает, что "Контейнеры являются отличным фактором, способствуют облачного программного обеспечения". Фонд Cloud Native Computing Foundation ставит контейнеризацию микрослужб в качестве первого шага в своей [карте Cloud-Native Trail Map](https://raw.githubusercontent.com/cncf/trailmap/master/CNCF_TrailMap_latest.png) - руководства для предприятий, начинающих свое путешествие в облаке.

Контейнеризация микрослужбы проста и проста. Код, его зависимости и время выполнения упакованы в двоичный файл, называемый [изображением контейнера.](https://docs.docker.com/glossary/?term=image) Изображения хранятся в [реестре контейнеров,](https://caylent.com/container-registries/)который выступает в качестве репозитория или библиотеки для изображений. Реестр может быть размещен на компьютере разработки, в центре обработки данных или в общедоступном облаке. Докер сам поддерживает публичный реестр через [Docker hub](https://hub.docker.com/). Облако Azure имеет [реестр контейнеров](https://azure.microsoft.com/services/container-registry/) для хранения изображений контейнеров рядом с облачными приложениями, которые будут их запускать.

При необходимости изображение преобразуется в экземпляр бегущего контейнера. Экземпляр работает на любом компьютере с установленным механизмом [запуска контейнера.](https://kubernetes.io/docs/setup/production-environment/container-runtimes/) Вы можете иметь столько экземпляров контейнерной службы по мере необходимости.

На рисунке 1-5 показаны три различных микрослужбы, каждая из которых находится в собственном контейнере, работая на одном хосте.

![Несколько контейнеров на одном узле](./media/hosting-mulitple-containers.png)

**Рисунок 1-5**. Несколько контейнеров на одном узле

Обратите внимание, как каждый контейнер поддерживает свой собственный набор зависимостей и время выполнения, которые могут быть разными. Здесь мы видим различные версии микрослужбы продукта, работающие на одном и том же узлах. Каждый контейнер разделяет фрагмент базовой операционной системы, памяти и процессора, но изолирован друг от друга.

Обратите внимание, насколько хорошо модель контейнера охватывает принцип «Зависимости» из [приложения «Двенадцать факторов».](https://12factor.net/)

> *Фактор \#2 указывает, что «каждая микрослужба изолирует и упаковывает свои собственные зависимости, внеся изменения, не влияя на всю систему».*

Контейнеры поддерживают рабочие нагрузки Linux и Windows. Облако Azure открыто охватывает и то, и другое. Интересно, что именно Linux, а не Windows Server, стал самой популярной операционной системой в Azure.

В то время как существует несколько поставщиков контейнеров, Docker захватил львиную долю рынка. Компания была движущей движения контейнеров программного обеспечения. Он стал де-факто стандартом для упаковки, развертывания и запуска облачных приложений.

### <a name="why-containers"></a>Почему контейнеры?

Контейнеры обеспечивают портативность и гарантируют согласованность в средах. Инкапсулируя все в единый пакет, вы *изолируете* микрослужбу и ее зависимости от базовой инфраструктуры.

Вы можете развернуть тот же контейнер в любой среде с движком времени выполнения Docker. Контейнерные рабочие нагрузки также устраняют затраты на предварительную настройку каждой среды с помощью инфраструктур, библиотек программного обеспечения и двигателей времени выполнения.

Совместное использование базовой операционной системы и ресурсов-хоста, контейнеры имеют гораздо меньший след, чем полная виртуальная машина. Меньший размер увеличивает *плотность*или количество микрослужб, что данный хост может работать в одно время.

### <a name="container-orchestration"></a>Оркестрация контейнеров

В то время как такие инструменты, как Docker создают изображения и запускают контейнеры, вам также нужны инструменты для управления ими. Управление контейнерами осуществляется с помощью специальной программной программы под названием контейнерный оркестратор. При работе в масштабе, контейнерная оркестровка имеет важное значение.

На рисунке 1-6 показаны задачи управления, которые обеспечивают контейнерные оркестранты.

![Что делают контейнерные оркестранты](./media/what-container-orchestrators-do.png)

**Рисунок 1-6**. Что делают контейнерные оркестранты

В следующей таблице описаны общие задачи оркестровки.

|  Задания | Объяснение  |
| :-------- | :-------- |
| Планирование | Автоматическое предоставление экземпляров контейнеров.|
| Аффинити/анти-сродство | Предоставление контейнеров поблизости или далеко друг от друга, помогая доступности и производительности. |
| Мониторинг работоспособности | Автоматически обнаруживать и исправлять сбои.|
| Отработка отказа | Автоматическое переобеспечение неудавшегося экземпляра на здоровые машины.|
| Масштабирование | Автоматически добавляйте или удаляйте экземпляр контейнера для удовлетворения спроса.|
| Сеть | Управление сетевой накладкой для контейнерной связи.|
| Обнаружение служб | Включите контейнеры, чтобы найти друг друга.|
| Последовательные обновления | Координировать постепенные обновления с нулевым развертыванием времени простоя. Автоматически откат проблемных изменений.|

Обратите внимание, как оркестранты принимают принципы разъявления и параллелизма из [Приложения Двенадцати Факторов,](https://12factor.net/)обсуждавшихся ранее в главе.

> *Фактор \#9 указывает, что "случаи обслуживания должны быть одноразовыми, предпочитая быстрые стартапы для увеличения возможностей масштабируемости и изящные остановки, чтобы оставить систему в правильном состоянии. Докер контейнеры вместе с оркестратором по своей сути удовлетворить это требование ".*

> *Фактор \#8 указывает, что "Услуги масштабируются в большом количестве небольших идентичных процессов (копий), в отличие от масштабирования одного большого экземпляра на самой мощной доступной машине".*

В то время как существует несколько контейнерных оркестровщиков, [Kubernetes](https://kubernetes.io/docs/concepts/overview/what-is-kubernetes/) стал де-факто стандартом для облачного мира. Это портативная, расширяемая платформа с открытым исходным кодом для управления контейнерными рабочими нагрузками.

Вы можете разместить свой собственный экземпляр Kubernetes, но тогда вы будете нести ответственность за подготовку и управление своими ресурсами - которые могут быть сложными. Облако Azure включает в себя Kubernetes как управляемую службу, [службу Azure Kubernetes (AKS).](https://azure.microsoft.com/services/kubernetes-service/) Управляемая служба позволяет в полной мере использовать свои возможности, без необходимости устанавливать и поддерживать его.

Службы Azure Kubernetes подробно описаны в главе 2, *масштабирование облачных приложений.*

## <a name="backing-services"></a>Резервные службы

Облачные системы зависят от множества различных вспомогательных ресурсов, таких как хранилища данных, брокеры сообщений, мониторинг и службы идентификации. Эти службы известны как [службы поддержки.](https://12factor.net/backing-services)

 На рисунке 1-7 показано много общих служб поддержки, которые потребляют облачные системы.

![Общие службы поддержки](./media/common-backing-services.png)

**Рисунок 1-7**. Общие службы поддержки

Поддержка услуг содействовать "безгражданства" принцип из [Двенадцати фактор приложений](https://12factor.net/), обсуждалось ранее в главе.

>*Фактор \#6* указывает, что "каждая микрослужба должна выполняться в своем собственном процессе, изолированном от других запущенных служб. Экстернализация требуемого состояния для резервной службы, такой как распределенный кэш или хранилище данных."

Вы можете разместить свои собственные службы поддержки, но тогда вы будете нести ответственность за лицензирование, подготовку и управление этими ресурсами.

Поставщики облачных услуг предлагают богатый ассортимент *управляемых услуг поддержки.* Вместо того, чтобы владеть услугой, вы просто потребляете ее. Поставщик управляет ресурсом в масштабе и несет ответственность за производительность, безопасность и техническое обслуживание. Мониторинг, избыточность и доступность встроены в службу. Провайдеры полностью поддерживают свои управляемые услуги - открывают билет и исправляют вашу проблему.

Облачные системы отдают предпочтение управляемым службам поддержки от облачных поставщиков. Экономия времени и труда велика. Операционный риск хостинга собственных и испытывают проблемы могут получить дорого быстро.

Наилучшей практикой является рассматривать службу поддержки как *прилагаемый ресурс,* динамически связанный с микрослужбой с информацией (URL и учетными данными), хранящейся во внешней конфигурации. Это руководство изложено в [приложении 12-фактор](https://12factor.net/), обсуждается ранее в главе.

>*Фактор \#4* указывает, что службы поддержки "должны быть выставлены через адресный URL. Это отменяет ресурс от приложения, позволяя ему быть взаимозаменяемым».

>*Фактор \#3* указывает, что "информация о конфигурации перемещается из микрослужбы и экстернализуется с помощью инструмента управления конфигурацией за пределами кода".

С помощью этого шаблона служба поддержки может быть прикреплена и отделена без изменений кода. Вы можете продвигать микрослужбу от Q до промежуточной среды. Вы обновляете конфигурацию микрослужбы, чтобы указать на службы поддержки в постановке и вводить настройки в контейнер через переменную среды.

Облачные поставщики предоставляют AA,sA, чтобы вы могли общаться со своими собственными службами поддержки. Эти библиотеки инкапсулируют сантехнику и сложность. Общение непосредственно с этими AA будет тесно пара ваш код в службу поддержки. Лучше изолировать детали реализации API поставщика. Введите слой посредничества или промежуточный API, подвергая общие операции коду службы. Эта свободная связь позволяет поменять одну службу поддержки на другую или переместить код в другое общедоступное облако без внесения изменений в основной код службы.

Службы поддержки подробно обсуждаются в главе 5, *шаблонах данных cloud-Native*и главе 4, *шаблоны связи Cloud-Native.*

## <a name="automation"></a>Служба автоматизации

Как вы видели, облачные системы охватывают микрослужбы, контейнеры и современный дизайн систем для достижения скорости и гибкости. Но это только часть истории. Как обеспечить облачные среды, на которых работают эти системы? Как быстро развертывать функции и обновления приложений? Как закруглить полную картину?

Введите общепринятую практику [инфраструктуры как Код](https://docs.microsoft.com/azure/devops/learn/what-is-infrastructure-as-code), или IaC.

С помощью IaC вы автоматируеподготовки платформы и развертывания приложений. Вы по существу применяете методы разработки программного обеспечения, такие как тестирование и версия для ваших практик DevOps. Инфраструктура и развертывание являются автоматизированными, последовательными и повторяемыми.

### <a name="automating-infrastructure"></a>Автоматизация инфраструктуры

Такие инструменты, как [Azure Resource Manager,](https://azure.microsoft.com/documentation/articles/resource-group-overview/)Terraform и [Azure CLI,](https://docs.microsoft.com/cli/azure/)позволяют декларативно списать требуемую облачную инфраструктуру. Имена ресурсов, местоположения, возможности и секреты параметрыи и динамические. Скрипт версиируется и проверяется в исходном элементе управления как артефакт вашего проекта. Вы ссылаетесь на скрипт для обеспечения последовательной и повторяемой инфраструктуры в средах системы, таких как кВС, постановка и производство.

Под капотом, IaC является идемпотентным, что означает, что вы можете запустить тот же сценарий снова и снова без побочных эффектов. Если команде необходимо внести изменения, они отоменяют и перезапустите сценарий. Затрагиваются только обновленные ресурсы.

В статье [«Что такое инфраструктура как код»,](https://docs.microsoft.com/azure/devops/learn/what-is-infrastructure-as-code)автор Сэм Гукенхаймер описывает, как: «Команды, которые реализуют IaC, могут быстро и в масштабе обеспечивать стабильную среду. Команды избегают ручной настройки сред и обеспечивают согласованность, представляя желаемое состояние своих сред с помощью кода. Развертывание инфраструктуры с Помощью IaC повторяется и предотвращает проблемы времени выполнения, вызванные дрейфом конфигурации или отсутствующими зависимостями. Команды DevOps могут работать вместе с единым набором практик и инструментов для быстрого, надежного и масштабного предоставления приложений и их вспомогательной инфраструктуры».

### <a name="automating-deployments"></a>Автоматизация развертывания

[Приложение «Двенадцать факторов»,](https://12factor.net/)обсуждаемое ранее, требует отдельных шагов при преобразовании заполненного кода в запущенное приложение.

> *Фактор \#5* указывает, что "каждый релиз должен обеспечивать строгое разделение на этапах сборки, выпуска и запуска. Каждый из них должен быть помечен уникальным идентификатором и поддерживать возможность отката».

Современные системы CI/CD помогают реализовать этот принцип. Они предоставляют отдельные шаги развертывания и помогают обеспечить согласованный и качественный код, доступный пользователям.

На рисунке 1-8 показано разделение процесса развертывания.

![Шаги развертывания в конвейере CI/CD](./media/build-release-run-pipeline.png)

**Рисунок 1-8**. Этапы развертывания в конвейере CI/CD

В предыдущем рисунке, обратите особое внимание на разделение задач.

Разработчик создает функцию в среде разработки, итерируя через так называемый «внутренний цикл» кода, запуска и отладки. После завершения этот код *засовывается* в репозиторий кода, например GitHub, Azure DevOps или BitBucket.

Нажатие запускает стадию сборки, которая преобразует код в двоичный артефакт. Работа осуществляется с конвейером [непрерывной интеграции (CI).](https://martinfowler.com/articles/continuousIntegration.html) Он автоматически создает, тестирует и упаковывает приложение.

Этап выпуска подхватывает двоичный артефакт, применяет информацию о конфигурации внешнего приложения и среды и производит неизменяемый релиз. Выпуск развертывается в заданную среду. Работа выполняется с конвейером [непрерывной доставки (CD).](https://martinfowler.com/bliki/ContinuousDelivery.html) Каждый релиз должен быть идентифицирован. Вы можете сказать: "Это развертывание работает релиз 2.1.1 приложения".

Наконец, выпущенная функция запущена в среде целевого выполнения. Релизы являются неизменяемым, что означает, что любое изменение должно создать новый релиз.

Применяя эту практику, организации радикально эволюционировали в том, как они подают программное обеспечение. Многие из них перешли от ежеквартальных релизов к обновлениям по требованию. Цель состоит в том, чтобы поймать проблемы в начале цикла разработки, когда они дешевле исправить. Чем дольше продолжительность между интеграциями, тем более дорогостоящими становятся решения.  При последовательности в процессе интеграции команды могут чаще фиксировать изменения кода, что приводит к улучшению совместной работы и качеству программного обеспечения.

### <a name="azure-pipelines"></a>Azure Pipelines

Облако Azure включает в себя новый CI/CD-сервис под названием [Azure Pipelines,](https://azure.microsoft.com/services/devops/pipelines/)который является частью предложения [Azure DevOps,](https://azure.microsoft.com/services/devops/) показанного на рисунке 1-9.

![Трубопроводы Azure в ДевОпс](./media/devops-components.png)

**Рисунок 1-9**. Предложения Azure DevOps

Azure Pipelines — это облачный сервис, сочетающий в себе непрерывную интеграцию (CI) и непрерывную доставку (CD). Вы можете автоматически тестировать, создавать и отомещать свой код в любую цель.

Вы определяете свой конвейер в коде в файле YAML вместе с остальной частью кода для вашего приложения.

- Конвейер приводится в версию с кодом и выполняет одну и ту же структуру ветвления.
- Вы получаете проверку изменений с помощью отзывов кода в запросах на вытягивание и политиках создания ветвей.
- Каждая ветвь, которую вы используете, может настроить политику сборки, изменив файл azure-pipelines.yml.
- Файл конвейера проверяется в управлении версиями и может быть исследован, если есть проблема.

Служба Azure Pipelines поддерживает большинство поставщиков Git и может создавать конвейеры развертывания для приложений, написанных на платформах Linux, macOS или Windows. Она включает в себя поддержку Java, .NET, JavaScript, Python, PHP, Go, XCode и C.

>[!div class="step-by-step"]
>[Предыдущий](introduction.md)
>[Следующий](candidate-apps.md)
