---
title: Определение ориентации на облако
description: Ознакомьтесь с базовыми основами, которые предоставляют основой для облачных систем
author: robvet
ms.date: 08/20/2019
ms.openlocfilehash: 27191a67b2964ac2e1636a4d7dc55d5314b78439
ms.sourcegitcommit: 559fcfbe4871636494870a8b716bf7325df34ac5
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 10/30/2019
ms.locfileid: "73841807"
---
# <a name="defining-cloud-native"></a>Определение машинного кода в облаке

[!INCLUDE [book-preview](../../../includes/book-preview.md)]

Прерывать работу и текст 10 коллег. Попросите их определить термин "облако машинного кода". Хороший шанс, вы получите восемь различных ответов. Что интересно, за шесть месяцев с момента развития облачных технологий и методик, поэтому будет определено их определение.

Облачные машинные системы — это все об изменении способа создания критически важных бизнес-систем.

Облачные системы предназначены для обеспечения быстрого изменения, крупномасштабного масштабирования и устойчивости.

Облачная инфраструктура машинного кода обеспечивает [официальное определение](https://github.com/cncf/foundation/blob/master/charter.md):

> *Облачные технологии позволяют организациям создавать и запускать масштабируемые приложения в современных динамических средах, таких как общедоступные, частные и гибридные облака. Этот подход проиллюстрировать контейнеры, сети служб, микрослужбы, неизменяемую инфраструктуру и декларативные API.*

> *Эти методы обеспечивают устойчивую, управляемую и наблюдаемую систему слабо связанных систем. В сочетании с надежной автоматизацией они позволяют инженерам часто вносить значительные изменения в критические и предсказуемые результаты с минимальными работают.*

Приложения становятся все более сложными с пользователями, которые требуют больше и больше. Пользователи предполагают быстрое реагирование, инновационные функции и нулевое время простоя. Проблемы с производительностью, повторяющиеся ошибки и невозможность перемещения быстро перестают быть приемлемыми. Они легко переходят на ваш конкурент.

Облачная машинная поддержка очень важна для *ускорения* и *гибкости*. Бизнес-системы развиваются от поддержки бизнес-возможностей до оружие стратегических преобразований, что ускоряет бизнес-скорость и рост. Крайне важно немедленно получить идеи на рынке.

Вот несколько компаний, которые реализовали эти методы. Подумайте о скорости, гибкости и масштабируемости.

| Компания | Удобной |
| :-------- | :-------- |
| [Netflix](https://www.infoq.com/news/2013/06/netflix/) | Содержит 600 и более служб в рабочей среде. Развертывает сотни раз в день. |
| [Uber](https://eng.uber.com/micro-deploy/) | Содержит 1000 служб, хранящихся в рабочей среде. Развертывает несколько тысяч сборок каждую неделю. |
| [WeChat](https://www.cs.columbia.edu/~ruigu/papers/socc18-final100.pdf) | Содержит 300 и более служб в рабочей среде. Вносит почти 1 000 изменений в день. |

Как видите, Netflix, Uber и WeChat предоставляют системы, состоящие из сотен независимых микрослужб. Этот стиль архитектуры позволяет им быстро реагировать на условия рынка. Они могут мгновенно обновлять небольшие области в активном, сложном приложении и по отдельности масштабировать эти области по мере необходимости.

Скорость и гибкость машинного кода в облаке поступают от ряда факторов. Самое главное — облачная инфраструктура. Пять дополнительных базовых принципов, показанных на рисунке 1-3, также предоставляют основой для собственных облачных систем.

![Собственные базовые основы облака](./media/cloud-native-foundational-pillars.png)

**Рис. 1-3**. Собственные базовые основы облака

Давайте попробуем некоторое время, чтобы лучше понять значимость каждого из этих принципов.

## <a name="the-cloud"></a>Облако...

Облачные системы используют все преимущества модели облачной службы.

Эти системы, разработанные для создания динамичных виртуальных облачных сред, широко используют инфраструктуру вычислений ["платформа как услуга" (PaaS)](https://azure.microsoft.com/overview/what-is-paas/) и управляемые службы. Они обрабатывают базовую инфраструктуру *как* готовую к запуску за считанные минуты и изменяют размер, масштабируются, перемещаются или уничтожаются по требованию — через автоматизацию.

Рассмотрим широко принятый DevOps концепцию [Pets и крупный рогатый скот](https://medium.com/@Joachim8675309/devops-concepts-pets-vs-cattle-2380b5aab313). В традиционном центре обработки данных серверы обрабатываются как *pets*: физический компьютер, с учетом значимого имени и таком для. Масштабирование выполняется путем добавления дополнительных ресурсов на тот же компьютер (увеличение масштаба). Если сервер станет нетрудоспособным, вы медперсонала его работоспособность. Если сервер станет недоступным, все уведомления.

Модель службы *крупный рогатый скот* отличается. Каждый экземпляр подготавливается как виртуальная машина или контейнер. Они идентичны и получают идентификатор системы, такой как Service-01, Service-02 и т. д. Масштабирование выполняется путем их создания (горизонтальное масштабирование). Если один из них становится недоступным, никто не замечает.

Модель крупный рогатый скот использует *неизменяемую инфраструктуру*. Серверы не восстанавливаются или не изменяются. Если один из них завершается сбоем или требует обновления, он уничтожается, а новый — с помощью автоматизации.

Облачные системы используют модель службы крупный рогатый скот. Они продолжают работать по мере того, как инфраструктура масштабируется или выходит за пределы компьютеров, на которых они работают.

Облачная платформа Azure поддерживает такой тип высокоэластичной инфраструктуры с возможностью автоматического масштабирования, самостоятельной восстановления и мониторинга.

## <a name="modern-design"></a>Современный дизайн

Как вы разрабатываете собственное облачное приложение? Как будет выглядеть архитектура? К каким принципам, шаблонам и рекомендациям будет придерживаться? Какая инфраструктура и операционные проблемы важны?

### <a name="the-twelve-factor-application"></a>Приложение двенадцать факторов

Распространенной методологией для создания облачных приложений является [12-факторное приложение](https://12factor.net/). Он описывает набор принципов и методик, которые разработчики используют для создания приложений, оптимизированных для современных облачных сред. Особое внимание уделяется повышению переносимости между средами и декларативной автоматизацией.

Во многих случаях, применимых к веб-приложениям, многие специалисты считают его надежным основанием для создания облачных приложений. Системы, основанные на этих принципах, могут быстро развертывать и масштабировать и добавлять функции для быстрого реагирования на изменения рынка.

В следующей таблице показана более двенадцатая методология:

|    |  Фактор | Объяснение  |
| :-------- | :-------- | :-------- |
| 1 | База кода | Единая база кода для каждой микрослужбы, хранящаяся в собственном репозитории. С помощью системы управления версиями можно выполнять развертывание в нескольких средах (вопросы и ответы, промежуточные и рабочие). |
| 2 | Зависимости | Каждая микрослужба изолирует и упаковывает свои собственные зависимости, внося изменения, не влияя на всю систему. |
| 3 | Конфигурации  | Сведения о конфигурации перемещаются из микрослужбы и изменяются с помощью средства управления конфигурацией за пределами кода. Одно и то же развертывание может распространяться между средами с применением правильной конфигурации.  |
| 4 | Резервные службы | Вспомогательные ресурсы (хранилища данных, кэши, брокеры сообщений) должны предоставляться через адресный URL-адрес. Это приведет к отделению ресурса от приложения, что позволит ему быть взаимозаменяемым.  |
| 5 | Сборка, выпуск, запуск | Каждый выпуск должен обеспечивать строгое разделение на этапах сборки, выпуска и выполнения. Каждый из них должен быть помечен уникальным ИДЕНТИФИКАТОРом и поддерживать возможность отката. Современные системы CI/CD помогают выполнить этот принцип. |
| 6 | Процессы | Каждая микрослужба должна выполняться в собственном процессе, изолированном от других работающих служб. Выносить требуется состояние для службы резервного копирования, такой как распределенный кэш или хранилище данных. |
| 7 | Привязка портов | Каждая микрослужба должна быть автономной с ее интерфейсами и функциями, предоставляемыми на собственном порте. Это обеспечивает изоляцию от других микрослужб. |
| 8 | Параллельность | Службы масштабируются по большому количеству небольших идентичных процессов (копий) в отличие от масштабирования одного крупного экземпляра на наиболее мощном компьютере. |
| 9 | Утилизация | Экземпляры службы должны быть уничтожены, что позволяет использовать быстрые запуски для повышения масштабируемости и корректного завершения работы, чтобы оставить систему в правильном состоянии. Контейнеры DOCKER и Orchestrator по сути соответствуют этому требованию. |
| 10 | Контроль четности для разработки и произв. | Старайтесь, чтобы среды в жизненном цикле приложения были как можно более похожими, избегая дорогостоящих ярлыков. В этом случае внедрение контейнеров может значительно повысить уровень участия в той же среде выполнения. |
| 11 | Ведение журнала | Рассматривайте журналы, созданные микрослужбами, как потоки событий. Обработайте их с помощью агрегатора событий и распространяюйте данные в средства управления интеллектуального анализа данных и журналов, такие как Azure Monitor или Splunk, а также долгосрочное архивирование. |
| 12 | Процессы администратора | Выполнение задач администрирования и управления в качестве одноразовых процессов. Задачи могут включать очистку данных и извлекать аналитику для отчета. Инструменты, которые выполняют эти задачи, следует вызывать из рабочей среды, но отдельно от приложения. |

В книге [за пределами 12-факторного приложения](https://content.pivotal.io/blog/beyond-the-twelve-factor-app)автор Кевин Хоффман сведения о каждом из первоначальных 12 факторов (написанных на 2011). Кроме того, в книге есть три дополнительных фактора, отражающих сегодняшний современный дизайн облачных приложений.

|    |  Новый фактор | Объяснение  |
| :-------- | :-------- | :-------- |
| 13 | Сначала API | Сделайте все услуги. Предположим, ваш код будет использоваться интерфейсным клиентом, шлюзом или другой службой. |
| 14 | Телеметрия | На рабочей станции имеется глубокая видимость приложения и его поведение. В облаке это не так. Убедитесь, что проект включает в себя сбор данных о мониторинге, характере для домена, а также данные о работоспособности и системе. |
| 15 | Проверка подлинности и авторизация  | Реализуйте удостоверение с самого начала. Рассмотрим функции [RBAC (Управление доступом на основе ролей)](https://docs.microsoft.com/azure/role-based-access-control/overview) , доступные в общедоступных облаках.  |

Мы будем называть многие из 12 факторов в этой главе и во всей книге.

### <a name="critical-design-considerations"></a>Важные рекомендации по проектированию

Помимо рекомендаций, предоставленных из двенадцатой методологии, существует несколько критических решений по проектированию, которые необходимо выполнить при создании распределенных систем.

*Соединений*

Как клиентские приложения внешнего интерфейса обмениваются данными с основными службами на основе резервного копирования? Будет ли разрешена прямая связь? Или же вы можете составить абстрактные серверные службы с помощью шлюза фасадной, обеспечивающего гибкость, контроль и безопасность?

Как серверные основные службы будут взаимодействовать друг с другом? Будут ли разрешаться прямые вызовы HTTP, которые приведут к взаимосвязанию и производительности, а также к гибкости? Или вы можете рассмотреть возможность обработки несвязанных сообщений с помощью технологий очередей и разделов?

Обмен данными рассматривается в главе 4, *встроенных в облако шаблонах обмена данными*.

*Устойчивость*

Архитектура микрослужб перемещает систему из внутрипроцессного в сетевую связь. Что произойдет в распределенной среде, если служба б не отвечает на вызов из службы A? Что происходит, когда служба C становится временно недоступной и другие службы вызывают ее стек и снижают производительность системы?

Устойчивость подробно описана в главе 6, *отказоустойчивость в облаке*.

*Распределенные данные*

Каждая микрослужба по своей структуре инкапсулирует собственные данные, предоставляя операции через общедоступный интерфейс. Если да, как запросить данные или реализовать транзакцию для нескольких служб?

Распределенные данные подробно описаны в главе 5, о *собственных шаблонах данных в облаке*.

*Удостоверение*

Как ваша служба определяет, кто обращается к ней и какие разрешения они имеют?

Удостоверение подробно описано в главе 8, *Identity*.

## <a name="microservices"></a>Микрослужбы

Облачные системы включают микрослужбы, популярный архитектурный стиль для создания современных приложений.

Созданные в виде распределенного набора небольших независимых служб, взаимодействующих через общую структуру, микрослужбы имеют следующие характеристики.

- Каждый из них реализует конкретную бизнес-возможность в более крупном контексте домена.

- Каждый из них разрабатывается автономно и может быть развернут независимо.

- Каждая из них включает в себя инкапсуляцию собственной технологии хранения данных (SQL, NoSQL) и платформы программирования.

- Каждый из них выполняется в собственном процессе и взаимодействует с другими пользователями с помощью стандартных протоколов связи, таких как HTTP/HTTPS, WebSockets или [AMQP](https://en.wikipedia.org/wiki/Advanced_Message_Queuing_Protocol).

- Они объединяются для формирования приложения.

Рис. 1-4. противоположность монолитным приложениям подходу с использованием микрослужб. Обратите внимание, что Монолит состоит из многоуровневой архитектуры, которая выполняется в одном процессе. Обычно он использует реляционную базу данных. Однако подход на основе микрослужб разделяет функциональность на независимые службы, которые включают логику и данные. Каждая микрослужба содержит собственное хранилище данных.

![Монолитное развертывание и микрослужбы](./media/monolithic-vs-microservices.png)

**Рис. 1-4.** Монолитное развертывание и микрослужбы

Обратите внимание на то, как микрослужбы передают принцип «одна база кода — одно приложение» из [двенадцатого приложения](https://12factor.net/), о котором говорилось ранее в главе.

> *Коэффициент \#1 указывает "одну базу кода для каждой микрослужбы, которая хранится в собственном репозитории. Отслеживание версий позволяет выполнять развертывание в нескольких средах ".*

### <a name="why-microservices"></a>Зачем нужны микрослужбы?

Микрослужбы обеспечивают гибкость.

Ранее в этой главе мы сравнивали приложение электронной коммерции, созданное как монолитное, с микрослужбами. В примере мы видели некоторые четкие преимущества:

- Каждая микрослужба имеет автономный жизненный цикл и может развиваться независимо и часто развертываться. Не нужно ждать ежеквартального выпуска для развертывания новых функций или обновлений. Вы можете обновить небольшое пространство сложного приложения, не нарушая работу всей системы.

- Каждая микрослужба может масштабироваться независимо друг от друга. Вместо масштабирования всего приложения как единого блока вы масштабируете только те службы, для которых требуется больше вычислительной мощности или пропускной способности сети. Такой детализированный подход к масштабированию обеспечивает более высокий контроль над системой и помогает снизить общие затраты при масштабировании частей системы, а не на всех.

Отличное справочное руководство по основам микрослужб является [микрослужбами .NET: архитектура для контейнерных приложений .NET](https://docs.microsoft.com/dotnet/standard/microservices-architecture/). Подробное руководство подробно в проектировании и архитектуре микрослужб. Это вспомогательная [архитектура микрослужб с полным стеком](https://github.com/dotnet-architecture/eShopOnContainers) , доступная для бесплатной загрузки Майкрософт.

### <a name="developing-microservices"></a>Разработка микрослужб

Микрослужбы можно создавать с любой современной платформой разработки.

Платформа Microsoft .NET Core отлично подходит. Бесплатный и открытый исходный код содержит множество встроенных функций для упрощения разработки микрослужб. .NET Core является кросс-платформенным. Приложения можно создавать и запускать в Windows, macOS и большинстве разновидностей Linux.

.NET Core является высокопроизводительным и имеет более высокую оценку по сравнению с Node. js и другими конкурирующими платформами. Интересно, [течемповер](https://www.techempower.com/) проводил широкий набор [тестов производительности](https://www.techempower.com/benchmarks/#section=data-r17&hw=ph&test=plaintext) на многих платформах веб-приложений и платформах. .NET Core оценено в 10-и более поздних версиях Node. js и других конкурирующих платформах.

.NET Core поддерживается корпорацией Майкрософт и сообществом .NET на сайте GitHub.

## <a name="containers"></a>Контейнеры

Настоящее время, естественно слышать термин *контейнер* , упомянутый в любом обсуждении, относящемся к *облачной машинной*работе. В книге, в [шаблонах](https://www.manning.com/books/cloud-native-patterns), созданных в облаке, автор Корнелиа Дэвис отслеживает, что "контейнеры — это отличная поддержка облачного программного обеспечения". Облачная собственная вычислительная среда помещает контейнер микрослужб в качестве первого шага в [собственных облачных](https://raw.githubusercontent.com/cncf/trailmap/master/CNCF_TrailMap_latest.png) руководствах по основам для предприятий, которые начинают свое облако в собственном облаке.

Контейнеризация микрослужба проста и проста. Код, его зависимости и среда выполнения упаковываются в двоичный файл, называемый [образом контейнера](https://docs.docker.com/glossary/?term=image). Образы хранятся в [реестре контейнеров](https://caylent.com/container-registries/), который выступает в качестве репозитория или библиотеки для образов. Реестр можно найти на компьютере разработчика, в центре обработки данных или в общедоступном облаке. Сам DOCKER поддерживает общедоступный реестр через [DOCKER Hub](https://hub.docker.com/). В облаке Azure есть [Реестр контейнеров](https://azure.microsoft.com/services/container-registry/) для хранения образов контейнеров, близких к облачным приложениям, которые будут их запускать.

При необходимости образ преобразуется в выполняющийся экземпляр контейнера. Экземпляр выполняется на любом компьютере, на котором установлена подсистема [контейнера среды выполнения](https://kubernetes.io/docs/setup/production-environment/container-runtimes/) . При необходимости можно использовать любое количество экземпляров контейнерной службы.

На рис. 1-5 показаны три различные микрослужбы, каждая из которых находится в отдельном контейнере, работающем на одном узле.

![Несколько контейнеров на одном узле](./media/hosting-mulitple-containers.png)

**Рис. 1-5**. Несколько контейнеров на одном узле

Обратите внимание, что каждый контейнер поддерживает собственный набор зависимостей и среды выполнения, который может отличаться. Здесь мы видим различные версии микрослужбы продукта, работающие на одном узле. Каждый контейнер использует один и тот же сегмент основной операционной системы, памяти и процессора, но изолирован друг от друга.

Обратите внимание, насколько хорошо модель контейнера использует принцип "зависимостей" из [двенадцатого приложения](https://12factor.net/).

> *Фактор \#2 указывает, что каждая микрослужба изолирует и упаковывает свои собственные зависимости, внося изменения, не влияя на всю систему.*

Контейнеры поддерживают рабочие нагрузки Linux и Windows. Облако Azure открыто и использует оба варианта. Что интересно, это Linux, а не Windows Server, который стал самой популярной операционной системой в Azure.

Хотя существует несколько поставщиков контейнеров, Docker захватывает общую долю рынка Lion. Компания управляет перемещением контейнеров программного обеспечения. Он стал стандартом де-факто для упаковки, развертывания и выполнения собственных облачных приложений.

### <a name="why-containers"></a>Зачем нужны контейнеры?

Контейнеры обеспечивают переносимость и гарантируют согласованность в разных средах. Инкапсуляция всех компонентов в один пакет *изолирует* микрослужбу и ее зависимости от базовой инфраструктуры.

Этот контейнер можно развернуть в любой среде, в которой находится подсистема выполнения DOCKER. Контейнерные рабочие нагрузки также устраняют затраты на предварительную настройку каждой среды с помощью платформ, библиотек программного обеспечения и ядер среды выполнения.

При совместном использовании базовой операционной системы и ресурсов узла контейнеры имеют намного меньший объем, чем полная виртуальная машина. Чем меньше размер, тем больше *плотность*или число микрослужб, которые может запустить конкретный узел.

### <a name="container-orchestration"></a>Оркестрации контейнеров

Хотя средства, такие как DOCKER, создают образы и запускают контейнеры, вам также нужны средства для управления ими. Управление контейнерами выполняется с помощью специальной программной программы, именуемой контейнером Orchestrator. При работе в масштабе управление контейнером является обязательным.

На рис. 1-6 показаны задачи управления, предоставляемые оркестрации контейнеров.

![Что такое оркестрации для контейнеров](./media/what-container-orchestrators-do.png)

**Рис. 1-6**. Что такое оркестрации для контейнеров

В следующей таблице описаны общие задачи оркестрации.

|  Задачи | Объяснение  |
| :-------- | :-------- |
| Создается | Автоматически подготавливать экземпляры контейнеров.|
| Сходство/сглаживание | Подготавливайте контейнеры рядом друг с другом, обеспечивая доступность и производительность. |
| Мониторинг работоспособности | Автоматическое обнаружение и устранение сбоев.|
| Перемещение | Автоматически повторно подготавливать неисправный экземпляр к работоспособным компьютерам.|
| Масштабирование | Автоматическое добавление или удаление экземпляра контейнера для удовлетворения спроса.|
| Сети | Управление наложением сетей для обмена данными между контейнерами.|
| Обнаружение служб | Включите контейнеры для размещения друг друга.|
| Последовательные обновления | Координирование добавочных обновлений с нулевым временем простоя. Автоматически выполнить откат проблемных изменений.|

Обратите внимание, как оркестрации применяет принципы реализации и параллелизма из [12-факторного приложения](https://12factor.net/), рассмотренного выше в главе.

> *Фактор \#9 указывает, что "экземпляры службы должны быть уничтожены, отпользующий быстрые запуски для повышения возможностей масштабируемости и корректного завершения работы, чтобы оставить систему в правильном состоянии. Контейнеры DOCKER вместе с Orchestrator по сути соответствуют этому требованию ".*

> *Фактор \#8 указывает, что "службы масштабируются по большому количеству небольших идентичных процессов (копий), а не к масштабированию одного крупного экземпляра на наиболее мощном компьютере".*

Хотя существует несколько оркестрации контейнеров, [Kubernetes](https://kubernetes.io/docs/concepts/overview/what-is-kubernetes/) стал стандартом де-факто для облачного машинного мира. Это переносимая расширяемая платформа с открытым исходным кодом для управления контейнерными рабочими нагрузками.

Можно разместить собственный экземпляр Kubernetes, но вы должны быть ответственными за подготовку и управление ресурсами, которые могут быть сложными. Облачные функции Azure Kubernetes в качестве управляемой службы, [службы Kubernetes Azure (AKS)](https://azure.microsoft.com/services/kubernetes-service/). Управляемая служба позволяет полностью использовать ее функции без необходимости устанавливать и обслуживать ее.

Службы Azure Kubernetes Services подробно описаны в главе 2, в которой выполняется *масштабирование собственных приложений в облаке*.

## <a name="backing-services"></a>Резервные службы

Собственные системы в облаке зависят от множества различных вспомогательных ресурсов, таких как хранилища данных, брокеры сообщений, мониторинг и службы удостоверений. Эти службы называются [резервными службами](https://12factor.net/backing-services).

 На рис. 1-7 показаны многие распространенные службы резервного копирования, используемые в облачных системах.

![Распространенные службы резервного копирования](./media/common-backing-services.png)

**Рис. 1-7**. Распространенные службы резервного копирования

Резервные службы повлияют на принцип "Стателесснесс" из [12-факторного приложения](https://12factor.net/), рассмотренного выше в главе.

>*Фактор \#6* указывает, что каждая микрослужба должна выполняться в собственном процессе, изолированном от других работающих служб. Выносить требуется состояние для службы резервного копирования, такой как распределенный кэш или хранилище данных ".

Можно разместить собственные резервные службы, но вы должны быть ответственными за лицензирование, подготовку и управление этими ресурсами.

Поставщики облачных услуг предлагают широкий спектр *управляемых резервных служб.* Вместо того, чтобы присвоить службе, достаточно просто ее использовать. Поставщик управляет ресурсами в масштабе и несет ответственность за производительность, безопасность и обслуживание. Мониторинг, избыточность и доступность встроены в службу. Поставщики полностью поддерживают свои управляемые службы. Откройте билет и устраните проблему.

Облачные системы применяют управляемые резервные службы от поставщиков облачных служб. Экономия времени и усилий отлично подходит. Рабочий риск размещения собственных и неисправностей может быстро стать дорогостоящим.

Рекомендуется рассматривать резервную службу как *подключенный ресурс*, динамически привязанный к микрослужбе с информацией (URL-адресом и учетными данными), хранящимися во внешней конфигурации. Это руководство написано в составе [приложения 12-факторного уровня](https://12factor.net/), которое обсуждалось ранее в главе.

>*Коэффициент \#4* указывает, что резервные службы должны предоставляться через АДРЕСНЫЙ URL-адрес. Это приведет к отделению ресурса от приложения, что позволит ему быть взаимозаменяемым.

>*Коэффициент \#3* указывает, что "сведения о конфигурации перемещаются из микрослужбы и изменяются с помощью средства управления конфигурацией за пределами кода".

В этом шаблоне резервная служба может быть присоединена и отсоединена без изменения кода. Микрослужбу из раздела "вопросы и ответы" можно повысить до промежуточной среды. Необходимо обновить конфигурацию микрослужбы, чтобы она указывала на резервные службы в промежуточном хранилище, и внедрить параметры в контейнер с помощью переменной среды.

Поставщики облачных служб предоставляют интерфейсы API для взаимодействия со своими собственными резервными службами. Эти библиотеки инкапсулируют коммуникации и сложность. Непосредственное взаимодействие с этими API-интерфейсами обеспечивает тесное связывание кода со службой резервного копирования. Рекомендуется изолировать сведения о реализации API поставщика. Познакомьтесь с уровнем взаимодействий или промежуточным API, который предоставляет общий доступ к коду службы. Эта слабая связь позволяет переключать одну резервную службу на другую или перемещать код в другое общедоступное облако без внесения изменений в код службы магистрали.

Службы резервного копирования подробно обсуждаются в главе 5, в *собственных шаблонах данных в облаке*, а глав 4 — в *собственных шаблонах взаимодействия*.

## <a name="automation"></a>автоматизация

Как вы уже видели, облачные системы используют микрослужбы, контейнеры и современные архитектурные системы для достижения максимальной скорости и гибкости. Но это лишь часть истории. Как подготавливать облачные среды, в которых работают эти системы? Как быстро развертывать функции и обновления приложений? Как округлить полную картину?

Введите общепринятое практическое занятие [инфраструктуры как код](https://docs.microsoft.com/azure/devops/learn/what-is-infrastructure-as-code)или IaC.

С помощью IaC вы Автоматизируйте подготовку платформы и развертывание приложений. По сути, вы применяете методики проектирования программного обеспечения, такие как тестирование и управление версиями, в DevOps. Ваша инфраструктура и развертывания являются автоматизированными, постоянными и повторяемыми.

### <a name="automating-infrastructure"></a>Автоматизация инфраструктуры

Такие средства, как [Azure Resource Manager](https://azure.microsoft.com/documentation/articles/resource-group-overview/), Terraform и [Azure CLI](https://docs.microsoft.com/cli/azure/), позволяют декларативно создать скрипт для необходимой облачной инфраструктуры. Имена ресурсов, расположения, емкости и секреты являются параметризованными и динамическими. Скрипт имеет версию и возвращается в систему управления версиями в качестве артефакта проекта. Сценарий вызывается для обеспечения согласованной и повторяемой инфраструктуры в системных средах, таких как контроль качества, промежуточное и рабочее.

Внутри IaC — идемпотентными, то есть вы можете выполнять один и тот же сценарий без побочных эффектов. Если команде необходимо внести изменения, они редактируют и повторно запускают скрипт. Затрагиваются только обновленные ресурсы.

В статье понятие " [инфраструктура как код](https://docs.microsoft.com/azure/devops/learn/what-is-infrastructure-as-code)", автор SAM Гукенхаймера описывает, как "команды, реализующие IaC, могут быстро доставлять стабильные среды и масштабировать их. Команды избегают ручной настройки сред и обеспечивают согласованность, представляя требуемое состояние своих сред с помощью кода. Развертывания инфраструктуры с IaC являются повторяемыми и предотвращают проблемы во время выполнения, вызванные отклонением конфигурации или отсутствием зависимостей. Команды DevOps могут работать вместе с единым набором практических рекомендаций и средств для быстрой и надежной доставки приложений и их поддерживающих инфраструктуры. "

### <a name="automating-deployments"></a>Автоматизация развертываний

Более [12-факторное приложение](https://12factor.net/), рассмотренное ранее, вызывает отдельные шаги при преобразовании завершенного кода в выполняющееся приложение.

> *Фактор \#5* указывает, что "каждый выпуск должен обеспечивать строгое разделение на этапах сборки, выпуска и запуска. Каждый из них должен быть помечен уникальным ИДЕНТИФИКАТОРом и поддерживать возможность отката.

Современные системы CI/CD помогают выполнить этот принцип. Они предоставляют отдельные шаги по развертыванию и обеспечивают единообразный и качественный код, доступный пользователям.

На рисунке 1-8 показано разделение между процессом развертывания.

![Этапы развертывания в конвейере CI/CD](./media/build-release-run-pipeline.png)

**Рис. 1-8**. Этапы развертывания в конвейере CI/CD

На предыдущем рисунке особое внимание уделяется разделению задач.

Разработчик конструирует функцию в своей среде разработки, просматривая, что называется внутренним циклом кода, выполнения и отладки. По завершении этот код *помещается* в репозиторий кода, например GitHub, Azure DevOps или BitBucket.

Принудительная отправка активирует этап сборки, который преобразует код в двоичный артефакт. Работа реализуется с помощью конвейера [непрерывной интеграции (CI)](https://martinfowler.com/articles/continuousIntegration.html) . Он автоматически создает, тестирует и упаковывает приложение.

На этапе выпуска выполняется выбор двоичного артефакта, применяются сведения о конфигурации внешнего приложения и среды, а также создается неизменяемый выпуск. Выпуск развертывается в указанную среду. Работа реализуется с помощью конвейера [непрерывной поставки (CD)](https://martinfowler.com/bliki/ContinuousDelivery.html) . Каждый выпуск следует идентифицировать. Можно сказать: «в этом развертывании выполняется выпуск с обновлением программного продукта».

Наконец, выпущенная функция запускается в целевой среде выполнения. Выпуски являются неизменяемыми, поэтому любое изменение должно создать новый выпуск.

Применение этих рекомендаций позволяет организациям радикально развивать, как они поставляют программное обеспечение. Многие из квартальных выпусков перемещаются в обновления по запросу. Цель состоит в том, чтобы перехватить проблемы на ранних этапах цикла разработки, если их устранение меньше затратно. Чем дольше продолжительность между интеграцией, тем более дорогостоящими могут быть проблемы.  Благодаря согласованности в процессе интеграции группы могут чаще зафиксировать изменения кода, что повышает эффективность совместной работы и качества программного обеспечения.

### <a name="azure-pipelines"></a>Azure Pipelines

Облако Azure включает новую службу CI/CD, озаглавленную [Azure pipelines](https://azure.microsoft.com/services/devops/pipelines/), которая является частью предложения [Azure DevOps](https://azure.microsoft.com/services/devops/) , показанного на рис. 1-9.

![Azure Pipelines в DevOps](./media/devops-components.png)

**Рис. 1-9**. Предложения Azure DevOps

Azure Pipelines — это облачная служба, которая сочетает непрерывную интеграцию (CI) и непрерывную доставку (CD). Вы можете автоматически тестировать, собирать и поставлять код в любой целевой объект.

Вы определяете конвейер в коде в файле YAML вместе с остальной частью кода приложения.

- Код конвейера имеет версию кода и соответствует той же структуре ветвления.
- Вы получаете проверку изменений с помощью проверок кода в запросах на вытягивание и политиках построения ветви.
- Каждая используемая ветвь может настраивать политику сборки, изменяя файл Азуре-пипелинес. yml.
- Файл конвейера возвращается в систему управления версиями, и его можно исследовать, если возникла проблема.

Служба Azure Pipelines поддерживает большинство поставщиков Git и может создавать конвейеры развертывания для приложений, написанных на платформах Linux, macOS или Windows. Он включает поддержку Java, .NET, JavaScript, Python, PHP, Go, XCode и C++.

>[!div class="step-by-step"]
>[Назад](introduction.md)
>[Вперед](candidate-apps.md)
