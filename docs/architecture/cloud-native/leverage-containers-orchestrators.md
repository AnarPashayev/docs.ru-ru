---
title: Использование контейнеров и оркестраторов
description: Использование контейнеров DOCKER и orchestration Kubernetes в Azure
ms.date: 05/31/2020
ms.openlocfilehash: f9e8672b742217388bd719262ffdfee63618fd14
ms.sourcegitcommit: 27a15a55019f6b5f2733961738babe94aec0def3
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 09/15/2020
ms.locfileid: "90540547"
---
# <a name="leveraging-containers-and-orchestrators"></a>Использование контейнеров и оркестраторов

Контейнеры и оркестрации предназначены для решения проблем, характерных для монолитных подходов к развертыванию.

## <a name="challenges-with-monolithic-deployments"></a>Проблемы с монолитными развертываниями

Обычно большинство приложений развернуты как единое целое. Такие приложения называются монолитными. Этот общий подход к развертыванию приложений в виде отдельных единиц, даже если они состоят из нескольких модулей или сборок, называется монолитной архитектурой, как показано на рисунке 3-1.

![Монолитная архитектура.](./media/monolithic-design.png)

**Рис. 3-1**. Монолитная архитектура.

Хотя они имеют преимущество простоты, монолитные архитектуры сталкиваются с несколькими проблемами:

### <a name="deployment"></a>Развертывание

Для монолитных приложений требуется полное развертывание всего приложения, даже если было внесено небольшое изменение. Полные развертывания могут быть дорогостоящими и подвержены ошибкам. Кроме того, они нуждаются в перезапуске приложения, временно влияющем на недоступность.

### <a name="scaling"></a>Масштабирование

Монолитное приложение полностью размещается на одном экземпляре компьютера, что часто требует наличия оборудования с высокой степенью возможностей. Если для какой бы то ни было части монолита требуется масштабирование, то на другой компьютер должна быть развернута еще одна копия всего приложения. С монолитой вы не можете масштабировать компоненты приложения по отдельности — все или ничего. Масштабирование компонентов, которые не требуют масштабирования, приводит к неэффективному и дорогостоящему использованию ресурсов.

### <a name="environment"></a>Среда

Монолитные приложения обычно развертываются в среде размещения с предварительно установленными зависимостями операционной системы, среды выполнения и библиотек. Эта среда может не совпадать с той, на которой приложение было разработано или протестировано. Несогласованность между средами приложений является распространенным источником проблем для монолитных развертываний.

### <a name="coupling"></a>Тесн

Монолитное приложение, скорее всего, будет работать с высокой взаимозависимостью от функциональных компонентов. Без жестких границ системные изменения часто приводят к непредвиденным и дорогостоящим побочным эффектам. Новые функции и исправления становятся сложными, трудоемкими и затратными для реализации. Для обновлений требуется всестороннее тестирование. Связывание также затрудняет рефакторинг компонентов или замену в альтернативных реализациях. Даже при использовании строгого разделения проблем архитектурные еросион наборы в виде монолитной базы кода, как правило, приводит к разрушению незавершенных "особых случаев".

### <a name="platform-lock-in"></a>Блокировка платформы — в

Монолитное приложение создается с помощью одного стека технологий. При предоставлении единообразия это обязательство может стать препятствием для инноваций. Новые функции и компоненты будут создаваться с использованием текущего стека приложения, даже если более современные технологии могут быть лучшим выбором. Долгосрочный риск — ваш стек технологий становится устаревшим и устаревшим. При перепроектировании всего приложения до новой, более современной платформы лучше всего надорого и рискованно.

## <a name="what-are-the-benefits-of-containers-and-orchestrators"></a>Каковы преимущества контейнеров и оркестрации?

Мы предоставили контейнеры в главе 1. Мы выделили, каким образом облачная инфраструктура машинного кода (КНКФ) ранжирует схему в качестве первого шага в [собственных облачных](https://raw.githubusercontent.com/cncf/trailmap/master/CNCF_TrailMap_latest.png) руководствах по основам для предприятий, которые начинают свое облако в собственном облаке. В этом разделе обсуждаются преимущества контейнеров.

DOCKER — это самая популярная платформа управления контейнерами. Он работает с контейнерами как в Linux, так и в Windows. Контейнеры предоставляют отдельные, но воспроизводимые среды приложений, которые выполняются одинаково в любой системе. Этот аспект делает их идеальными для разработки и размещения облачных служб. Контейнеры изолированы друг от друга. Два контейнера на одном и том же оборудовании узла могут иметь разные версии программного обеспечения, не вызывая конфликтов.

Контейнеры определяются простыми текстовыми файлами, которые становятся артефактами проекта и возвращаются в систему управления версиями. Хотя для обновления полных серверов и виртуальных машин требуется ручное обновление, контейнеры легко контролируются версиями. Приложения, созданные для работы в контейнерах, можно разрабатывать, тестировать и развертывать с помощью автоматизированных средств в составе конвейера сборки.

Контейнеры являются неизменяемыми. После определения контейнера его можно повторно создать и запустить точно таким же образом. Эта неизменность предоставляет модель, основанную на компонентах. Если некоторые части приложения развиваются иначе, чем другие, то зачем развертывать все приложение, когда можно просто развернуть наиболее часто меняющиеся части? Различные функции и проблемы с перекрестной обрезкой приложения можно разбить на отдельные единицы. На рис. 3-2 показано, как монолитное приложение может использовать преимущества контейнеров и микрослужб, делегируя определенные функции или функциональные возможности. Остальные функции в самом приложении также были контейнерными.

![Разбивает монолитное приложение на использование микрослужб в серверной части.](./media/cloud-native-design.png)

**Рис. 3-2**. Разложение монолитного приложения для использования микрослужб.

Каждая облачная служба строится и развертывается в отдельном контейнере. Каждый из них может обновляться по мере необходимости. Отдельные службы могут размещаться на узлах с ресурсами, соответствующими каждой службе. Среда, в которой работает каждая служба, является неизменяемой, совместно используемой в средах разработки, тестирования и рабочей среды и легко связана с управлением версиями. Связь между различными областями приложения происходит явным образом в виде вызовов или сообщений между службами, а не зависимостями во время компиляции внутри монолиты. Вы также можете выбрать технологию, которая лучше всего подходит для данной возможности, не требуя внесения изменений в остальную часть приложения.

Для контейнерных служб требуется автоматическое управление. Было бы невозможным вручную администрировать большой набор независимо развернутых контейнеров. Например, рассмотрим следующие задачи:

- Как будут подготавливаться экземпляры контейнеров в кластере нескольких компьютеров?
- Как будет развернут, как контейнеры будут обнаруживать друг друга и обмениваться данными?
- Как контейнеры могут масштабироваться или по требованию?
- Как отслеживать работоспособность каждого контейнера?
- Как защитить контейнер от сбоев оборудования и программного обеспечения?
- Как обновить Контейнеры для активного приложения с нулевым временем простоя?

Оркестрации контейнеров позволяют решать и автоматизировать эти и другие задачи.

В облачной системе экономичной системы Kubernetes стал де-факто контейнером Orchestrator. Это платформа с открытым кодом, управляемая облачной средой Cloud Foundation (КНКФ). Kubernetes автоматизирует развертывание, масштабирование и эксплуатационные проблемы в контейнерных рабочих нагрузках в кластере компьютеров. Однако установка Kubernetes и управление ими являются сложными.

Гораздо лучшим подходом является использование Kubernetes в качестве управляемой службы от поставщика облачных служб. В облаке Azure реализована полностью управляемая платформа Kubernetes с [пакетом Azure Kubernetes Service (AKS)](https://azure.microsoft.com/services/kubernetes-service/). AKS абстрагирует сложность и эксплуатационные издержки на управление Kubernetes. Использование Kubernetes в качестве облачной службы; Корпорация Майкрософт несет ответственность за управление и поддержку. AKS также тесно интегрируется с другими службами Azure и средствами разработки.

AKS — это технология на основе кластера. Пул федеративных виртуальных машин или узлов развертывается в облаке Azure. Вместе они формируют среду высокой доступности или кластер. Кластер выглядит как простая единая сущность для собственного облачного приложения. В этом случае AKS развертывает контейнерные службы на этих узлах после предопределенной стратегии, которая равномерно распределяет нагрузку.

## <a name="what-are-the-scaling-benefits"></a>Каковы преимущества масштабирования?

Службы, созданные на основе контейнеров, могут использовать преимущества масштабирования, предоставляемые средствами оркестрации, такими как Kubernetes. По проектам контейнеры хорошо осведомлены о себе. После создания нескольких контейнеров, которые должны работать вместе, следует упорядочить их на более высоком уровне. Организация большого количества контейнеров и их общих зависимостей, таких как конфигурация сети, заключается в том, где средства оркестрации могут сэкономить день! Kubernetes создает слой абстракции для групп контейнеров и организует *их в модули*Pod. Модули Pod выполняются на рабочих компьютерах, которые называются *узлами*. Эта организованная структура называется *кластером*. На рис. 3-3 показаны различные компоненты кластера Kubernetes.

![Компоненты кластера Kubernetes. ](./media/kubernetes-cluster-components.png)
 **Рис. 3-3**. Компоненты кластера Kubernetes.

Масштабирование контейнерных рабочих нагрузок является ключевой функцией оркестрации контейнеров. AKS поддерживает автоматическое масштабирование в двух измерениях: экземпляры контейнеров и расчетные узлы. Вместе они дают AKS возможность быстро и эффективно реагировать на всплески спроса и добавлять дополнительные ресурсы. Далее в этой главе обсуждается масштабирование в AKS.

### <a name="declarative-versus-imperative"></a>Декларативная и императивная

Kubernetes поддерживает как декларативную, так и императивную конфигурацию. Императивный подход включает выполнение различных команд, которые сообщают Kubernetes, что делать каждый шаг. Запустите этот образ. Удалите этот модуль. Предоставление этого порта. С помощью декларативного подхода вы создаете файл конфигурации, который называется манифестом, чтобы описать, что вам нужно, а не делать. Kubernetes считывает манифест и преобразует требуемое конечное состояние в фактическое конечное состояние.

Императивные команды прекрасно подходят для обучения и интерактивного эксперимента. Однако необходимо декларативно создать файлы манифеста Kubernetes, чтобы использовать инфраструктуру в качестве подхода к коду, обеспечивая надежность и повторяемые развертывания. Файл манифеста становится артефактом проекта и используется в конвейере CI/CD для автоматизации развертываний Kubernetes.

Если вы уже настроили кластер с помощью императивных команд, можно экспортировать декларативный манифест с помощью `kubectl get svc SERVICENAME -o yaml > service.yaml` . Эта команда создает манифест, аналогичный показанному ниже.

```yaml
apiVersion: v1
kind: Service
metadata:
  creationTimestamp: "2019-09-13T13:58:47Z"
  labels:
    component: apiserver
    provider: kubernetes
  name: kubernetes
  namespace: default
  resourceVersion: "153"
  selfLink: /api/v1/namespaces/default/services/kubernetes
  uid: 9b1fac62-d62e-11e9-8968-00155d38010d
spec:
  clusterIP: 10.96.0.1
  ports:
  - name: https
    port: 443
    protocol: TCP
    targetPort: 6443
  sessionAffinity: None
  type: ClusterIP
status:
  loadBalancer: {}
```

При использовании декларативной конфигурации можно предварительно просмотреть изменения, которые будут сделаны до их фиксации, используя `kubectl diff -f FOLDERNAME` для папки, в которой находятся файлы конфигурации. Убедившись, что изменения необходимо применить, выполните команду `kubectl apply -f FOLDERNAME` . Добавьте `-R` в рекурсивную обработку иерархии папок.

Также можно использовать декларативную конфигурацию с другими функциями Kubernetes, одной из которых является развертывание. Декларативные развертывания помогают управлять выпусками, обновлениями и масштабированием. Они указывают контроллеру развертывания Kubernetes о том, как развертывать новые изменения, масштабировать нагрузку и откатить до предыдущей редакции. Если кластер работает нестабильно, декларативное развертывание автоматически вернет кластер в нужное состояние. Например, если узел должен аварийно завершить работу, механизм развертывания повторно развертывает замену для достижения требуемого состояния.

Использование декларативной конфигурации позволяет представить инфраструктуру в виде кода, который можно возвратить и поработать с версиями вместе с кодом приложения. Он обеспечивает улучшенный контроль изменений и улучшенную поддержку непрерывного развертывания с помощью конвейера сборки и развертывания.

## <a name="what-scenarios-are-ideal-for-containers-and-orchestrators"></a>Какие сценарии идеально подходят для контейнеров и оркестрации?

Следующие сценарии идеально подходят для использования контейнеров и оркестрации.

### <a name="applications-requiring-high-uptime-and-scalability"></a>Приложения, которым требуются высокая отказоустойчивость и масштабируемость

Отдельные приложения с высокой степенью бесперебойной работы и требованиями к масштабируемости являются идеальным кандидатом для собственных облачных архитектур, использующих микрослужбы, контейнеры и оркестрации. Их можно разрабатывать в контейнерах, тестировать в средах с управлением версиями и развертывать в рабочей среде с нулевым временем простоя. Использование кластеров Kubernetes гарантирует, что такие приложения также могут масштабироваться по запросу и автоматически восстанавливаться при сбоях узлов.

### <a name="large-numbers-of-applications"></a>Большое число приложений

Организации, которые развертывают и обслуживают большое количество приложений, получают преимущество от контейнеров и оркестрации. Настройка контейнерных сред и кластеров Kubernetes в первую очередь является фиксированной ценой. Для развертывания, обслуживания и обновления отдельных приложений стоимость зависит от количества приложений. Помимо небольшого числа приложений сложность обслуживания пользовательских приложений вручную превышает затраты на реализацию решения с помощью контейнеров и оркестрации.

## <a name="when-should-you-avoid-using-containers-and-orchestrators"></a>Когда следует избегать использования контейнеров и оркестрации?

Если вы не можете создать приложение, следуя принципам применения двенадцати факторов, следует рассмотреть возможность исключения контейнеров и оркестрации. В таких случаях рассмотрим платформу размещения на основе виртуальных машин или, возможно, некоторую гибридную систему. С его помощью можно всегда отключать определенные части функциональности в отдельные контейнеры или даже бессерверные функции.

## <a name="development-resources"></a>Ресурсы по разработке

В этом разделе приведен краткий список ресурсов по разработке, которые могут помочь приступить к использованию контейнеров и оркестрации для следующего приложения. Если вы ищете рекомендации по проектированию собственного облачного приложения архитектуры микрослужб, ознакомьтесь с руководством по работе с этой книгой, [микрослужбами .NET: архитектурой для контейнерных приложений .NET](https://dotnet.microsoft.com/download/thank-you/microservices-architecture-ebook).

### <a name="local-kubernetes-development"></a>Локальная разработка Kubernetes

Развертывания Kubernetes обеспечивают отличное значение в рабочих средах, но также могут выполняться локально на компьютере разработки. Хотя вы можете работать с отдельными микрослужбами независимо, иногда приходится запускать всю систему локально — так же, как она будет выполняться при развертывании в рабочей среде. Существует несколько средств, которые могут помочь: Minikube и DOCKER Desktop. Visual Studio также предоставляет средства для разработки DOCKER.

### <a name="minikube"></a>Minikube

Что такое Minikube? Проект Minikube говорит «Minikube реализует локальный кластер Kubernetes в macOS, Linux и Windows». Ее основными целями являются «лучший инструмент для разработки локальных Kubernetes приложений и поддержка всех функций Kubernetes». Установка Minikube отделена от DOCKER, но Minikube поддерживает различные низкоуровневые оболочки, чем поддерживает DOCKER Desktop. В настоящее время Minikube поддерживает следующие функции Kubernetes:

- DNS
- нодепортс
- Конфигмапс и секреты
- Панели мониторинга
- Среды выполнения контейнеров: DOCKER, RKT, CRI-O и контейнеры
- Включение сетевого интерфейса контейнера (CNI)
- Входящий трафик

После установки Minikube можно быстро приступить к работе, выполнив `minikube start` команду, которая скачивает образ и запускает локальный кластер Kubernetes. После запуска кластера вы взаимодействуете с ним с помощью стандартных команд Kubernetes `kubectl` .

### <a name="docker-desktop"></a>Docker Desktop

Вы также можете работать с Kubernetes непосредственно из DOCKER Desktop в Windows. Это единственный вариант, если вы используете контейнеры Windows, а также отличный выбор для контейнеров, отличных от Windows. На рис. 3-4 показано, как включить поддержку локальных Kubernetes при работе с DOCKER Desktop.

![Настройка Kubernetes в DOCKER Desktop](./media/docker-desktop-kubernetes.png)

**Рис. 3-4**. Настройка Kubernetes в DOCKER Desktop.

DOCKER Desktop — это наиболее популярное средство для локальной настройки и запуска контейнерных приложений. При работе с DOCKER Desktop можно разрабатывать локально на основе того же набора образов контейнеров DOCKER, который будет развернут в рабочей среде. Приложение DOCKER Desktop предназначено для локального создания, тестирования и поставки контейнерных приложений. Он поддерживает контейнеры Linux и Windows. После отправки образов в реестр образов, например реестр контейнеров Azure или DOCKER Hub, AKS может извлечь и развернуть их в рабочей среде.

### <a name="visual-studio-docker-tooling"></a>Инструментарий DOCKER в Visual Studio

Visual Studio поддерживает разработку с помощью DOCKER для веб-приложений. При создании нового ASP.NET Core приложения вы можете настроить его с помощью поддержки DOCKER, как показано на рис. 3-5.

![Visual Studio включить поддержку DOCKER](./media/visual-studio-enable-docker-support.png)

**Рис. 3-5**. Visual Studio включить поддержку DOCKER

Если выбран этот параметр, проект создается с помощью `Dockerfile` в корневом каталоге, который можно использовать для сборки и размещения приложения в контейнере DOCKER. Пример Dockerfile показан на рис. 3 -6. git

```dockerfile
FROM mcr.microsoft.com/dotnet/core/aspnet:3.1-buster-slim AS base
WORKDIR /app
EXPOSE 80
EXPOSE 443

FROM mcr.microsoft.com/dotnet/core/sdk:3.1-buster AS build
WORKDIR /src
COPY ["eShopWeb/eShopWeb.csproj", "eShopWeb/"]
RUN dotnet restore "eShopWeb/eShopWeb.csproj"
COPY . .
WORKDIR "/src/eShopWeb"
RUN dotnet build "eShopWeb.csproj" -c Release -o /app/build

FROM build AS publish
RUN dotnet publish "eShopWeb.csproj" -c Release -o /app/publish

FROM base AS final
WORKDIR /app
COPY --from=publish /app/publish .
ENTRYPOINT ["dotnet", "eShopWeb.dll"]
```

**Рис. 3-6**. Visual Studio Generated Dockerfile

Поведение по умолчанию при запуске приложения настроено на использование DOCKER. На рис. 3-7 показаны различные параметры запуска, доступные в новом проекте ASP.NET Core, созданном с помощью добавленной поддержки DOCKER.

![Параметры запуска для Visual Studio DOCKER](./media/visual-studio-docker-run-options.png)

**Рис. 3-7**. Параметры запуска для Visual Studio DOCKER

Помимо локальной разработки [Azure dev Spaces](https://docs.microsoft.com/azure/dev-spaces/) предоставляет несколько разработчикам удобный способ работы с собственными конфигурациями Kubernetes в Azure. Как видно на рисунке 3-7, приложение можно также запустить в Azure Dev Spaces.

Кроме того, в любое время можно добавить поддержку DOCKER в существующее приложение ASP.NET Core. В Обозреватель решений Visual Studio щелкните правой кнопкой мыши проект и **добавьте**  >  **поддержку DOCKER**, как показано на рис. 3-8.

![Поддержка добавления DOCKER в Visual Studio](./media/visual-studio-add-docker-support.png)

**Рис. 3-8**. Добавление поддержки DOCKER в Visual Studio

Также можно добавить поддержку оркестрации контейнера, также показанную на рисунке 3-8. По умолчанию Orchestrator использует Kubernetes и Helm. После выбора Orchestrator в `azds.yaml` корневой каталог проекта добавляется файл, и `charts` добавляется папка, содержащая диаграммы Helm, используемые для настройки и развертывания приложения в Kubernetes. На рис. 3-9 показаны итоговые файлы в новом проекте.

![Добавление поддержки Orchestrator в Visual Studio](./media/visual-studio-add-orchestrator-support.png)

**Рис. 3-9**. Добавление поддержки оркестрации в Visual Studio

### <a name="visual-studio-code-docker-tooling"></a>Visual Studio Code средства DOCKER

Для Visual Studio Code, поддерживающих разработку DOCKER, доступно несколько расширений.

Microsoft предоставляет [DOCKER для расширения Visual Studio Code](https://marketplace.visualstudio.com/items?itemName=ms-azuretools.vscode-docker). Это расширение упрощает процесс добавления поддержки контейнеров в приложения. Он формирует шаблоны для необходимых файлов, создает образы DOCKER и позволяет выполнять отладку приложения в контейнере. Расширение включает в себя визуальный обозреватель, который упрощает выполнение действий с контейнерами и изображениями, такими как запуск, завершение, проверка, удаление и многое другое. Расширение также поддерживает Docker Compose, что позволяет управлять несколькими работающими контейнерами как одним блоком.

>[!div class="step-by-step"]
>[Назад](scale-applications.md)
>[Вперед](leverage-serverless-functions.md)
