---
title: Кэширование в приложении, ориентированном на облако
description: Узнайте о стратегиях кэширования в собственном приложении для облака.
author: robvet
ms.date: 05/17/2020
ms.openlocfilehash: 84860ad4583e4b45d5ca9490d9f0167e7439d3d4
ms.sourcegitcommit: 5b475c1855b32cf78d2d1bbb4295e4c236f39464
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 09/24/2020
ms.locfileid: "91161091"
---
# <a name="caching-in-a-cloud-native-app"></a>Кэширование в собственном приложении для облака

Преимущества кэширования хорошо понятны. Этот метод позволяет временно скопировать часто используемые данные из серверного хранилища данных в *Быстрое хранилище* , расположенное ближе к приложению. Кэширование часто реализуется там, где...

- Данные остаются относительно статическими.
- Доступ к данным выполняется медленно, особенно по сравнению с скоростью кэша.
- На данные налагаются высокие уровни конкуренции.

## <a name="why"></a>Почему?

Как обсуждалось в [руководстве по кэшированию Microsoft](/azure/architecture/best-practices/caching), кэширование может повысить производительность, масштабируемость и доступность для отдельных микрослужб и системы в целом. Это сокращает задержку и состязание за обработку больших объемов параллельных запросов к хранилищу данных. По мере увеличения объема данных и числа пользователей повышается преимущество кэширования.

Кэширование наиболее эффективно, когда клиент многократно считывает неизменяемые данные или редко меняются. Примеры включают справочные сведения, такие как сведения о продуктах и ценах, или общие статические ресурсы, которые являются дорогостоящими для конструирования.

Хотя микрослужбы не имеют состояния, распределенный кэш может поддерживать одновременный доступ к данным состояния сеанса, когда это необходимо.

Также рассмотрите возможность кэширования, чтобы избежать повторяющихся вычислений. Если операция преобразует данные или выполняет сложное вычисление, кэширует результат для последующих запросов.

## <a name="caching-architecture"></a>Архитектура кэширования

Облачные машинные приложения обычно реализуют архитектуру распределенного кэширования. Кэш размещается как облачная [Служба резервного копирования](./definition.md#backing-services), отделенная от микрослужб. На рис. 5-15 показана архитектура.

![Кэширование в собственном облачном приложении](media/caching-in-a-cloud-native-app.png)

**Рис. 5-15**. кэширование в собственном облачном приложении

На предыдущем рисунке обратите внимание на то, как кэш не зависит от микрослужб и используется совместно. В этом сценарии кэш вызывается [шлюзом API](./front-end-communication.md). Как обсуждалось в главе 4, шлюз выступает в качестве внешнего интерфейса для всех входящих запросов. Распределенный кэш повышает скорость реагирования системы путем возвращения кэшированных данных везде, где это возможно. Кроме того, отделение кэша от служб позволяет кэшу независимо увеличивать или уменьшать размер кэша для удовлетворения увеличенных требований к трафику.

На предыдущем рисунке представлен общий шаблон кэширования, известный как [шаблон кэша](/azure/architecture/patterns/cache-aside). Для входящего запроса сначала необходимо запросить кэш (шаг \# 1) для ответа. Если объект найден, данные возвращаются немедленно. Если данные не существуют в кэше (называемые [промахом кэша](https://www.techopedia.com/definition/6308/cache-miss)), они извлекаются из локальной базы данных в подчиненной службе (шаг \# 2). Затем он записывается в кэш для будущих запросов (шаг \# 3) и возвращается вызывающему. Необходимо принять меры для периодического исключения кэшированных данных, чтобы система своевременно и стабильно выполнялась.

По мере роста общего кэша может оказаться полезным секционировать данные на нескольких узлах. Это позволит сократить состязание и повысить масштабируемость. Многие службы кэширования поддерживают возможность динамического добавления и удаления узлов и перераспределения данных по секциям. Этот подход обычно включает кластеризацию. Кластеризация предоставляет коллекцию федеративных узлов в виде простого единого кэша. Однако на внутреннем уровне данные распределены между узлами после предопределенной стратегии распределения, которая равномерно распределяет нагрузку.

## <a name="azure-cache-for-redis"></a>Кэш Redis для Azure

[Кэш Azure для Redis](https://azure.microsoft.com/services/cache/) — это безопасное кэширование данных и служба посредника обмена сообщениями, полностью управляемая корпорацией Майкрософт. Использование в качестве предложения платформы как услуги (PaaS) обеспечивает высокую пропускную способность и низкую задержку доступа к данным. Служба доступна для любого приложения в среде Azure или за ее пределами.

Кэш Azure для службы Redis управляет доступом к серверам Redis с открытым исходным кодом, размещенным в центрах обработки данных Azure. Служба выступает в качестве фасадной для управления, контроля доступа и безопасности. Служба изначально поддерживает обширный набор структур данных, включая строки, хэши, списки и наборы. Если приложение уже использует Redis, оно будет работать как есть с кэшем Azure для Redis.

Кэш Azure для Redis — это больше, чем простой сервер кэша. Она может поддерживать ряд сценариев для расширения архитектуры микрослужб:

- Хранилище данных в памяти
- Распределенная нереляционная база данных
- Брокер сообщений
- Сервер конфигурации или обнаружения;
  
В сложных сценариях копия кэшированных данных может быть [сохранена на диске](/azure/azure-cache-for-redis/cache-how-to-premium-persistence). Если аварийное событие отключает как основной, так и кэш реплик, кэш восстанавливается из последнего моментального снимка.

Кэш Redis для Azure доступен в нескольких предварительно определенных конфигурациях и ценовых категориях. На [уровне Premium](/azure/azure-cache-for-redis/cache-overview#service-tiers) реализовано множество функций корпоративного уровня, таких как кластеризация, сохраняемость данных, Георепликация и изоляция виртуальных сетей.

>[!div class="step-by-step"]
>[Назад](relational-vs-nosql-data.md)
>[Вперед](elastic-search-in-azure.md)
