---
title: Метрики ML.NET
description: Общие сведения о метриках, которые используются для оценки производительности модели ML.NET
ms.date: 12/17/2019
ms.openlocfilehash: 8e823fd8cc344c1b8e0ecd709b527137368cbfa0
ms.sourcegitcommit: 9a97c76e141333394676bc5d264c6624b6f45bcf
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 01/08/2020
ms.locfileid: "75739604"
---
# <a name="evaluate-your-mlnet-model-with-metrics"></a>Оценка модели ML.NET с помощью метрик

Общие сведения о метриках, которые используются для оценки модели ML.NET.

Требуемые метрики оценки зависят от типа задачи машинного обучения, которую выполняет модель.

Например, для выполнения задачи классификации модель оценивается путем измерения того, насколько хорошо прогнозируемая категория соответствует фактической категории. Для задачи кластеризации оценка производится на основе того, насколько близко кластерные элементы находятся друг к другу и насколько велико расстояние между кластерами.

## <a name="evaluation-metrics-for-binary-classification"></a>Метрики оценки для двоичной классификации

| metrics   |      Описание      |  Вы ищете |
|-----------|-----------------------|-----------|
| **Точность** |  [Точность](https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification) — это доля правильных прогнозов с помощью проверочного набора данных. Это соотношение числа правильно угаданных и общего числа примеров входных данных. Эта метрика работает хорошо, если существует аналогичное количество выборок, принадлежащих каждому классу.| **Чем ближе к 1,00, тем лучше**. Точное значение 1,00 говорит о проблемах (обычно это утечка меток и целей, переобучение или тестирование с помощью учебных данных). Если тестовые данные не сбалансированы (большинство экземпляров относится к одному из классов), набор данных мал или оценка подходит к значению 0,00 или 1,00, то точность не отражает фактическую эффективность классификатора и вам нужно проверить дополнительные метрики. |
| **AUC** |    [aucROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) или *площадь под кривой* оценивает площадь под кривой, созданной суммированием частот истинно положительных результатов и ложно положительных результатов.  |   **Чем ближе к 1,00, тем лучше**. Для того чтобы модель была допустима, ее значение должно быть больше 0,50. Модель со значением AUC не выше 0,50 неприменима. |
| **AUCPR** | [aucPR](https://www.coursera.org/lecture/ml-classification/precision-recall-curve-rENu8) или *площадь под кривой "точность — полнота"* : удобная мера успешного прогноза, когда классы различаются (крайне неравномерно распределенные наборы данных). |  **Чем ближе к 1,00, тем лучше**. Высокий уровень оценки, близкий к 1,00, показывает, что классификатор возвращает точные результаты (высокая точность), а также возвращает большую часть всех положительных результатов (высокий уровень полноты). |
| **Показатель F1** | [Показатель F1](https://en.wikipedia.org/wiki/F1_score) также называется *сбалансированной F-оценкой или F-мерой*. Это среднее гармоническое значение точности и полноты. Показатель F1 полезен в том случае, если необходимо найти баланс между точностью и полнотой.| **Чем ближе к 1,00, тем лучше**.  Показатель F1 достигает лучшего значения в 1,00 и худшего — в 0,00. Он сообщает, насколько точен классификатор. |

Дополнительные сведения о метриках бинарной классификации см. в следующих статьях:

- [Точность, полнота или F1?](https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9)
- [Класс метрик бинарной классификации](xref:Microsoft.ML.Data.BinaryClassificationMetrics)
- [Связь между кривыми "точность — полнота" и кривыми ROC](http://pages.cs.wisc.edu/~jdavis/davisgoadrichcamera2.pdf)

## <a name="evaluation-metrics-for-multi-class-classification"></a>Метрики оценки для многоклассовой классификации

| metrics   |      Описание      |  Вы ищете |
|-----------|-----------------------|-----------|
| **Микроточность** |  [Микросредняя точность](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MicroAccuracy) агрегирует вклады всех классов для вычисления среднего показателя. Это доля экземпляров, которые модель правильно спрогнозировала. Микросреднее не учитывает членство в классе. По сути, каждая пара "пример — класс" одинаково участвует в метрике точности. | **Чем ближе к 1,00, тем лучше**. В задаче многоклассовой классификации микроточность является предпочтительной по сравнению с макроточностью, если есть подозрение, что может присутствовать несбалансированность классов (например, гораздо больше примеров из одного класса, чем из других).|
| **Макроточность** | [Макросредняя точность](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MacroAccuracy) — это средняя точность на уровне класса. Вычисляется точность для каждого класса, а макроточность — это среднее этих значений. По сути, каждый класс одинаково участвует в этой метрике точности. Миноритарным классам назначается тот же вес, что и более крупным. Макросреднее значение метрики назначает один и тот же вес для каждого класса независимо от того, сколько экземпляров содержит класс набора данных. |  **Чем ближе к 1,00, тем лучше**.  Она вычисляет метрики независимо для каждого класса и затем берет среднее значение (поэтому все классы учитываются одинаково). |
| **Логарифмическая потеря**| [Логарифмическая потеря](http://wiki.fast.ai/index.php/Log_Loss) измеряет производительность модели классификации, где значение вероятности прогноза составляет от 0,00 до 1,00. Потеря увеличивается по мере отклонения прогнозируемой вероятности от фактического значения метки. | **Чем ближе к 0,00, тем лучше**. У идеальной модели значение потери равно 0,00. Цель нашей модели машинного обучения — свести к минимуму это значение.|
| **Редукция логарифмической потери** | [Редукцию логарифмических потери](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.LogLossReduction) можно интерпретировать как преимущество классификатора над случайным прогнозом.| **Имеет значения в диапазоне от -inf до 1,00, где 1,00 — идеальный прогноз, а 0,00 — средние прогнозы**. Например, если значение равно 0,20, оно может интерпретироваться как "вероятность правильного прогноза на 20 % лучше случайного угадывания".|

Обычно микроточность лучше согласуется с бизнес-потребностями прогнозов машинного обучения. Если вы хотите выбрать одну метрику для определения качества задачи многоклассовой классификации, обычно следует выбрать микроточность.

Например, для задачи классификации запросов в службу поддержки (сопоставляет входящие запросы в и команды службы поддержки)

- Микроточность — как часто входящий запрос передается подходящей команде сотрудников?
- Макроточность — как часто входящий запрос подходит для команды в среднем случае?

Макроточность перевешивает небольшие команды в этом примере; небольшие команды, которые получают только 10 обращений в год, учитываются наравне с большой командой с 10 000 обращений в год. В этом случае микроточность лучше коррелирует с бизнес-потребностями: "сколько времени и денег можно сэкономить, автоматизируя процесс маршрутизации запросов в службу".

Дополнительные сведения о метриках многоклассовой классификации см. в следующих статьях:

- [Запись блога о микро- и макросредних значениях точности, полноты и показателя F](https://rushdishams.blogspot.com/2011/08/micro-and-macro-average-of-precision.html)
- [Мультиклассовая классификация несбалансированных наборов данных](https://towardsdatascience.com/machine-learning-multiclass-classification-with-imbalanced-data-set-29f6a177c1a)

## <a name="evaluation-metrics-for-regression-and-recommendation"></a>Метрики оценки для задач регрессии и рекомендации

Задачи регрессии и рекомендации прогнозируют число. В случае регрессии число может быть любым выходным свойством, на которое влияют входные свойства. В случае рекомендации число обычно представляет собой значение оценки (например, от 1 до 5) или рекомендацию "да/нет" (представленную 1 и 0 соответственно).

| Метрика   |      Описание      |  Вы ищете |
|----------|-----------------------|-----------|
| **R-квадрат** |  [R-квадрат (R2)](https://en.wikipedia.org/wiki/Coefficient_of_determination) или *коэффициент детерминации* обозначает совокупную прогнозирующую способность модели в диапазоне от -inf до 1,00. 1,00 означает, что есть идеальное совпадение, но совпадение может быть произвольно плохим, поэтому оценки могут быть отрицательными. Оценка 0,00 означает, что модель прогнозирует ожидаемое значение для метки. R2 измеряет, насколько реальные значения данных близки к прогнозируемым. | **Чем ближе к 1,00, тем выше качество**. Тем не менее иногда низкие значения (например, 0,50) могут быть полностью нормальны или достаточны для вашего сценария, тогда как высокие значения не всегда подходят и могут быть подозрительными. |
| **Абсолютная потеря** |  [Абсолютная потеря](https://en.wikipedia.org/wiki/Mean_absolute_error), или *средняя абсолютная погрешность (MAE)* , измеряет, насколько прогнозы близки к фактическим результатам. Это среднее значение всех ошибок модели, где ошибка модели — абсолютное расстояние между значением прогнозируемой метки и значением правильной метки. Эта ошибка прогноза вычисляется для каждой записи проверочного набора данных. Наконец, среднее значение вычисляется для всех зарегистрированных абсолютных ошибок.| **Чем ближе к 0,00, тем выше качество.** Средняя абсолютная погрешность использует ту же шкалу данных, что и измеряемые данные (то есть не нормализуется до определенного диапазона). Абсолютная потеря, квадратичная потеря и среднеквадратичная потеря могут использоваться только для сравнения моделей для одного набора данных или наборов данных с аналогичным распределением значений меток. |
| **Квадратичная потеря** |  [Квадратичная потеря](https://en.wikipedia.org/wiki/Mean_squared_error) (или *средний квадрат погрешности (MSE)* ; также называемая *среднеквадратичным отклонением (MSD)* ) указывает, насколько близка линия регрессии к набору значений тестовых данных. Это достигается путем вычисления расстояний от точек до линии регрессии ("ошибок") и возведением их в квадрат. Квадрат дает больше веса большим расстояниям. | Этот показатель всегда является неотрицательным, **значения ближе к 0,00 предпочтительнее**. В зависимости от данных может оказаться невозможным получить очень маленькое значение для среднеквадратичной ошибки.|
| **RMS-потеря** |  [RMS-потеря](https://en.wikipedia.org/wiki/Root-mean-square_deviation) (или *среднеквадратичная ошибка (RMSE)* ; также называемая *среднеквадратическим отклонением, RMSD*) измеряет разность между значениями, прогнозируемыми моделью, и значениями, наблюдаемыми в моделируемой среде. RMS-потеря — это квадратный корень из квадратной потери; она использует те же единицы, что и метка, аналогично абсолютной потере, но придает больший вес большей разности. Среднеквадратичная ошибка обычно используется в климатологии, прогнозировании и регрессионном анализе для проверки экспериментальных результатов. | Этот показатель всегда является неотрицательным, **значения ближе к 0,00 предпочтительнее**. RMSD — это мера точности для сравнения ошибок прогнозирования различных моделей на конкретном наборе данных, а не между наборами данных, так как она зависит от масштаба.|

Дополнительные сведения о метриках регрессии см. в следующих статьях:

- [Регрессионный анализ: как интерпретировать R-квадрат и оценить критерии соответствия?](https://blog.minitab.com/blog/adventures-in-statistics-2/regression-analysis-how-do-i-interpret-r-squared-and-assess-the-goodness-of-fit)
- [Способ интерпретации R-квадрата в регрессионном анализе](https://statisticsbyjim.com/regression/interpret-r-squared-regression)
- [Определение R-квадрата](https://www.investopedia.com/terms/r/r-squared.asp)
- [Определение среднеквадратической ошибки](https://www.statisticshowto.datasciencecentral.com/mean-squared-error/)
- [Что такое средний квадрат погрешности и среднеквадратичная ошибка?](https://www.vernier.com/til/1014/)

## <a name="evaluation-metrics-for-clustering"></a>Метрики оценки для кластеризации

| Метрика   |      Описание      |  Вы ищете |
|----------|-----------------------|-----------|
|**Среднее расстояние**|Среднее расстояние между точками данных и центром назначенного им кластера. Среднее расстояние — это мера близости точек данных к центроидам кластеров. Эта метрика указывает, насколько "плотным" является кластер.|Значения ближе к **0** предпочтительнее. Чем ближе среднее расстояние к нулю, тем более кластеризованы данные. Обратите внимание, что эта метрика будет уменьшаться, если количество кластеров увеличивается. В крайнем случае (где каждая отдельная точка данных является собственным кластером) она будет равна нулю.
|**Индекс Дэвиса — Болдина**|Среднее соотношение расстояний внутри кластера и расстояний между кластерами. Чем плотнее кластер и чем дальше кластеры друг от друга, тем ниже это значение.|Значения ближе к **0** предпочтительнее. Кластеры, которые находятся дальше друг от друга и являются менее распределенными, приведут к лучшей оценке.|
|**Нормализованная взаимная информация**|Эта метрика подходит, когда данные, используемые для обучения модели кластеризации, также поставляются с контрольными метками (то есть защищенной кластеризацией). Метрика "Нормализованная взаимная информация" показывает, назначаются ли одинаковые точки данных одному и тому же кластеру, а разные точки данных — различным кластерам. Эта метрика принимает значение от 0 до 1.|Значения ближе к **1** предпочтительнее.|

## <a name="evaluation-metrics-for-ranking"></a>Метрики оценки для ранжирования

| Метрика   |      Описание      |  Вы ищете |
|----------|-----------------------|-----------|
|**Дисконтированная совокупная прибыль**|Дисконтированная совокупная прибыль является мерой качества ранжирования. Она является производной от двух предположений. Первое: высоко релевантные элементы более полезны, если отображаются выше в порядке ранжирования. Второе: полезность отслеживает релевантность, то есть, чем выше релевантность, тем полезнее элемент. Дисконтированная совокупная прибыль рассчитывается для конкретной позиции в порядке ранжирования. Она суммирует оценку релевантности, деленную на логарифм индекса ранжирования до нужной позиции. Она рассчитывается с помощью формулы $\sum_{i=0}^{p} \frac {rel_i} {\log_{e}{i+1}}$. Оценки релевантности предоставляются алгоритму обучения ранжирования в качестве контрольных меток. Одно значение дисконтированной совокупной прибыли предоставляется для каждой позиции в таблице ранжирования, отсюда и название "Дисконтированная совокупная **прибыль**". |**Предпочтение отдается более высоким значениям**|
|**Нормализованная дисконтированная совокупная прибыль**|Нормализация дисконтированной совокупной прибыли позволяет сравнивать метрику для списков ранжирования различной длины.|**Значения ближе к 1 предпочтительнее**.|

## <a name="evaluation-metrics-for-anomaly-detection"></a>Метрики оценки для обнаружения аномалий

| Метрика   |      Описание      |  Вы ищете |
|----------|-----------------------|-----------|
|**Площадь под ROC-кривой**|Метрика "Площадь под ROC-кривой" показывает, насколько хорошо модель разделяет аномальные и обычные точки данных.|**Значения ближе к 1 предпочтительнее**. Только значения больше 0,5 демонстрируют эффективность модели. Значения 0,5 или ниже указывают, что модель работает не лучше, чем случайное распределение входных данных на категории аномальных и обычных.|
|**Частота обнаружения при количестве ложноположительных значений**|Частота обнаружения при количестве ложноположительных значений — это соотношение количества правильно определенных аномалий и общего количества аномалий в тестовом наборе, индексируемых по каждому ложноположительному результату. Таким образом, для каждого ложноположительного элемента существует значение частоты обнаружения при количестве ложных срабатываний.|**Значения ближе к 1 предпочтительнее**. Если ложные срабатывания отсутствуют, это значение равно 1.|
