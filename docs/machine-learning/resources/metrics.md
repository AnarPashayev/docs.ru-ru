---
title: Метрики ML.NET
description: Общие сведения о метриках, которые используются для оценки производительности модели ML.NET
ms.date: 12/17/2019
ms.openlocfilehash: 8e823fd8cc344c1b8e0ecd709b527137368cbfa0
ms.sourcegitcommit: 7588136e355e10cbc2582f389c90c127363c02a5
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/15/2020
ms.locfileid: "79397803"
---
# <a name="evaluate-your-mlnet-model-with-metrics"></a><span data-ttu-id="4fafa-103">Оценка модели ML.NET с помощью метрик</span><span class="sxs-lookup"><span data-stu-id="4fafa-103">Evaluate your ML.NET model with metrics</span></span>

<span data-ttu-id="4fafa-104">Общие сведения о метриках, которые используются для оценки модели ML.NET.</span><span class="sxs-lookup"><span data-stu-id="4fafa-104">Understand the metrics used to evaluate an ML.NET model.</span></span>

<span data-ttu-id="4fafa-105">Требуемые метрики оценки зависят от типа задачи машинного обучения, которую выполняет модель.</span><span class="sxs-lookup"><span data-stu-id="4fafa-105">Evaluation metrics are specific to the type of machine learning task that a model performs.</span></span>

<span data-ttu-id="4fafa-106">Например, для выполнения задачи классификации модель оценивается путем измерения того, насколько хорошо прогнозируемая категория соответствует фактической категории.</span><span class="sxs-lookup"><span data-stu-id="4fafa-106">For example, for the classification task, the model is evaluated by measuring how well a predicted category matches the actual category.</span></span> <span data-ttu-id="4fafa-107">Для задачи кластеризации оценка производится на основе того, насколько близко кластерные элементы находятся друг к другу и насколько велико расстояние между кластерами.</span><span class="sxs-lookup"><span data-stu-id="4fafa-107">And for clustering, evaluation is based on how close clustered items are to each other, and how much separation there is between the clusters.</span></span>

## <a name="evaluation-metrics-for-binary-classification"></a><span data-ttu-id="4fafa-108">Метрики оценки для двоичной классификации</span><span class="sxs-lookup"><span data-stu-id="4fafa-108">Evaluation metrics for Binary Classification</span></span>

| <span data-ttu-id="4fafa-109">metrics</span><span class="sxs-lookup"><span data-stu-id="4fafa-109">Metrics</span></span>   |      <span data-ttu-id="4fafa-110">Описание</span><span class="sxs-lookup"><span data-stu-id="4fafa-110">Description</span></span>      |  <span data-ttu-id="4fafa-111">Вы ищете</span><span class="sxs-lookup"><span data-stu-id="4fafa-111">Look for</span></span> |
|-----------|-----------------------|-----------|
| <span data-ttu-id="4fafa-112">**Точность**</span><span class="sxs-lookup"><span data-stu-id="4fafa-112">**Accuracy**</span></span> |  <span data-ttu-id="4fafa-113">[Точность](https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification) — это доля правильных прогнозов с помощью проверочного набора данных.</span><span class="sxs-lookup"><span data-stu-id="4fafa-113">[Accuracy](https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification) is the proportion of correct predictions with a test data set.</span></span> <span data-ttu-id="4fafa-114">Это соотношение числа правильно угаданных и общего числа примеров входных данных.</span><span class="sxs-lookup"><span data-stu-id="4fafa-114">It is the ratio of number of correct predictions to the total number of input samples.</span></span> <span data-ttu-id="4fafa-115">Эта метрика работает хорошо, если существует аналогичное количество выборок, принадлежащих каждому классу.</span><span class="sxs-lookup"><span data-stu-id="4fafa-115">It works well if there are similar number of samples belonging to each class.</span></span>| <span data-ttu-id="4fafa-116">**Чем ближе к 1,00, тем лучше**.</span><span class="sxs-lookup"><span data-stu-id="4fafa-116">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="4fafa-117">Точное значение 1,00 говорит о проблемах (обычно это утечка меток и целей, переобучение или тестирование с помощью учебных данных).</span><span class="sxs-lookup"><span data-stu-id="4fafa-117">But exactly 1.00 indicates an issue (commonly: label/target leakage, over-fitting, or testing with training data).</span></span> <span data-ttu-id="4fafa-118">Если тестовые данные не сбалансированы (большинство экземпляров относится к одному из классов), набор данных мал или оценка подходит к значению 0,00 или 1,00, то точность не отражает фактическую эффективность классификатора и вам нужно проверить дополнительные метрики.</span><span class="sxs-lookup"><span data-stu-id="4fafa-118">When the test data is unbalanced (where most of the instances belong to one of the classes), the dataset is small, or scores approach 0.00 or 1.00, then accuracy doesn’t really capture the effectiveness of a classifier and you need to check additional metrics.</span></span> |
| <span data-ttu-id="4fafa-119">**AUC**</span><span class="sxs-lookup"><span data-stu-id="4fafa-119">**AUC**</span></span> |    <span data-ttu-id="4fafa-120">[aucROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) или *площадь под кривой* оценивает площадь под кривой, созданной суммированием частот истинно положительных результатов и ложно положительных результатов.</span><span class="sxs-lookup"><span data-stu-id="4fafa-120">[aucROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) or *Area under the curve* measures the area under the curve created by sweeping the true positive rate vs. the false positive rate.</span></span>  |   <span data-ttu-id="4fafa-121">**Чем ближе к 1,00, тем лучше**.</span><span class="sxs-lookup"><span data-stu-id="4fafa-121">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="4fafa-122">Для того чтобы модель была допустима, ее значение должно быть больше 0,50.</span><span class="sxs-lookup"><span data-stu-id="4fafa-122">It should be greater than 0.50 for a model to be acceptable.</span></span> <span data-ttu-id="4fafa-123">Модель со значением AUC не выше 0,50 неприменима.</span><span class="sxs-lookup"><span data-stu-id="4fafa-123">A model with AUC of 0.50 or less is worthless.</span></span> |
| <span data-ttu-id="4fafa-124">**AUCPR**</span><span class="sxs-lookup"><span data-stu-id="4fafa-124">**AUCPR**</span></span> | <span data-ttu-id="4fafa-125">[aucPR](https://www.coursera.org/lecture/ml-classification/precision-recall-curve-rENu8) или *площадь под кривой "точность — полнота"* : удобная мера успешного прогноза, когда классы различаются (крайне неравномерно распределенные наборы данных).</span><span class="sxs-lookup"><span data-stu-id="4fafa-125">[aucPR](https://www.coursera.org/lecture/ml-classification/precision-recall-curve-rENu8) or *Area under the curve of a Precision-Recall curve*: Useful measure of success of prediction when the classes are imbalanced (highly skewed datasets).</span></span> |  <span data-ttu-id="4fafa-126">**Чем ближе к 1,00, тем лучше**.</span><span class="sxs-lookup"><span data-stu-id="4fafa-126">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="4fafa-127">Высокий уровень оценки, близкий к 1,00, показывает, что классификатор возвращает точные результаты (высокая точность), а также возвращает большую часть всех положительных результатов (высокий уровень полноты).</span><span class="sxs-lookup"><span data-stu-id="4fafa-127">High scores close to 1.00 show that the classifier is returning accurate results (high precision), as well as returning a majority of all positive results (high recall).</span></span> |
| <span data-ttu-id="4fafa-128">**Показатель F1**</span><span class="sxs-lookup"><span data-stu-id="4fafa-128">**F1-score**</span></span> | <span data-ttu-id="4fafa-129">[Показатель F1](https://en.wikipedia.org/wiki/F1_score) также называется *сбалансированной F-оценкой или F-мерой*.</span><span class="sxs-lookup"><span data-stu-id="4fafa-129">[F1 score](https://en.wikipedia.org/wiki/F1_score) also known as *balanced F-score or F-measure*.</span></span> <span data-ttu-id="4fafa-130">Это среднее гармоническое значение точности и полноты.</span><span class="sxs-lookup"><span data-stu-id="4fafa-130">It's the harmonic mean of the precision and recall.</span></span> <span data-ttu-id="4fafa-131">Показатель F1 полезен в том случае, если необходимо найти баланс между точностью и полнотой.</span><span class="sxs-lookup"><span data-stu-id="4fafa-131">F1 Score is helpful when you want to seek a balance between Precision and Recall.</span></span>| <span data-ttu-id="4fafa-132">**Чем ближе к 1,00, тем лучше**.</span><span class="sxs-lookup"><span data-stu-id="4fafa-132">**The closer to 1.00, the better**.</span></span>  <span data-ttu-id="4fafa-133">Показатель F1 достигает лучшего значения в 1,00 и худшего — в 0,00.</span><span class="sxs-lookup"><span data-stu-id="4fafa-133">An F1 score reaches its best value at 1.00 and worst score at 0.00.</span></span> <span data-ttu-id="4fafa-134">Он сообщает, насколько точен классификатор.</span><span class="sxs-lookup"><span data-stu-id="4fafa-134">It tells you how precise your classifier is.</span></span> |

<span data-ttu-id="4fafa-135">Дополнительные сведения о метриках бинарной классификации см. в следующих статьях:</span><span class="sxs-lookup"><span data-stu-id="4fafa-135">For further details on binary classification metrics read the following articles:</span></span>

- [<span data-ttu-id="4fafa-136">Точность, полнота или F1?</span><span class="sxs-lookup"><span data-stu-id="4fafa-136">Accuracy, Precision, Recall, or F1?</span></span>](https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9)
- [<span data-ttu-id="4fafa-137">Класс метрик бинарной классификации</span><span class="sxs-lookup"><span data-stu-id="4fafa-137">Binary Classification Metrics class</span></span>](xref:Microsoft.ML.Data.BinaryClassificationMetrics)
- [<span data-ttu-id="4fafa-138">Связь между кривыми "точность — полнота" и кривыми ROC</span><span class="sxs-lookup"><span data-stu-id="4fafa-138">The Relationship Between Precision-Recall and ROC Curves</span></span>](http://pages.cs.wisc.edu/~jdavis/davisgoadrichcamera2.pdf)

## <a name="evaluation-metrics-for-multi-class-classification"></a><span data-ttu-id="4fafa-139">Метрики оценки для многоклассовой классификации</span><span class="sxs-lookup"><span data-stu-id="4fafa-139">Evaluation metrics for Multi-class Classification</span></span>

| <span data-ttu-id="4fafa-140">metrics</span><span class="sxs-lookup"><span data-stu-id="4fafa-140">Metrics</span></span>   |      <span data-ttu-id="4fafa-141">Описание</span><span class="sxs-lookup"><span data-stu-id="4fafa-141">Description</span></span>      |  <span data-ttu-id="4fafa-142">Вы ищете</span><span class="sxs-lookup"><span data-stu-id="4fafa-142">Look for</span></span> |
|-----------|-----------------------|-----------|
| <span data-ttu-id="4fafa-143">**Микроточность**</span><span class="sxs-lookup"><span data-stu-id="4fafa-143">**Micro-Accuracy**</span></span> |  <span data-ttu-id="4fafa-144">[Микросредняя точность](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MicroAccuracy) агрегирует вклады всех классов для вычисления среднего показателя.</span><span class="sxs-lookup"><span data-stu-id="4fafa-144">[Micro-average Accuracy](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MicroAccuracy) aggregates the contributions of all classes to compute the average metric.</span></span> <span data-ttu-id="4fafa-145">Это доля экземпляров, которые модель правильно спрогнозировала.</span><span class="sxs-lookup"><span data-stu-id="4fafa-145">It is the fraction of instances predicted correctly.</span></span> <span data-ttu-id="4fafa-146">Микросреднее не учитывает членство в классе.</span><span class="sxs-lookup"><span data-stu-id="4fafa-146">The micro-average does not take class membership into account.</span></span> <span data-ttu-id="4fafa-147">По сути, каждая пара "пример — класс" одинаково участвует в метрике точности.</span><span class="sxs-lookup"><span data-stu-id="4fafa-147">Basically, every sample-class pair contributes equally to the accuracy metric.</span></span> | <span data-ttu-id="4fafa-148">**Чем ближе к 1,00, тем лучше**.</span><span class="sxs-lookup"><span data-stu-id="4fafa-148">**The closer to 1.00, the better**.</span></span> <span data-ttu-id="4fafa-149">В задаче многоклассовой классификации микроточность является предпочтительной по сравнению с макроточностью, если есть подозрение, что может присутствовать несбалансированность классов (например,</span><span class="sxs-lookup"><span data-stu-id="4fafa-149">In a multi-class classification task, micro-accuracy is preferable over macro-accuracy if you suspect there might be class imbalance (i.e</span></span> <span data-ttu-id="4fafa-150">гораздо больше примеров из одного класса, чем из других).</span><span class="sxs-lookup"><span data-stu-id="4fafa-150">you may have many more examples of one class than of other classes).</span></span>|
| <span data-ttu-id="4fafa-151">**Макроточность**</span><span class="sxs-lookup"><span data-stu-id="4fafa-151">**Macro-Accuracy**</span></span> | <span data-ttu-id="4fafa-152">[Макросредняя точность](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MacroAccuracy) — это средняя точность на уровне класса.</span><span class="sxs-lookup"><span data-stu-id="4fafa-152">[Macro-average Accuracy](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MacroAccuracy) is the average accuracy at the class level.</span></span> <span data-ttu-id="4fafa-153">Вычисляется точность для каждого класса, а макроточность — это среднее этих значений.</span><span class="sxs-lookup"><span data-stu-id="4fafa-153">The accuracy for each class is computed and the macro-accuracy is the average of these accuracies.</span></span> <span data-ttu-id="4fafa-154">По сути, каждый класс одинаково участвует в этой метрике точности.</span><span class="sxs-lookup"><span data-stu-id="4fafa-154">Basically, every class contributes equally to the accuracy metric.</span></span> <span data-ttu-id="4fafa-155">Миноритарным классам назначается тот же вес, что и более крупным.</span><span class="sxs-lookup"><span data-stu-id="4fafa-155">Minority classes are given equal weight as the larger classes.</span></span> <span data-ttu-id="4fafa-156">Макросреднее значение метрики назначает один и тот же вес для каждого класса независимо от того, сколько экземпляров содержит класс набора данных.</span><span class="sxs-lookup"><span data-stu-id="4fafa-156">The macro-average metric gives the same weight to each class, no matter how many instances from that class the dataset contains.</span></span> |  <span data-ttu-id="4fafa-157">**Чем ближе к 1,00, тем лучше**.</span><span class="sxs-lookup"><span data-stu-id="4fafa-157">**The closer to 1.00, the better**.</span></span>  <span data-ttu-id="4fafa-158">Она вычисляет метрики независимо для каждого класса и затем берет среднее значение (поэтому все классы учитываются одинаково).</span><span class="sxs-lookup"><span data-stu-id="4fafa-158">It computes the metric independently for each class and then takes the average (hence treating all classes equally)</span></span> |
| <span data-ttu-id="4fafa-159">**Логарифмическая потеря**</span><span class="sxs-lookup"><span data-stu-id="4fafa-159">**Log-loss**</span></span>| <span data-ttu-id="4fafa-160">[Логарифмическая потеря](http://wiki.fast.ai/index.php/Log_Loss) измеряет производительность модели классификации, где значение вероятности прогноза составляет от 0,00 до 1,00.</span><span class="sxs-lookup"><span data-stu-id="4fafa-160">[Logarithmic loss](http://wiki.fast.ai/index.php/Log_Loss) measures the performance of a classification model where the prediction input is a probability value between 0.00 and 1.00.</span></span> <span data-ttu-id="4fafa-161">Потеря увеличивается по мере отклонения прогнозируемой вероятности от фактического значения метки.</span><span class="sxs-lookup"><span data-stu-id="4fafa-161">Log-loss increases as the predicted probability diverges from the actual label.</span></span> | <span data-ttu-id="4fafa-162">**Чем ближе к 0,00, тем лучше**.</span><span class="sxs-lookup"><span data-stu-id="4fafa-162">**The closer to 0.00, the better**.</span></span> <span data-ttu-id="4fafa-163">У идеальной модели значение потери равно 0,00.</span><span class="sxs-lookup"><span data-stu-id="4fafa-163">A perfect model would have a log-loss of 0.00.</span></span> <span data-ttu-id="4fafa-164">Цель нашей модели машинного обучения — свести к минимуму это значение.</span><span class="sxs-lookup"><span data-stu-id="4fafa-164">The goal of our machine learning models is to minimize this value.</span></span>|
| <span data-ttu-id="4fafa-165">**Редукция логарифмической потери**</span><span class="sxs-lookup"><span data-stu-id="4fafa-165">**Log-Loss Reduction**</span></span> | <span data-ttu-id="4fafa-166">[Редукцию логарифмических потери](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.LogLossReduction) можно интерпретировать как преимущество классификатора над случайным прогнозом.</span><span class="sxs-lookup"><span data-stu-id="4fafa-166">[Logarithmic loss reduction](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.LogLossReduction) can be interpreted as the advantage of the classifier over a random prediction.</span></span>| <span data-ttu-id="4fafa-167">**Имеет значения в диапазоне от -inf до 1,00, где 1,00 — идеальный прогноз, а 0,00 — средние прогнозы**.</span><span class="sxs-lookup"><span data-stu-id="4fafa-167">**Ranges from -inf and 1.00, where 1.00 is perfect predictions and 0.00 indicates mean predictions**.</span></span> <span data-ttu-id="4fafa-168">Например, если значение равно 0,20, оно может интерпретироваться как "вероятность правильного прогноза на 20 % лучше случайного угадывания".</span><span class="sxs-lookup"><span data-stu-id="4fafa-168">For example, if the value equals 0.20, it can be interpreted as "the probability of a correct prediction is 20% better than random guessing"</span></span>|

<span data-ttu-id="4fafa-169">Обычно микроточность лучше согласуется с бизнес-потребностями прогнозов машинного обучения.</span><span class="sxs-lookup"><span data-stu-id="4fafa-169">Micro-accuracy is generally better aligned with the business needs of ML predictions.</span></span> <span data-ttu-id="4fafa-170">Если вы хотите выбрать одну метрику для определения качества задачи многоклассовой классификации, обычно следует выбрать микроточность.</span><span class="sxs-lookup"><span data-stu-id="4fafa-170">If you want to select a single metric for choosing the quality of a multiclass classification task, it should usually be micro-accuracy.</span></span>

<span data-ttu-id="4fafa-171">Например, для задачи классификации запросов в службу поддержки (сопоставляет входящие запросы в и команды службы поддержки)</span><span class="sxs-lookup"><span data-stu-id="4fafa-171">Example, for a support ticket classification task: (maps incoming tickets to support teams)</span></span>

- <span data-ttu-id="4fafa-172">Микроточность — как часто входящий запрос передается подходящей команде сотрудников?</span><span class="sxs-lookup"><span data-stu-id="4fafa-172">Micro-accuracy -- how often does an incoming ticket get classified to the right team?</span></span>
- <span data-ttu-id="4fafa-173">Макроточность — как часто входящий запрос подходит для команды в среднем случае?</span><span class="sxs-lookup"><span data-stu-id="4fafa-173">Macro-accuracy -- for an average team, how often is an incoming ticket correct for their team?</span></span>

<span data-ttu-id="4fafa-174">Макроточность перевешивает небольшие команды в этом примере; небольшие команды, которые получают только 10 обращений в год, учитываются наравне с большой командой с 10 000 обращений в год.</span><span class="sxs-lookup"><span data-stu-id="4fafa-174">Macro-accuracy overweights small teams in this example; a small team that gets only 10 tickets per year counts as much as a large team with 10k tickets per year.</span></span> <span data-ttu-id="4fafa-175">В этом случае микроточность лучше коррелирует с бизнес-потребностями: "сколько времени и денег можно сэкономить, автоматизируя процесс маршрутизации запросов в службу".</span><span class="sxs-lookup"><span data-stu-id="4fafa-175">Micro-accuracy in this case correlates better with the business need of, "how much time/money can the company save by automating my ticket routing process".</span></span>

<span data-ttu-id="4fafa-176">Дополнительные сведения о метриках многоклассовой классификации см. в следующих статьях:</span><span class="sxs-lookup"><span data-stu-id="4fafa-176">For further details on multi-class classification metrics read the following articles:</span></span>

- [<span data-ttu-id="4fafa-177">Запись блога о микро- и макросредних значениях точности, полноты и показателя F</span><span class="sxs-lookup"><span data-stu-id="4fafa-177">Micro- and Macro-average of Precision, Recall, and F-Score</span></span>](https://rushdishams.blogspot.com/2011/08/micro-and-macro-average-of-precision.html)
- [<span data-ttu-id="4fafa-178">Мультиклассовая классификация несбалансированных наборов данных</span><span class="sxs-lookup"><span data-stu-id="4fafa-178">Multiclass Classification with Imbalanced Dataset</span></span>](https://towardsdatascience.com/machine-learning-multiclass-classification-with-imbalanced-data-set-29f6a177c1a)

## <a name="evaluation-metrics-for-regression-and-recommendation"></a><span data-ttu-id="4fafa-179">Метрики оценки для задач регрессии и рекомендации</span><span class="sxs-lookup"><span data-stu-id="4fafa-179">Evaluation metrics for Regression and Recommendation</span></span>

<span data-ttu-id="4fafa-180">Задачи регрессии и рекомендации прогнозируют число.</span><span class="sxs-lookup"><span data-stu-id="4fafa-180">Both the regression and recommendation tasks predict a number.</span></span> <span data-ttu-id="4fafa-181">В случае регрессии число может быть любым выходным свойством, на которое влияют входные свойства.</span><span class="sxs-lookup"><span data-stu-id="4fafa-181">In the case of regression, the number can be any output property that is influenced by the input properties.</span></span> <span data-ttu-id="4fafa-182">В случае рекомендации число обычно представляет собой значение оценки (например, от 1 до 5) или рекомендацию "да/нет" (представленную 1 и 0 соответственно).</span><span class="sxs-lookup"><span data-stu-id="4fafa-182">For recommendation, the number is usually a rating value (between 1 and 5 for example), or a yes/no recommendation (represented by 1 and 0 respectively).</span></span>

| <span data-ttu-id="4fafa-183">Метрика</span><span class="sxs-lookup"><span data-stu-id="4fafa-183">Metric</span></span>   |      <span data-ttu-id="4fafa-184">Описание</span><span class="sxs-lookup"><span data-stu-id="4fafa-184">Description</span></span>      |  <span data-ttu-id="4fafa-185">Вы ищете</span><span class="sxs-lookup"><span data-stu-id="4fafa-185">Look for</span></span> |
|----------|-----------------------|-----------|
| <span data-ttu-id="4fafa-186">**R-квадрат**</span><span class="sxs-lookup"><span data-stu-id="4fafa-186">**R-Squared**</span></span> |  <span data-ttu-id="4fafa-187">[R-квадрат (R2)](https://en.wikipedia.org/wiki/Coefficient_of_determination) или *коэффициент детерминации* обозначает совокупную прогнозирующую способность модели в диапазоне от -inf до 1,00.</span><span class="sxs-lookup"><span data-stu-id="4fafa-187">[R-squared (R2)](https://en.wikipedia.org/wiki/Coefficient_of_determination), or *Coefficient of determination* represents the predictive power of the model as a value between -inf and 1.00.</span></span> <span data-ttu-id="4fafa-188">1,00 означает, что есть идеальное совпадение, но совпадение может быть произвольно плохим, поэтому оценки могут быть отрицательными.</span><span class="sxs-lookup"><span data-stu-id="4fafa-188">1.00 means there is a perfect fit, and the fit can be arbitrarily poor so the scores can be negative.</span></span> <span data-ttu-id="4fafa-189">Оценка 0,00 означает, что модель прогнозирует ожидаемое значение для метки.</span><span class="sxs-lookup"><span data-stu-id="4fafa-189">A score of 0.00 means the model is guessing the expected value for the label.</span></span> <span data-ttu-id="4fafa-190">R2 измеряет, насколько реальные значения данных близки к прогнозируемым.</span><span class="sxs-lookup"><span data-stu-id="4fafa-190">R2 measures how close the actual test data values are to the predicted values.</span></span> | <span data-ttu-id="4fafa-191">**Чем ближе к 1,00, тем выше качество**.</span><span class="sxs-lookup"><span data-stu-id="4fafa-191">**The closer to 1.00, the better quality**.</span></span> <span data-ttu-id="4fafa-192">Тем не менее иногда низкие значения (например, 0,50) могут быть полностью нормальны или достаточны для вашего сценария, тогда как высокие значения не всегда подходят и могут быть подозрительными.</span><span class="sxs-lookup"><span data-stu-id="4fafa-192">However, sometimes low R-squared values (such as 0.50) can be entirely normal or good enough for your scenario and high R-squared values are not always good and be suspicious.</span></span> |
| <span data-ttu-id="4fafa-193">**Абсолютная потеря**</span><span class="sxs-lookup"><span data-stu-id="4fafa-193">**Absolute-loss**</span></span> |  <span data-ttu-id="4fafa-194">[Абсолютная потеря](https://en.wikipedia.org/wiki/Mean_absolute_error), или *средняя абсолютная погрешность (MAE)* , измеряет, насколько прогнозы близки к фактическим результатам.</span><span class="sxs-lookup"><span data-stu-id="4fafa-194">[Absolute-loss](https://en.wikipedia.org/wiki/Mean_absolute_error) or *Mean absolute error (MAE)* measures how close the predictions are to the actual outcomes.</span></span> <span data-ttu-id="4fafa-195">Это среднее значение всех ошибок модели, где ошибка модели — абсолютное расстояние между значением прогнозируемой метки и значением правильной метки.</span><span class="sxs-lookup"><span data-stu-id="4fafa-195">It is the average of all the model errors, where model error is the absolute distance between the predicted label value and the correct label value.</span></span> <span data-ttu-id="4fafa-196">Эта ошибка прогноза вычисляется для каждой записи проверочного набора данных.</span><span class="sxs-lookup"><span data-stu-id="4fafa-196">This prediction error is calculated for each record of the test data set.</span></span> <span data-ttu-id="4fafa-197">Наконец, среднее значение вычисляется для всех зарегистрированных абсолютных ошибок.</span><span class="sxs-lookup"><span data-stu-id="4fafa-197">Finally, the mean value is calculated for all recorded absolute errors.</span></span>| <span data-ttu-id="4fafa-198">**Чем ближе к 0,00, тем выше качество.**</span><span class="sxs-lookup"><span data-stu-id="4fafa-198">**The closer to 0.00, the better quality.**</span></span> <span data-ttu-id="4fafa-199">Средняя абсолютная погрешность использует ту же шкалу данных, что и измеряемые данные (то есть не нормализуется до определенного диапазона).</span><span class="sxs-lookup"><span data-stu-id="4fafa-199">The mean absolute error uses the same scale as the data being measured (is not normalized to specific range).</span></span> <span data-ttu-id="4fafa-200">Абсолютная потеря, квадратичная потеря и среднеквадратичная потеря могут использоваться только для сравнения моделей для одного набора данных или наборов данных с аналогичным распределением значений меток.</span><span class="sxs-lookup"><span data-stu-id="4fafa-200">Absolute-loss, Squared-loss, and RMS-loss can only be used to make comparisons between models for the same dataset or dataset with a similar label value distribution.</span></span> |
| <span data-ttu-id="4fafa-201">**Квадратичная потеря**</span><span class="sxs-lookup"><span data-stu-id="4fafa-201">**Squared-loss**</span></span> |  <span data-ttu-id="4fafa-202">[Квадратичная потеря](https://en.wikipedia.org/wiki/Mean_squared_error) (или *средний квадрат погрешности (MSE)* ; также называемая *среднеквадратичным отклонением (MSD)* ) указывает, насколько близка линия регрессии к набору значений тестовых данных. Это достигается путем вычисления расстояний от точек до линии регрессии ("ошибок") и возведением их в квадрат.</span><span class="sxs-lookup"><span data-stu-id="4fafa-202">[Squared-loss](https://en.wikipedia.org/wiki/Mean_squared_error) or *Mean Squared Error (MSE)*, also called *Mean Squared Deviation (MSD)*, tells you how close a regression line is to a set of test data values by taking the distances from the points to the regression line (these distances are the errors E) and squaring them.</span></span> <span data-ttu-id="4fafa-203">Квадрат дает больше веса большим расстояниям.</span><span class="sxs-lookup"><span data-stu-id="4fafa-203">The squaring gives more weight to larger differences.</span></span> | <span data-ttu-id="4fafa-204">Этот показатель всегда является неотрицательным, **значения ближе к 0,00 предпочтительнее**.</span><span class="sxs-lookup"><span data-stu-id="4fafa-204">It is always non-negative, and **values closer to 0.00 are better**.</span></span> <span data-ttu-id="4fafa-205">В зависимости от данных может оказаться невозможным получить очень маленькое значение для среднеквадратичной ошибки.</span><span class="sxs-lookup"><span data-stu-id="4fafa-205">Depending on your data, it may be impossible to get a very small value for the mean squared error.</span></span>|
| <span data-ttu-id="4fafa-206">**RMS-потеря**</span><span class="sxs-lookup"><span data-stu-id="4fafa-206">**RMS-loss**</span></span> |  <span data-ttu-id="4fafa-207">[RMS-потеря](https://en.wikipedia.org/wiki/Root-mean-square_deviation) (или *среднеквадратичная ошибка (RMSE)* ; также называемая *среднеквадратическим отклонением, RMSD*) измеряет разность между значениями, прогнозируемыми моделью, и значениями, наблюдаемыми в моделируемой среде.</span><span class="sxs-lookup"><span data-stu-id="4fafa-207">[RMS-loss](https://en.wikipedia.org/wiki/Root-mean-square_deviation) or *Root Mean Squared Error (RMSE)* (also called *Root Mean Square Deviation, RMSD*), measures the difference between values predicted by a model and the values observed from the environment that is being modeled.</span></span> <span data-ttu-id="4fafa-208">RMS-потеря — это квадратный корень из квадратной потери; она использует те же единицы, что и метка, аналогично абсолютной потере, но придает больший вес большей разности.</span><span class="sxs-lookup"><span data-stu-id="4fafa-208">RMS-loss is the square root of Squared-loss and has the same units as the label, similar to the absolute-loss though giving more weight to larger differences.</span></span> <span data-ttu-id="4fafa-209">Среднеквадратичная ошибка обычно используется в климатологии, прогнозировании и регрессионном анализе для проверки экспериментальных результатов.</span><span class="sxs-lookup"><span data-stu-id="4fafa-209">Root mean square error is commonly used in climatology, forecasting, and regression analysis to verify experimental results.</span></span> | <span data-ttu-id="4fafa-210">Этот показатель всегда является неотрицательным, **значения ближе к 0,00 предпочтительнее**.</span><span class="sxs-lookup"><span data-stu-id="4fafa-210">It is always non-negative, and **values closer to 0.00 are better**.</span></span> <span data-ttu-id="4fafa-211">RMSD — это мера точности для сравнения ошибок прогнозирования различных моделей на конкретном наборе данных, а не между наборами данных, так как она зависит от масштаба.</span><span class="sxs-lookup"><span data-stu-id="4fafa-211">RMSD is a measure of accuracy, to compare forecasting errors of different models for a particular dataset and not between datasets, as it is scale-dependent.</span></span>|

<span data-ttu-id="4fafa-212">Дополнительные сведения о метриках регрессии см. в следующих статьях:</span><span class="sxs-lookup"><span data-stu-id="4fafa-212">For further details on regression metrics, read the following articles:</span></span>

- [<span data-ttu-id="4fafa-213">Регрессионный анализ: как интерпретировать R-квадрат и оценить критерии соответствия?</span><span class="sxs-lookup"><span data-stu-id="4fafa-213">Regression Analysis: How Do I Interpret R-squared and Assess the Goodness-of-Fit?</span></span>](https://blog.minitab.com/blog/adventures-in-statistics-2/regression-analysis-how-do-i-interpret-r-squared-and-assess-the-goodness-of-fit)
- [<span data-ttu-id="4fafa-214">Способ интерпретации R-квадрата в регрессионном анализе</span><span class="sxs-lookup"><span data-stu-id="4fafa-214">How To Interpret R-squared in Regression Analysis</span></span>](https://statisticsbyjim.com/regression/interpret-r-squared-regression)
- [<span data-ttu-id="4fafa-215">Определение R-квадрата</span><span class="sxs-lookup"><span data-stu-id="4fafa-215">R-Squared Definition</span></span>](https://www.investopedia.com/terms/r/r-squared.asp)
- [<span data-ttu-id="4fafa-216">Определение среднеквадратической ошибки</span><span class="sxs-lookup"><span data-stu-id="4fafa-216">Mean Squared Error Definition</span></span>](https://www.statisticshowto.datasciencecentral.com/mean-squared-error/)
- [<span data-ttu-id="4fafa-217">Что такое средний квадрат погрешности и среднеквадратичная ошибка?</span><span class="sxs-lookup"><span data-stu-id="4fafa-217">What are Mean Squared Error and Root Mean Squared Error?</span></span>](https://www.vernier.com/til/1014/)

## <a name="evaluation-metrics-for-clustering"></a><span data-ttu-id="4fafa-218">Метрики оценки для кластеризации</span><span class="sxs-lookup"><span data-stu-id="4fafa-218">Evaluation metrics for Clustering</span></span>

| <span data-ttu-id="4fafa-219">Метрика</span><span class="sxs-lookup"><span data-stu-id="4fafa-219">Metric</span></span>   |      <span data-ttu-id="4fafa-220">Описание</span><span class="sxs-lookup"><span data-stu-id="4fafa-220">Description</span></span>      |  <span data-ttu-id="4fafa-221">Вы ищете</span><span class="sxs-lookup"><span data-stu-id="4fafa-221">Look for</span></span> |
|----------|-----------------------|-----------|
|<span data-ttu-id="4fafa-222">**Среднее расстояние**</span><span class="sxs-lookup"><span data-stu-id="4fafa-222">**Average Distance**</span></span>|<span data-ttu-id="4fafa-223">Среднее расстояние между точками данных и центром назначенного им кластера.</span><span class="sxs-lookup"><span data-stu-id="4fafa-223">Average of the distance between data points and the center of their assigned cluster.</span></span> <span data-ttu-id="4fafa-224">Среднее расстояние — это мера близости точек данных к центроидам кластеров.</span><span class="sxs-lookup"><span data-stu-id="4fafa-224">The average distance is a measure of proximity of the data points to cluster centroids.</span></span> <span data-ttu-id="4fafa-225">Эта метрика указывает, насколько "плотным" является кластер.</span><span class="sxs-lookup"><span data-stu-id="4fafa-225">It's a measure of how 'tight' the cluster is.</span></span>|<span data-ttu-id="4fafa-226">Значения ближе к **0** предпочтительнее.</span><span class="sxs-lookup"><span data-stu-id="4fafa-226">Values closer to **0** are better.</span></span> <span data-ttu-id="4fafa-227">Чем ближе среднее расстояние к нулю, тем более кластеризованы данные.</span><span class="sxs-lookup"><span data-stu-id="4fafa-227">The closer to zero the average distance is, the more clustered the data is.</span></span> <span data-ttu-id="4fafa-228">Обратите внимание, что эта метрика будет уменьшаться, если количество кластеров увеличивается. В крайнем случае (где каждая отдельная точка данных является собственным кластером) она будет равна нулю.</span><span class="sxs-lookup"><span data-stu-id="4fafa-228">Note though, that this metric will decrease if the number of clusters is increased, and in the extreme case (where each distinct data point is its own cluster) it will be equal to zero.</span></span>
|<span data-ttu-id="4fafa-229">**Индекс Дэвиса — Болдина**</span><span class="sxs-lookup"><span data-stu-id="4fafa-229">**Davies Bouldin Index**</span></span>|<span data-ttu-id="4fafa-230">Среднее соотношение расстояний внутри кластера и расстояний между кластерами.</span><span class="sxs-lookup"><span data-stu-id="4fafa-230">The average ratio of within-cluster distances to between-cluster distances.</span></span> <span data-ttu-id="4fafa-231">Чем плотнее кластер и чем дальше кластеры друг от друга, тем ниже это значение.</span><span class="sxs-lookup"><span data-stu-id="4fafa-231">The tighter the cluster, and the further apart the clusters are, the lower this value is.</span></span>|<span data-ttu-id="4fafa-232">Значения ближе к **0** предпочтительнее.</span><span class="sxs-lookup"><span data-stu-id="4fafa-232">Values closer to **0** are better.</span></span> <span data-ttu-id="4fafa-233">Кластеры, которые находятся дальше друг от друга и являются менее распределенными, приведут к лучшей оценке.</span><span class="sxs-lookup"><span data-stu-id="4fafa-233">Clusters that are farther apart and less dispersed will result in a better score.</span></span>|
|<span data-ttu-id="4fafa-234">**Нормализованная взаимная информация**</span><span class="sxs-lookup"><span data-stu-id="4fafa-234">**Normalized Mutual Information**</span></span>|<span data-ttu-id="4fafa-235">Эта метрика подходит, когда данные, используемые для обучения модели кластеризации, также поставляются с контрольными метками (то есть защищенной кластеризацией).</span><span class="sxs-lookup"><span data-stu-id="4fafa-235">Can be used when the training data used to train the clustering model also comes with ground truth labels (that is, supervised clustering).</span></span> <span data-ttu-id="4fafa-236">Метрика "Нормализованная взаимная информация" показывает, назначаются ли одинаковые точки данных одному и тому же кластеру, а разные точки данных — различным кластерам.</span><span class="sxs-lookup"><span data-stu-id="4fafa-236">The Normalized Mutual Information metric measures whether similar data points get assigned to the same cluster and disparate data points get assigned to different clusters.</span></span> <span data-ttu-id="4fafa-237">Эта метрика принимает значение от 0 до 1.</span><span class="sxs-lookup"><span data-stu-id="4fafa-237">Normalized mutual information is a value between 0 and 1</span></span>|<span data-ttu-id="4fafa-238">Значения ближе к **1** предпочтительнее.</span><span class="sxs-lookup"><span data-stu-id="4fafa-238">Values closer to **1** are better</span></span>|

## <a name="evaluation-metrics-for-ranking"></a><span data-ttu-id="4fafa-239">Метрики оценки для ранжирования</span><span class="sxs-lookup"><span data-stu-id="4fafa-239">Evaluation metrics for Ranking</span></span>

| <span data-ttu-id="4fafa-240">Метрика</span><span class="sxs-lookup"><span data-stu-id="4fafa-240">Metric</span></span>   |      <span data-ttu-id="4fafa-241">Описание</span><span class="sxs-lookup"><span data-stu-id="4fafa-241">Description</span></span>      |  <span data-ttu-id="4fafa-242">Вы ищете</span><span class="sxs-lookup"><span data-stu-id="4fafa-242">Look for</span></span> |
|----------|-----------------------|-----------|
|<span data-ttu-id="4fafa-243">**Дисконтированная совокупная прибыль**</span><span class="sxs-lookup"><span data-stu-id="4fafa-243">**Discounted Cumulative Gains**</span></span>|<span data-ttu-id="4fafa-244">Дисконтированная совокупная прибыль является мерой качества ранжирования.</span><span class="sxs-lookup"><span data-stu-id="4fafa-244">Discounted cumulative gain (DCG) is a measure of ranking quality.</span></span> <span data-ttu-id="4fafa-245">Она является производной от двух предположений.</span><span class="sxs-lookup"><span data-stu-id="4fafa-245">It is derived from two assumptions.</span></span> <span data-ttu-id="4fafa-246">Первое: высоко релевантные элементы более полезны, если отображаются выше в порядке ранжирования.</span><span class="sxs-lookup"><span data-stu-id="4fafa-246">One: Highly relevant items are more useful when appearing higher in ranking order.</span></span> <span data-ttu-id="4fafa-247">Второе: полезность отслеживает релевантность, то есть, чем выше релевантность, тем полезнее элемент.</span><span class="sxs-lookup"><span data-stu-id="4fafa-247">Two: Usefulness tracks relevance that is, the higher the relevance, the more useful an item.</span></span> <span data-ttu-id="4fafa-248">Дисконтированная совокупная прибыль рассчитывается для конкретной позиции в порядке ранжирования.</span><span class="sxs-lookup"><span data-stu-id="4fafa-248">Discounted cumulative gain is calculated for a particular position in the ranking order.</span></span> <span data-ttu-id="4fafa-249">Она суммирует оценку релевантности, деленную на логарифм индекса ранжирования до нужной позиции.</span><span class="sxs-lookup"><span data-stu-id="4fafa-249">It sums the relevance grading divided by the logarithm of the ranking index up to the position of interest.</span></span> <span data-ttu-id="4fafa-250">Она рассчитывается с помощью формулы $\sum_{i=0}^{p} \frac {rel_i} {\log_{e}{i+1}}$. Оценки релевантности предоставляются алгоритму обучения ранжирования в качестве контрольных меток.</span><span class="sxs-lookup"><span data-stu-id="4fafa-250">It is calculated using $\sum_{i=0}^{p} \frac {rel_i} {\log_{e}{i+1}}$ Relevance gradings are provided to a ranking training algorithm as ground truth labels.</span></span> <span data-ttu-id="4fafa-251">Одно значение дисконтированной совокупной прибыли предоставляется для каждой позиции в таблице ранжирования, отсюда и название "Дисконтированная совокупная **прибыль**".</span><span class="sxs-lookup"><span data-stu-id="4fafa-251">One DCG value is provided for each position in the ranking table, hence the name Discounted Cumulative **Gains**.</span></span> |<span data-ttu-id="4fafa-252">**Предпочтение отдается более высоким значениям**</span><span class="sxs-lookup"><span data-stu-id="4fafa-252">**Higher values are better**</span></span>|
|<span data-ttu-id="4fafa-253">**Нормализованная дисконтированная совокупная прибыль**</span><span class="sxs-lookup"><span data-stu-id="4fafa-253">**Normalized Discounted Cumulative Gains**</span></span>|<span data-ttu-id="4fafa-254">Нормализация дисконтированной совокупной прибыли позволяет сравнивать метрику для списков ранжирования различной длины.</span><span class="sxs-lookup"><span data-stu-id="4fafa-254">Normalizing DCG allows the metric to be compared for ranking lists of different lengths</span></span>|<span data-ttu-id="4fafa-255">**Значения ближе к 1 предпочтительнее**.</span><span class="sxs-lookup"><span data-stu-id="4fafa-255">**Values closer to 1 are better**</span></span>|

## <a name="evaluation-metrics-for-anomaly-detection"></a><span data-ttu-id="4fafa-256">Метрики оценки для обнаружения аномалий</span><span class="sxs-lookup"><span data-stu-id="4fafa-256">Evaluation metrics for Anomaly Detection</span></span>

| <span data-ttu-id="4fafa-257">Метрика</span><span class="sxs-lookup"><span data-stu-id="4fafa-257">Metric</span></span>   |      <span data-ttu-id="4fafa-258">Описание</span><span class="sxs-lookup"><span data-stu-id="4fafa-258">Description</span></span>      |  <span data-ttu-id="4fafa-259">Вы ищете</span><span class="sxs-lookup"><span data-stu-id="4fafa-259">Look for</span></span> |
|----------|-----------------------|-----------|
|<span data-ttu-id="4fafa-260">**Площадь под ROC-кривой**</span><span class="sxs-lookup"><span data-stu-id="4fafa-260">**Area Under ROC Curve**</span></span>|<span data-ttu-id="4fafa-261">Метрика "Площадь под ROC-кривой" показывает, насколько хорошо модель разделяет аномальные и обычные точки данных.</span><span class="sxs-lookup"><span data-stu-id="4fafa-261">Area under the receiver operator curve measures how well the model separates anomalous and usual data points.</span></span>|<span data-ttu-id="4fafa-262">**Значения ближе к 1 предпочтительнее**.</span><span class="sxs-lookup"><span data-stu-id="4fafa-262">**Values closer to 1 are better**.</span></span> <span data-ttu-id="4fafa-263">Только значения больше 0,5 демонстрируют эффективность модели.</span><span class="sxs-lookup"><span data-stu-id="4fafa-263">Only values greater than 0.5 demonstrate effectiveness of the model.</span></span> <span data-ttu-id="4fafa-264">Значения 0,5 или ниже указывают, что модель работает не лучше, чем случайное распределение входных данных на категории аномальных и обычных.</span><span class="sxs-lookup"><span data-stu-id="4fafa-264">Values of 0.5 or below indicate that the model is no better than randomly allocating the inputs to anomalous and usual categories</span></span>|
|<span data-ttu-id="4fafa-265">**Частота обнаружения при количестве ложноположительных значений**</span><span class="sxs-lookup"><span data-stu-id="4fafa-265">**Detection Rate At False Positive Count**</span></span>|<span data-ttu-id="4fafa-266">Частота обнаружения при количестве ложноположительных значений — это соотношение количества правильно определенных аномалий и общего количества аномалий в тестовом наборе, индексируемых по каждому ложноположительному результату.</span><span class="sxs-lookup"><span data-stu-id="4fafa-266">Detection rate at false positive count is the ratio of the number of correctly identified anomalies to the total number of anomalies in a test set, indexed by each false positive.</span></span> <span data-ttu-id="4fafa-267">Таким образом, для каждого ложноположительного элемента существует значение частоты обнаружения при количестве ложных срабатываний.</span><span class="sxs-lookup"><span data-stu-id="4fafa-267">That is, there is a value for detection rate at false positive count for each false positive item.</span></span>|<span data-ttu-id="4fafa-268">**Значения ближе к 1 предпочтительнее**.</span><span class="sxs-lookup"><span data-stu-id="4fafa-268">**Values closer to 1 are better**.</span></span> <span data-ttu-id="4fafa-269">Если ложные срабатывания отсутствуют, это значение равно 1.</span><span class="sxs-lookup"><span data-stu-id="4fafa-269">If there are no false positives, then this value is 1</span></span>|
