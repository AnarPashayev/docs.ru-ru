---
title: Метрики ML.NET
description: Общие сведения о метриках, которые используются для оценки производительности модели ML.NET
ms.date: 04/29/2019
author: ''
ms.openlocfilehash: 802f0a8fd32c492c8d9f89933b183802cb178cb3
ms.sourcegitcommit: 7e129d879ddb42a8b4334eee35727afe3d437952
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 05/23/2019
ms.locfileid: "66053041"
---
# <a name="model-evaluation-metrics-in-mlnet"></a>Метрики оценки модели в ML.NET

## <a name="metrics-for-binary-classification"></a>Метрики для бинарной классификации

| Метрики   |      Описание      |  Вы ищете |
|-----------|-----------------------|-----------|
| **Точность** |  [Точность](https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification) — это доля правильных прогнозов с помощью проверочного набора данных. Это соотношение числа правильно угаданных и общего числа примеров входных данных. Он работает хорошо, только если существует аналогичное количество выборок, принадлежащих каждому классу.| **Чем ближе к 1,00, тем лучше**. Точное значение 1,00 говорит о проблемах (обычно это утечка меток и целей, переобучение или тестирование с помощью учебных данных). Если тестовые данные не сбалансированы (большинство экземпляров относится к одному из классов), набор данных слишком мал или оценка подходит к значению 0,00 или 1,00, то точность не отражает фактическую эффективность классификатора и вам нужно проверить дополнительные метрики. |
| **AUC** |    [aucROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) или *площадь под кривой*: оценивает площадь под кривой, созданной суммированием частот истинно положительных результатов и ложно положительных результатов.  |   **Чем ближе к 1,00, тем лучше**. Значение должно быть больше 0,50 для допустимой модели; модель с AUC не выше 0,50 неприменима. |
| **AUCPR** | [aucPR](https://www.coursera.org/lecture/ml-classification/precision-recall-curve-rENu8) или *площадь под кривой "точность — полнота"* : удобная мера успешного прогноза, когда классы очень различаются (крайне неравномерно распределенные наборы данных). |  **Чем ближе к 1,00, тем лучше**. Высокий уровень оценки, близкий к 1,00, показывает, что классификатор возвращает точные результаты (высокая точность), а также возвращает большую часть всех положительных результатов (высокий уровень полноты). |
| **Показатель F1** | [Показатель F1](https://en.wikipedia.org/wiki/F1_score) также называется *сбалансированной F-оценкой или F-мерой*. Это среднее гармоническое значение точности и полноты. Показатель F1 полезен в том случае, если необходимо найти баланс между точностью и полнотой.| **Чем ближе к 1,00, тем лучше**.  Показатель F1 достигает лучшего значения в 1,00 и худшего — в 0,00. Он сообщает, насколько точен классификатор. |

Дополнительные сведения о метриках бинарной классификации см. в следующих статьях:

- [Точность, полнота или F1?](https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9)
- [Класс метрик бинарной классификации](xref:Microsoft.ML.Data.BinaryClassificationMetrics)
- [Связь между кривыми "точность — полнота" и кривыми ROC](http://pages.cs.wisc.edu/~jdavis/davisgoadrichcamera2.pdf)

## <a name="metrics-for-multi-class-classification"></a>Метрики для многоклассовой классификации

| Метрики   |      Описание      |  Вы ищете |
|-----------|-----------------------|-----------|
| **Микроточность** |  [Микросредняя точность](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MicroAccuracy) агрегирует вклады всех классов для вычисления среднего показателя. Это доля экземпляров, которые модель правильно спрогнозировала. Микросреднее не учитывает членство в классе. По сути, каждая пара "пример — класс" одинаково участвует в метрике точности. | **Чем ближе к 1,00, тем лучше**. В задаче многоклассовой классификации микроточность является предпочтительной по сравнению с макроточностью, если есть подозрение, что может присутствовать несбалансированность классов (например, гораздо больше примеров из одного класса, чем из других).|
| **Макроточность** | [Макросредняя точность](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.MacroAccuracy) — это средняя точность на уровне класса. Вычисляется точность для каждого класса, а макроточность — это среднее этих значений. По сути, каждый класс одинаково участвует в этой метрике точности. Миноритарным классам назначается тот же вес, что и более крупным. Макросреднее значение метрики назначает один и тот же вес для каждого класса независимо от того, сколько экземпляров содержит класс набора данных. |  **Чем ближе к 1,00, тем лучше**.  Она вычисляет метрики независимо для каждого класса и затем берет среднее значение (поэтому все классы учитываются одинаково). |
| **Логарифмическая потеря**| [Логарифмическая потеря](http://wiki.fast.ai/index.php/Log_Loss) измеряет производительность модели классификации, где значение вероятности прогноза составляет от 0,00 до 1,00. Потеря увеличивается по мере отклонения прогнозируемой вероятности от фактического значения метки. | **Чем ближе к 0,00, тем лучше**. У идеальной модели значение потери равно 0,00. Цель нашей модели машинного обучения — свести к минимуму это значение.|
| **Редукция логарифмической потери** | [Редукцию логарифмических потери](xref:Microsoft.ML.Data.MulticlassClassificationMetrics.LogLossReduction) можно интерпретировать как преимущество классификатора над случайным прогнозом.| **Имеет значения в диапазоне от -inf до 1,00, где 1,00 — идеальный прогноз, а 0,00 — средние прогнозы**. Например, если значение равно 0,20, оно может интерпретироваться как "вероятность правильного прогноза на 20 % лучше случайного угадывания".|

Обычно микроточность лучше согласуется с бизнес-потребностями прогнозов машинного обучения. Если вы хотите выбрать одну метрику для определения качества задачи многоклассовой классификации, обычно следует выбрать микроточность.

Например, для задачи классификации запросов в службу поддержки (сопоставляет входящие запросы в и команды службы поддержки)

- Микроточность — как часто входящий запрос передается подходящей команде сотрудников?
- Макроточность — как часто входящий запрос подходит для команды в среднем случае?

Макроточность перевешивает небольшие команды в этом примере; небольшие команды, которые получают только 10 обращений в год, учитываются наравне с большой командой с 10 000 обращений в год. В этом случае микроточность лучше коррелирует с бизнес-потребностями: "сколько времени и денег можно сэкономить, автоматизируя процесс маршрутизации запросов в службу".

Дополнительные сведения о метриках многоклассовой классификации см. в следующих статьях:

- [Микро- и макросреднее значения точности, полноты и F-оценки](http://rushdishams.blogspot.com/2011/08/micro-and-macro-average-of-precision.html)
- [Мультиклассовая классификация несбалансированных наборов данных](https://towardsdatascience.com/machine-learning-multiclass-classification-with-imbalanced-data-set-29f6a177c1a)

## <a name="metrics-for-regression"></a>Метрики для регрессии

| Метрики   |      Описание      |  Вы ищете |
|-----------|-----------------------|-----------|
| **R-квадрат** |  [R-квадрат (R2)](https://en.wikipedia.org/wiki/Coefficient_of_determination) или *коэффициент детерминации* обозначает совокупную прогнозирующую способность модели в диапазоне от -inf до 1,00. 1,00 означает, что есть идеальное совпадение, но совпадение может быть произвольно плохим, поэтому оценки могут быть отрицательными. Оценка 0,00 означает, что модель прогнозирует ожидаемое значение для метки. R2 измеряет, насколько реальные значения данных близки к прогнозируемым. | **Чем ближе к 1,00, тем выше качество**. Тем не менее иногда низкие значения (например, 0,50) могут быть полностью нормальны или достаточны для вашего сценария, тогда как высокие значения не всегда подходят и могут быть подозрительными. |
| **Абсолютная потеря** |  [Абсолютная потеря](https://en.wikipedia.org/wiki/Mean_absolute_error), или *средняя абсолютная погрешность (MAE)* , измеряет, насколько прогнозы близки к фактическим результатам. Это среднее значение всех ошибок модели, где ошибка модели — абсолютное расстояние между значением прогнозируемой метки и значением правильной метки. Эта ошибка прогноза вычисляется для каждой записи проверочного набора данных. Наконец, среднее значение вычисляется для всех зарегистрированных абсолютных ошибок.| **Чем ближе к 0,00, тем выше качество.** Обратите внимание, что средняя абсолютная погрешность использует ту же шкалу данных, что и измеряемые данные (то есть не нормализуется до определенного диапазона). Абсолютная потеря, квадратичная потеря и среднеквадратичная потеря могут использоваться только для сравнения моделей для одного набора данных или наборов данных с аналогичным распределением меток значений. |
| **Квадратичная потеря** |  [Квадратичная потеря](https://en.wikipedia.org/wiki/Mean_squared_error), или *средний квадрат погрешности (MSE)* , также называемый *среднеквадратичным отклонением (MSD)* , говорит о том, насколько близка линия регрессии к набору тестовых значений данных. Это достигается путем вычисления расстояний от точек до линии регрессии (эти расстояния являются ошибками E) и возведением их в квадрат. Квадрат дает больше веса большим расстояниям. | Этот показатель всегда является неотрицательным, **значения ближе к 0,00 предпочтительнее**. В зависимости от данных может оказаться невозможным получить очень маленькое значение для среднеквадратичной ошибки.|
| **RMS-потеря** |  [RMS-потеря](https://en.wikipedia.org/wiki/Root-mean-square_deviation), или *среднеквадратичная ошибка (RMSE)* (также называется *среднеквадратическое отклонение, RMSD*), фактически измеряет разность между значениями, прогнозируемыми моделью, и значениями, наблюдаемыми в моделируемой среде. RMS-потеря — это квадратный корень из квадратной потери; она использует те же единицы, что и метки, аналогично абсолютной потере, но приписывает больший вес большей разности. Среднеквадратичная ошибка обычно используется в климатологии, прогнозировании и регрессионном анализе для проверки экспериментальных результатов. | Этот показатель всегда является неотрицательным, **значения ближе к 0,00 предпочтительнее**. RMSD — это мера точности для сравнения ошибок прогнозирования различных моделей на конкретном наборе данных, а не между наборами данных, так как она зависит от масштаба.|

Дополнительные сведения о метриках регрессии см. в следующих статьях:

- [Регрессионный анализ: как интерпретировать R-квадрат и оценить критерии соответствия?](https://blog.minitab.com/blog/adventures-in-statistics-2/regression-analysis-how-do-i-interpret-r-squared-and-assess-the-goodness-of-fit)
- [Способ интерпретации R-квадрата в регрессионном анализе](https://statisticsbyjim.com/regression/interpret-r-squared-regression)
- [Определение R-квадрата](https://www.investopedia.com/terms/r/r-squared.asp)
- [Определение среднеквадратической ошибки](https://www.statisticshowto.datasciencecentral.com/mean-squared-error/)
- [Что такое средний квадрат погрешности и среднеквадратичная ошибка?](https://www.vernier.com/til/1014/)
