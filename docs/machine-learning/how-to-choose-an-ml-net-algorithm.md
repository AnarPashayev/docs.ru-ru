---
title: Выбор алгоритма ML.NET
description: Сведения о выборе алгоритма ML.NET для модели машинного обучения
ms.topic: overview
ms.date: 06/05/2019
ms.openlocfilehash: 0fed33203c02303e37e47f548e08ec131eeb1c77
ms.sourcegitcommit: 9a97c76e141333394676bc5d264c6624b6f45bcf
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 01/08/2020
ms.locfileid: "75739997"
---
# <a name="how-to-choose-an-mlnet-algorithm"></a><span data-ttu-id="eb66e-103">Выбор алгоритма ML.NET</span><span class="sxs-lookup"><span data-stu-id="eb66e-103">How to choose an ML.NET algorithm</span></span>

<span data-ttu-id="eb66e-104">Для каждой [задачи ML.NET](resources/tasks.md) существует несколько возможных алгоритмов обучения.</span><span class="sxs-lookup"><span data-stu-id="eb66e-104">For each [ML.NET task](resources/tasks.md), there are multiple training algorithms to choose from.</span></span> <span data-ttu-id="eb66e-105">Выбор конкретного алгоритма определяется проблемой, которую вы пытаетесь решить, характеристиками данных, а также доступными вам вычислительными ресурсами и ресурсами хранения.</span><span class="sxs-lookup"><span data-stu-id="eb66e-105">Which one to choose depends on the problem you are trying to solve, the characteristics of your data, and the compute and storage resources you have available.</span></span> <span data-ttu-id="eb66e-106">Важно отметить, что обучение модели машинного обучения — это итеративный процесс.</span><span class="sxs-lookup"><span data-stu-id="eb66e-106">It is important to note that training a machine learning model is an iterative process.</span></span> <span data-ttu-id="eb66e-107">Может потребоваться попробовать несколько алгоритмов, чтобы определить лучший из них.</span><span class="sxs-lookup"><span data-stu-id="eb66e-107">You might need to try multiple algorithms to find the one that works best.</span></span>

<span data-ttu-id="eb66e-108">Алгоритмы работают на базе **признаков**.</span><span class="sxs-lookup"><span data-stu-id="eb66e-108">Algorithms operate on **features**.</span></span> <span data-ttu-id="eb66e-109">Признаки — это числовые значения, вычисляемые на основе входных данных.</span><span class="sxs-lookup"><span data-stu-id="eb66e-109">Features are numerical values computed from your input data.</span></span> <span data-ttu-id="eb66e-110">Они являются оптимальным входными данными для алгоритмов машинного обучения.</span><span class="sxs-lookup"><span data-stu-id="eb66e-110">They are optimal inputs for machine learning algorithms.</span></span> <span data-ttu-id="eb66e-111">Вы преобразовываете необработанные входные данные в признаки, используя одно или несколько [преобразований данных](resources/transforms.md).</span><span class="sxs-lookup"><span data-stu-id="eb66e-111">You transform your raw input data into features using one or more [data transforms](resources/transforms.md).</span></span> <span data-ttu-id="eb66e-112">Например, текстовые данные преобразуются в набор из числа слов и числа сочетаний слов.</span><span class="sxs-lookup"><span data-stu-id="eb66e-112">For example, text data is transformed into a set of word counts and word combination counts.</span></span> <span data-ttu-id="eb66e-113">После извлечения признаков из необработанных данных с помощью преобразований данных они считаются **определенными признаками**.</span><span class="sxs-lookup"><span data-stu-id="eb66e-113">Once the features have been extracted from a raw data type using data transforms, they are referred to as **featurized**.</span></span> <span data-ttu-id="eb66e-114">Например, определенные признаки текста или определенные признаки данных изображения.</span><span class="sxs-lookup"><span data-stu-id="eb66e-114">For example, featurized text, or featurized image data.</span></span>

## <a name="trainer--algorithm--task"></a><span data-ttu-id="eb66e-115">Обучающий алгоритм = алгоритм + задача</span><span class="sxs-lookup"><span data-stu-id="eb66e-115">Trainer = Algorithm + Task</span></span>

<span data-ttu-id="eb66e-116">Алгоритм — это математическое описание, используемое для создания **модели**.</span><span class="sxs-lookup"><span data-stu-id="eb66e-116">An algorithm is the math that executes to produce a **model**.</span></span> <span data-ttu-id="eb66e-117">Различные алгоритмы дают модели с разными характеристиками.</span><span class="sxs-lookup"><span data-stu-id="eb66e-117">Different algorithms produce models with different characteristics.</span></span>

<span data-ttu-id="eb66e-118">В ML.NET один алгоритм можно применить к различным задачам.</span><span class="sxs-lookup"><span data-stu-id="eb66e-118">With ML.NET, the same algorithm can be applied to different tasks.</span></span> <span data-ttu-id="eb66e-119">Например, стохастический двойной покоординатный подъем можно использовать для двоичной классификации, многоклассовой классификации и регрессии.</span><span class="sxs-lookup"><span data-stu-id="eb66e-119">For example, Stochastic Dual Coordinated Ascent can be used for Binary Classification, Multiclass Classification, and Regression.</span></span> <span data-ttu-id="eb66e-120">Различие заключается в интерпретации выходных данных алгоритма для сопоставления с задачей.</span><span class="sxs-lookup"><span data-stu-id="eb66e-120">The difference is in how the output of the algorithm is interpreted to match the task.</span></span>

<span data-ttu-id="eb66e-121">Для каждого сочетания алгоритма и задачи ML.NET предоставляет компонент, который выполняет алгоритм обучения и осуществляет интерпретацию.</span><span class="sxs-lookup"><span data-stu-id="eb66e-121">For each algorithm/task combination, ML.NET provides a component that executes the training algorithm and does the interpretation.</span></span> <span data-ttu-id="eb66e-122">Такие компоненты называются обучающими алгоритмами.</span><span class="sxs-lookup"><span data-stu-id="eb66e-122">These components are called trainers.</span></span> <span data-ttu-id="eb66e-123">Например, <xref:Microsoft.ML.Trainers.SdcaRegressionTrainer> использует алгоритм **StochasticDualCoordinatedAscent**, применяемый к задаче **регрессии**.</span><span class="sxs-lookup"><span data-stu-id="eb66e-123">For example, the <xref:Microsoft.ML.Trainers.SdcaRegressionTrainer> uses the **StochasticDualCoordinatedAscent** algorithm applied to the **Regression** task.</span></span>

## <a name="linear-algorithms"></a><span data-ttu-id="eb66e-124">Линейные алгоритмы</span><span class="sxs-lookup"><span data-stu-id="eb66e-124">Linear algorithms</span></span>

<span data-ttu-id="eb66e-125">Линейные алгоритмы создают модель, которая вычисляет **оценки** на базе линейного сочетания входных данных и набора **весовых коэффициентов**.</span><span class="sxs-lookup"><span data-stu-id="eb66e-125">Linear algorithms produce a model that calculates **scores** from a linear combination of the input data and a set of **weights**.</span></span> <span data-ttu-id="eb66e-126">Весовые коэффициенты — это параметры модели, оцениваемые во время обучения.</span><span class="sxs-lookup"><span data-stu-id="eb66e-126">The weights are parameters of the model estimated during training.</span></span>

<span data-ttu-id="eb66e-127">Линейные алгоритмы хорошо подходят для признаков, являющихся [линейно сепарабельными](https://en.wikipedia.org/wiki/Linear_separability).</span><span class="sxs-lookup"><span data-stu-id="eb66e-127">Linear algorithms work well for features that are [linearly separable](https://en.wikipedia.org/wiki/Linear_separability).</span></span>

<span data-ttu-id="eb66e-128">Перед обучением с помощью линейного алгоритма нужно нормализовать признаки.</span><span class="sxs-lookup"><span data-stu-id="eb66e-128">Before training with a linear algorithm, the features should be normalized.</span></span> <span data-ttu-id="eb66e-129">Это не позволяет одному признаку оказывать большее влияние на результат по сравнению с другими признаками.</span><span class="sxs-lookup"><span data-stu-id="eb66e-129">This prevents one feature having more influence over the result than others.</span></span>

<span data-ttu-id="eb66e-130">В общем случае линейные алгоритмы являются масштабируемыми и быстрыми, а также не требуют больших затрат на обучение и прогнозирование.</span><span class="sxs-lookup"><span data-stu-id="eb66e-130">In general linear algorithms are scalable and fast, cheap to train, cheap to predict.</span></span> <span data-ttu-id="eb66e-131">Они масштабируются по количеству признаков и приблизительно по размеру набора данных для обучения.</span><span class="sxs-lookup"><span data-stu-id="eb66e-131">They scale by the number of features and approximately by the size of the training data set.</span></span>

<span data-ttu-id="eb66e-132">Линейные алгоритмы делают несколько проходов по данным для обучения.</span><span class="sxs-lookup"><span data-stu-id="eb66e-132">Linear algorithms make multiple passes over the training data.</span></span> <span data-ttu-id="eb66e-133">Если набор данных помещается в память, то добавление [контрольной точки кэша](xref:Microsoft.ML.LearningPipelineExtensions.AppendCacheCheckpoint*) в конвейер ML.NET перед добавлением обучающего алгоритма ускорит обучение.</span><span class="sxs-lookup"><span data-stu-id="eb66e-133">If your dataset fits into memory, then adding a [cache checkpoint](xref:Microsoft.ML.LearningPipelineExtensions.AppendCacheCheckpoint*) to your ML.NET pipeline before appending the trainer, will make the training run faster.</span></span>

<span data-ttu-id="eb66e-134">**Линейные обучающие алгоритмы**</span><span class="sxs-lookup"><span data-stu-id="eb66e-134">**Linear Trainers**</span></span>

|<span data-ttu-id="eb66e-135">Алгоритм</span><span class="sxs-lookup"><span data-stu-id="eb66e-135">Algorithm</span></span>|<span data-ttu-id="eb66e-136">Свойства</span><span class="sxs-lookup"><span data-stu-id="eb66e-136">Properties</span></span>|<span data-ttu-id="eb66e-137">Обучающие алгоритмы</span><span class="sxs-lookup"><span data-stu-id="eb66e-137">Trainers</span></span>|
|---------|----------|--------|
|<span data-ttu-id="eb66e-138">Усредненный персептрон</span><span class="sxs-lookup"><span data-stu-id="eb66e-138">Averaged perceptron</span></span>|<span data-ttu-id="eb66e-139">Лучше всего подходит для классификации текста.</span><span class="sxs-lookup"><span data-stu-id="eb66e-139">Best for text classification</span></span>|<xref:Microsoft.ML.Trainers.AveragedPerceptronTrainer>|
|<span data-ttu-id="eb66e-140">Стохастический двойной покоординатный подъем</span><span class="sxs-lookup"><span data-stu-id="eb66e-140">Stochastic dual coordinated ascent</span></span>|<span data-ttu-id="eb66e-141">Не требуется настройка для обеспечения хорошей производительности.</span><span class="sxs-lookup"><span data-stu-id="eb66e-141">Tuning not needed for good default performance</span></span>|<span data-ttu-id="eb66e-142"><xref:Microsoft.ML.Trainers.SdcaLogisticRegressionBinaryTrainer> <xref:Microsoft.ML.Trainers.SdcaNonCalibratedBinaryTrainer> <xref:Microsoft.ML.Trainers.SdcaMaximumEntropyMulticlassTrainer> <xref:Microsoft.ML.Trainers.SdcaNonCalibratedMulticlassTrainer> <xref:Microsoft.ML.Trainers.SdcaRegressionTrainer></span><span class="sxs-lookup"><span data-stu-id="eb66e-142"><xref:Microsoft.ML.Trainers.SdcaLogisticRegressionBinaryTrainer> <xref:Microsoft.ML.Trainers.SdcaNonCalibratedBinaryTrainer> <xref:Microsoft.ML.Trainers.SdcaMaximumEntropyMulticlassTrainer> <xref:Microsoft.ML.Trainers.SdcaNonCalibratedMulticlassTrainer> <xref:Microsoft.ML.Trainers.SdcaRegressionTrainer></span></span>|
|<span data-ttu-id="eb66e-143">L-BFGS</span><span class="sxs-lookup"><span data-stu-id="eb66e-143">L-BFGS</span></span>|<span data-ttu-id="eb66e-144">Используется при большом числе признаков.</span><span class="sxs-lookup"><span data-stu-id="eb66e-144">Use when number of features is large.</span></span> <span data-ttu-id="eb66e-145">Создает статистику обучения логистической регрессии, но масштабируется не так хорошо, как AveragedPerceptronTrainer</span><span class="sxs-lookup"><span data-stu-id="eb66e-145">Produces logistic regression training statistics, but doesn't scale as well as the AveragedPerceptronTrainer</span></span>|<span data-ttu-id="eb66e-146"><xref:Microsoft.ML.Trainers.LbfgsLogisticRegressionBinaryTrainer> <xref:Microsoft.ML.Trainers.LbfgsMaximumEntropyMulticlassTrainer> <xref:Microsoft.ML.Trainers.LbfgsPoissonRegressionTrainer></span><span class="sxs-lookup"><span data-stu-id="eb66e-146"><xref:Microsoft.ML.Trainers.LbfgsLogisticRegressionBinaryTrainer> <xref:Microsoft.ML.Trainers.LbfgsMaximumEntropyMulticlassTrainer> <xref:Microsoft.ML.Trainers.LbfgsPoissonRegressionTrainer></span></span>|
|<span data-ttu-id="eb66e-147">Посимвольный стохастический градиентный спуск</span><span class="sxs-lookup"><span data-stu-id="eb66e-147">Symbolic stochastic gradient descent</span></span>|<span data-ttu-id="eb66e-148">Самый быстрый и точный линейный обучающий алгоритм двоичной классификации.</span><span class="sxs-lookup"><span data-stu-id="eb66e-148">Fastest and most accurate linear binary classification trainer.</span></span> <span data-ttu-id="eb66e-149">Хорошо масштабируется по числу процессоров</span><span class="sxs-lookup"><span data-stu-id="eb66e-149">Scales well with number of processors</span></span>|<xref:Microsoft.ML.Trainers.SymbolicSgdLogisticRegressionBinaryTrainer>|

## <a name="decision-tree-algorithms"></a><span data-ttu-id="eb66e-150">Алгоритмы дерева принятия решений</span><span class="sxs-lookup"><span data-stu-id="eb66e-150">Decision tree algorithms</span></span>

<span data-ttu-id="eb66e-151">Алгоритмы дерева принятия решений создают модель, которая содержит ряд решений: по сути, блок-схему для значений данных.</span><span class="sxs-lookup"><span data-stu-id="eb66e-151">Decision tree algorithms create a model that contains a series of decisions: effectively a flow chart through the data values.</span></span>

<span data-ttu-id="eb66e-152">Для использования этого типа алгоритма не требуются линейно масштабируемые признаки.</span><span class="sxs-lookup"><span data-stu-id="eb66e-152">Features do not need to be linearly separable to use this type of algorithm.</span></span> <span data-ttu-id="eb66e-153">Кроме того, признаки не нужно нормализовывать, так как отдельные значения в векторе признаков используются независимо в процессе принятия решений.</span><span class="sxs-lookup"><span data-stu-id="eb66e-153">And features do not need to be normalized, because the individual values in the feature vector are used independently in the decision process.</span></span>

<span data-ttu-id="eb66e-154">Алгоритмы дерева принятия решений обычно очень точны.</span><span class="sxs-lookup"><span data-stu-id="eb66e-154">Decision tree algorithms are generally very accurate.</span></span>

<span data-ttu-id="eb66e-155">За исключением обобщенных аддитивных моделей (GAM), модели дерева могут иметь недостаточную объясняемость, когда число признаков велико.</span><span class="sxs-lookup"><span data-stu-id="eb66e-155">Except for Generalized Additive Models (GAMs), tree models can lack explainability when the number of features is large.</span></span>

<span data-ttu-id="eb66e-156">Алгоритмы дерева принятия решений используют больше ресурсов и хуже масштабируются по сравнению с линейными алгоритмами.</span><span class="sxs-lookup"><span data-stu-id="eb66e-156">Decision tree algorithms take more resources and do not scale as well as linear ones do.</span></span> <span data-ttu-id="eb66e-157">Они хорошо подходят для наборов данных, помещающихся в память.</span><span class="sxs-lookup"><span data-stu-id="eb66e-157">They do perform well on datasets that can fit into memory.</span></span>

<span data-ttu-id="eb66e-158">Расширенные деревья принятия решений представляют собой ансамбль небольших деревьев, где каждое дерево оценивает входные данные и передает результат следующему дереву для уточнения оценки и т. д., то есть каждое следующее дерево улучшает результат предыдущего.</span><span class="sxs-lookup"><span data-stu-id="eb66e-158">Boosted decision trees are an ensemble of small trees where each tree scores the input data and passes the score onto the next tree to produce a better score, and so on, where each tree in the ensemble improves on the previous.</span></span>

<span data-ttu-id="eb66e-159">**Обучающие алгоритмы деревьев принятия решений**</span><span class="sxs-lookup"><span data-stu-id="eb66e-159">**Decision tree trainers**</span></span>

|<span data-ttu-id="eb66e-160">Алгоритм</span><span class="sxs-lookup"><span data-stu-id="eb66e-160">Algorithm</span></span>|<span data-ttu-id="eb66e-161">Свойства</span><span class="sxs-lookup"><span data-stu-id="eb66e-161">Properties</span></span>|<span data-ttu-id="eb66e-162">Обучающие алгоритмы</span><span class="sxs-lookup"><span data-stu-id="eb66e-162">Trainers</span></span>|
|---------|----------|--------|
|<span data-ttu-id="eb66e-163">Машина слабого градиентного бустинга</span><span class="sxs-lookup"><span data-stu-id="eb66e-163">Light gradient boosted machine</span></span>|<span data-ttu-id="eb66e-164">Самый быстрый и точный из обучающих алгоритмов деревьев двоичной классификации.</span><span class="sxs-lookup"><span data-stu-id="eb66e-164">Fastest and most accurate of the binary classification tree trainers.</span></span> <span data-ttu-id="eb66e-165">Высокие возможности настройки</span><span class="sxs-lookup"><span data-stu-id="eb66e-165">Highly tunable</span></span>|<span data-ttu-id="eb66e-166"><xref:Microsoft.ML.Trainers.LightGbm.LightGbmBinaryTrainer> <xref:Microsoft.ML.Trainers.LightGbm.LightGbmMulticlassTrainer> <xref:Microsoft.ML.Trainers.LightGbm.LightGbmRegressionTrainer> <xref:Microsoft.ML.Trainers.LightGbm.LightGbmRankingTrainer></span><span class="sxs-lookup"><span data-stu-id="eb66e-166"><xref:Microsoft.ML.Trainers.LightGbm.LightGbmBinaryTrainer> <xref:Microsoft.ML.Trainers.LightGbm.LightGbmMulticlassTrainer> <xref:Microsoft.ML.Trainers.LightGbm.LightGbmRegressionTrainer> <xref:Microsoft.ML.Trainers.LightGbm.LightGbmRankingTrainer></span></span>|
|<span data-ttu-id="eb66e-167">Быстрое дерево</span><span class="sxs-lookup"><span data-stu-id="eb66e-167">Fast tree</span></span>|<span data-ttu-id="eb66e-168">Используется для данных изображения с определенными признаками.</span><span class="sxs-lookup"><span data-stu-id="eb66e-168">Use for featurized image data.</span></span> <span data-ttu-id="eb66e-169">Устойчив к несбалансированным данным.</span><span class="sxs-lookup"><span data-stu-id="eb66e-169">Resilient to unbalanced data.</span></span> <span data-ttu-id="eb66e-170">Высокие возможности настройки</span><span class="sxs-lookup"><span data-stu-id="eb66e-170">Highly tunable</span></span> | <span data-ttu-id="eb66e-171"><xref:Microsoft.ML.Trainers.FastTree.FastTreeBinaryTrainer> <xref:Microsoft.ML.Trainers.FastTree.FastTreeRegressionTrainer> <xref:Microsoft.ML.Trainers.FastTree.FastTreeTweedieTrainer> <xref:Microsoft.ML.Trainers.FastTree.FastTreeRankingTrainer></span><span class="sxs-lookup"><span data-stu-id="eb66e-171"><xref:Microsoft.ML.Trainers.FastTree.FastTreeBinaryTrainer> <xref:Microsoft.ML.Trainers.FastTree.FastTreeRegressionTrainer> <xref:Microsoft.ML.Trainers.FastTree.FastTreeTweedieTrainer> <xref:Microsoft.ML.Trainers.FastTree.FastTreeRankingTrainer></span></span>|
|<span data-ttu-id="eb66e-172">Быстрый лес</span><span class="sxs-lookup"><span data-stu-id="eb66e-172">Fast forest</span></span>|<span data-ttu-id="eb66e-173">Отлично подходит для данных с высоким уровнем шума.</span><span class="sxs-lookup"><span data-stu-id="eb66e-173">Works well with noisy data</span></span>|<span data-ttu-id="eb66e-174"><xref:Microsoft.ML.Trainers.FastTree.FastForestBinaryTrainer> <xref:Microsoft.ML.Trainers.FastTree.FastForestRegressionTrainer></span><span class="sxs-lookup"><span data-stu-id="eb66e-174"><xref:Microsoft.ML.Trainers.FastTree.FastForestBinaryTrainer> <xref:Microsoft.ML.Trainers.FastTree.FastForestRegressionTrainer></span></span>|
|<span data-ttu-id="eb66e-175">Обобщенная аддитивная модель (GAM)</span><span class="sxs-lookup"><span data-stu-id="eb66e-175">Generalized additive model (GAM)</span></span>|<span data-ttu-id="eb66e-176">Лучше всего подходит для случаев, где хорошо справляются алгоритмы дерева, но объясняемость является приоритетной задачей.</span><span class="sxs-lookup"><span data-stu-id="eb66e-176">Best for problems that perform well with tree algorithms but where explainability is a priority</span></span>|<span data-ttu-id="eb66e-177"><xref:Microsoft.ML.Trainers.FastTree.GamBinaryTrainer> <xref:Microsoft.ML.Trainers.FastTree.GamRegressionTrainer></span><span class="sxs-lookup"><span data-stu-id="eb66e-177"><xref:Microsoft.ML.Trainers.FastTree.GamBinaryTrainer> <xref:Microsoft.ML.Trainers.FastTree.GamRegressionTrainer></span></span>|

## <a name="matrix-factorization"></a><span data-ttu-id="eb66e-178">Факторизация матрицы</span><span class="sxs-lookup"><span data-stu-id="eb66e-178">Matrix factorization</span></span>

|<span data-ttu-id="eb66e-179">Свойства</span><span class="sxs-lookup"><span data-stu-id="eb66e-179">Properties</span></span>|<span data-ttu-id="eb66e-180">Обучающие алгоритмы</span><span class="sxs-lookup"><span data-stu-id="eb66e-180">Trainers</span></span>|
|----------|--------|
|<span data-ttu-id="eb66e-181">Лучше всего подходит для разреженных категориальных данных с большими наборами данных.</span><span class="sxs-lookup"><span data-stu-id="eb66e-181">Best for sparse categorical data, with large datasets</span></span>|<xref:Microsoft.ML.Trainers.FieldAwareFactorizationMachineTrainer>|

## <a name="meta-algorithms"></a><span data-ttu-id="eb66e-182">Метаалгоритмы</span><span class="sxs-lookup"><span data-stu-id="eb66e-182">Meta algorithms</span></span>

<span data-ttu-id="eb66e-183">Эти обучающие алгоритмы создают многоклассовый обучающий алгоритм из двоичного.</span><span class="sxs-lookup"><span data-stu-id="eb66e-183">These trainers create a multi-class trainer from a binary trainer.</span></span> <span data-ttu-id="eb66e-184">Используется с <xref:Microsoft.ML.Trainers.AveragedPerceptronTrainer>, <xref:Microsoft.ML.Trainers.LbfgsLogisticRegressionBinaryTrainer>, <xref:Microsoft.ML.Trainers.SymbolicSgdLogisticRegressionBinaryTrainer>, <xref:Microsoft.ML.Trainers.LightGbm.LightGbmBinaryTrainer>, <xref:Microsoft.ML.Trainers.FastTree.FastTreeBinaryTrainer>, <xref:Microsoft.ML.Trainers.FastTree.FastForestBinaryTrainer>, <xref:Microsoft.ML.Trainers.FastTree.GamBinaryTrainer>.</span><span class="sxs-lookup"><span data-stu-id="eb66e-184">Use with <xref:Microsoft.ML.Trainers.AveragedPerceptronTrainer>, <xref:Microsoft.ML.Trainers.LbfgsLogisticRegressionBinaryTrainer>, <xref:Microsoft.ML.Trainers.SymbolicSgdLogisticRegressionBinaryTrainer>, <xref:Microsoft.ML.Trainers.LightGbm.LightGbmBinaryTrainer>, <xref:Microsoft.ML.Trainers.FastTree.FastTreeBinaryTrainer>, <xref:Microsoft.ML.Trainers.FastTree.FastForestBinaryTrainer>, <xref:Microsoft.ML.Trainers.FastTree.GamBinaryTrainer>.</span></span>

|<span data-ttu-id="eb66e-185">Алгоритм</span><span class="sxs-lookup"><span data-stu-id="eb66e-185">Algorithm</span></span>|<span data-ttu-id="eb66e-186">Свойства</span><span class="sxs-lookup"><span data-stu-id="eb66e-186">Properties</span></span>|<span data-ttu-id="eb66e-187">Обучающие алгоритмы</span><span class="sxs-lookup"><span data-stu-id="eb66e-187">Trainers</span></span>|
|---------|----------|--------|
|<span data-ttu-id="eb66e-188">Один против всех</span><span class="sxs-lookup"><span data-stu-id="eb66e-188">One versus all</span></span>|<span data-ttu-id="eb66e-189">Этот многоклассовый классификатор обучает один двоичный классификатор для каждого класса, который отличает этот класс от других.</span><span class="sxs-lookup"><span data-stu-id="eb66e-189">This multiclass classifier trains one binary classifier for each class, which distinguishes that class from all other classes.</span></span> <span data-ttu-id="eb66e-190">Масштабирование ограничено числом классов для классификации.</span><span class="sxs-lookup"><span data-stu-id="eb66e-190">Is limited in scale by the number of classes to categorize</span></span>|[<span data-ttu-id="eb66e-191">OneVersusAllTrainer\<BinaryClassificationTrainer></span><span class="sxs-lookup"><span data-stu-id="eb66e-191">OneVersusAllTrainer\<BinaryClassificationTrainer></span></span>](xref:Microsoft.ML.Trainers.OneVersusAllTrainer) |
|<span data-ttu-id="eb66e-192">Попарное соединение</span><span class="sxs-lookup"><span data-stu-id="eb66e-192">Pairwise coupling</span></span>|<span data-ttu-id="eb66e-193">Этот многоклассовый классификатор обучает алгоритм двоичной классификации для каждой пары классов.</span><span class="sxs-lookup"><span data-stu-id="eb66e-193">This multiclass classifier trains a binary classification algorithm on each pair of classes.</span></span> <span data-ttu-id="eb66e-194">Масштабирование ограничено числом классов, так как требуется обучение для каждого сочетания из двух классов.</span><span class="sxs-lookup"><span data-stu-id="eb66e-194">Is limited in scale by the number of classes, as each combination of two classes must be trained.</span></span>|[<span data-ttu-id="eb66e-195">PairwiseCouplingTrainer\<BinaryClassificationTrainer></span><span class="sxs-lookup"><span data-stu-id="eb66e-195">PairwiseCouplingTrainer\<BinaryClassificationTrainer></span></span>](xref:Microsoft.ML.Trainers.PairwiseCouplingTrainer)|

## <a name="k-means"></a><span data-ttu-id="eb66e-196">Метод k-средних</span><span class="sxs-lookup"><span data-stu-id="eb66e-196">K-Means</span></span>

|<span data-ttu-id="eb66e-197">Свойства</span><span class="sxs-lookup"><span data-stu-id="eb66e-197">Properties</span></span>|<span data-ttu-id="eb66e-198">Обучающие алгоритмы</span><span class="sxs-lookup"><span data-stu-id="eb66e-198">Trainers</span></span>|
|----------|--------|
|<span data-ttu-id="eb66e-199">Используется для кластеризации.</span><span class="sxs-lookup"><span data-stu-id="eb66e-199">Use for clustering</span></span>|<xref:Microsoft.ML.Trainers.KMeansTrainer>|

## <a name="principal-component-analysis"></a><span data-ttu-id="eb66e-200">Анализ главных компонентов</span><span class="sxs-lookup"><span data-stu-id="eb66e-200">Principal component analysis</span></span>

|<span data-ttu-id="eb66e-201">Свойства</span><span class="sxs-lookup"><span data-stu-id="eb66e-201">Properties</span></span>|<span data-ttu-id="eb66e-202">Обучающие алгоритмы</span><span class="sxs-lookup"><span data-stu-id="eb66e-202">Trainers</span></span>|
|----------|--------|
|<span data-ttu-id="eb66e-203">Используется для обнаружения отклонений.</span><span class="sxs-lookup"><span data-stu-id="eb66e-203">Use for anomaly detection</span></span>|<xref:Microsoft.ML.Trainers.RandomizedPcaTrainer>|

## <a name="naive-bayes"></a><span data-ttu-id="eb66e-204">Упрощенный алгоритм Байеса</span><span class="sxs-lookup"><span data-stu-id="eb66e-204">Naive Bayes</span></span>

|<span data-ttu-id="eb66e-205">Свойства</span><span class="sxs-lookup"><span data-stu-id="eb66e-205">Properties</span></span>|<span data-ttu-id="eb66e-206">Обучающие алгоритмы</span><span class="sxs-lookup"><span data-stu-id="eb66e-206">Trainers</span></span>|
|----------|--------|
|<span data-ttu-id="eb66e-207">Этот обучающий алгоритм многоклассовой классификации используется, когда признаки являются независимыми, а набор данных невелик.</span><span class="sxs-lookup"><span data-stu-id="eb66e-207">Use this multi-class classification trainer when the features are independent, and the training dataset is small.</span></span>|<xref:Microsoft.ML.Trainers.NaiveBayesMulticlassTrainer>|

## <a name="prior-trainer"></a><span data-ttu-id="eb66e-208">Базовый обучающий алгоритм</span><span class="sxs-lookup"><span data-stu-id="eb66e-208">Prior Trainer</span></span>

|<span data-ttu-id="eb66e-209">Свойства</span><span class="sxs-lookup"><span data-stu-id="eb66e-209">Properties</span></span>|<span data-ttu-id="eb66e-210">Обучающие алгоритмы</span><span class="sxs-lookup"><span data-stu-id="eb66e-210">Trainers</span></span>|
|----------|--------|
|<span data-ttu-id="eb66e-211">Этот обучающий алгоритм двоичной классификации задает базовый уровень производительности для других обучающих алгоритмов.</span><span class="sxs-lookup"><span data-stu-id="eb66e-211">Use this binary classification trainer to baseline the performance of other trainers.</span></span> <span data-ttu-id="eb66e-212">Для обеспечения эффективности метрики других обучающих алгоритмов должны быть лучше, чем у базового.</span><span class="sxs-lookup"><span data-stu-id="eb66e-212">To be effective, the metrics of the other trainers should be better than the prior trainer.</span></span> |<xref:Microsoft.ML.Trainers.PriorTrainer>|
