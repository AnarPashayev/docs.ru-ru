---
title: Что такое Apache Spark?
description: Сведения об Apache Spark и сценариях обработки больших данных.
ms.date: 10/15/2019
ms.topic: conceptual
ms.custom: mvc
ms.openlocfilehash: 653f355d09a045feabb3dee0f5737cb691cf2dc4
ms.sourcegitcommit: 944ddc52b7f2632f30c668815f92b378efd38eea
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 11/03/2019
ms.locfileid: "73458175"
---
# <a name="what-is-apache-spark"></a>Что такое Apache Spark?

[Apache Spark](https://spark.apache.org/) — это платформа параллельной обработки с открытым кодом, которая поддерживает обработку в памяти, чтобы повысить производительность приложений, анализирующих большие данные. Решения для работы с большими данными предназначены для обработки данных со слишком большим объемом или сложностью для традиционных баз данных. Spark обрабатывает большие объемы данных в памяти, что намного быстрее, чем альтернативная обработка с использованием диска.

## <a name="common-big-data-scenarios"></a>Типичные сценарии обработки больших данных

Архитектура для работы с большими данными полезна, если вам нужно хранить и обрабатывать большие объемы данных, преобразовывать неструктурированные данные или обрабатывать потоковые данные. Spark предоставляет механизм распределенной обработки широкого назначения, который позволяет реализовать несколько сценариев работы с большими данными.

### <a name="extract-transform-and-load-etl"></a>Извлечение, преобразование и загрузка (ETL)

Процесс [извлечения, преобразования и загрузки (ETL)](/azure/architecture/data-guide/relational-data/etl) включает сбор данных из одного или нескольких источников, изменение этих данных и их перемещение в новое хранилище. Есть несколько способов преобразовать данные, например:

* Фильтрация
* Сортировка
* статистическая обработка;
* Соединение
* очистка;
* дедупликация;
* Validating

### <a name="real-time-data-stream-processing"></a>Обработка потоков данных в реальном времени

Данными потоковой передачи (реального времени) называют данные, которые находятся в движении. К ним относятся, например, данные телеметрии от устройств Интернета вещей, веб-журналы и сведения о посещении ресурсов. Обработка данных реального времени позволяет получить полезные сведения (например, с помощью геопространственного анализа, удаленного мониторинга и обнаружения аномалий). Как и в случае с реляционными данными, перед перемещением потоковых данных в приемник вы можете их фильтровать, объединять и подготавливать. Apache Spark поддерживает [обработку потока данных реального времени](/azure/architecture/data-guide/big-data/real-time-processing) с помощью [потоковой передачи Spark](https://spark.apache.org/streaming/).

### <a name="batch-processing"></a>Пакетная обработка

[Пакетная обработка](/azure/architecture/data-guide/big-data/batch-processing) — это обработка неактивных больших данных. Вы можете фильтровать, объединять и подготавливать очень большие наборы данных с помощью длительно выполняющихся параллельных заданий.

### <a name="machine-learning-through-mllib"></a>Машинное обучение с использованием MLlib

Машинное обучение позволяет выполнять расширенные аналитические задачи. Ваш компьютер может использовать существующие данные для прогнозирования реакции, результатов и тенденций. Библиотека машинного обучения [MLlib](https://spark.apache.org/mllib/) из Apache Spark содержит несколько алгоритмов машинного обучения и служебных программ.

### <a name="graph-processing-through-graphx"></a>Обработка графов с помощью GraphX

Граф — это коллекция узлов, которые соединяются ребрами. Вы можете использовать базу данных графов для иерархических или взаимосвязанных данных. Такие данные можно обрабатывать с помощью API [GraphX](https://spark.apache.org/graphx/) в Apache Spark.

### <a name="sql-and-structured-data-processing-with-spark-sql"></a>Обработка SQL и структурированных данных с помощью Spark SQL

Для работы со структурированными (форматированными) данными в приложении Spark можно использовать SQL-запросы с помощью [Spark SQL](https://spark.apache.org/sql/).

## <a name="apache-spark-architecture"></a>Архитектура Apache Spark

Для Apache Spark при использовании архитектуры "основной-рабочий", предусмотрено три основных компонента: драйвер, исполнители и диспетчер кластера.

![Архитектура Apache Spark](media/spark-architecture.png)

### <a name="driver"></a>Драйвер

Драйвер состоит из пользовательской программы, например консольного приложения C#, и сеанса Spark. Сеанс Spark принимает программу и делит ее на небольшие задачи, которые обрабатываются исполнителями.

### <a name="executors"></a>Исполнители

Каждый исполнитель (рабочий узел) получает от драйвера задачу и выполняет ее. Исполнители находятся в сущности, которая называется кластером.

### <a name="cluster-manager"></a>Диспетчер кластера

Диспетчер кластера взаимодействует с драйвером и исполнителями, выполняя следующие задачи:

* управление выделением ресурсов;
* управление разделением программы;
* управление выполнением программы.

## <a name="language-support"></a>Языковая поддержка

Apache Spark поддерживает следующие языки программирования:

* Scala
* Python
* Java
* SQL-код
* R
* .NET

## <a name="spark-apis"></a>API-интерфейсы Spark

Apache Spark поддерживает следующие API:

* [API Scala для Spark](https://spark.apache.org/docs/2.2.0/api/scala/index.html);
* [API Java для Spark](https://spark.apache.org/docs/2.2.0/api/java/index.html);
* [API Python для Spark](https://spark.apache.org/docs/2.2.0/api/python/index.html);
* [API R для Spark](https://spark.apache.org/docs/2.2.0/api/R/index.html);
* [Spark SQL](https://spark.apache.org/docs/latest/api/sql/index.html), встроенные функции.

## <a name="next-steps"></a>Следующие шаги

Сведения об использовании Apache Spark в приложениях .NET. .NET для Apache Spark позволяет разработчикам, имеющим опыт работы с .NET, создавать запросы для обработки больших данных на C# или F#.
> [!div class="nextstepaction"]
> [Что такое .NET для Apache Spark?](what-is-apache-spark-dotnet.md)
